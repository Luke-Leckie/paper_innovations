{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a87e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "#import ruptures as rpt\n",
    "import warnings\n",
    "#import ruptures\n",
    "#import requests\n",
    "import time\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c23dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH=\"/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca95648",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m paper_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATASET_PATH, paper)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(paper_path):\n\u001b[0;32m---> 20\u001b[0m     main_files \u001b[38;5;241m=\u001b[39m \u001b[43mfind_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     model_files \u001b[38;5;241m=\u001b[39m find_files(paper_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m main_files:\n",
      "Cell \u001b[0;32mIn [6], line 6\u001b[0m, in \u001b[0;36mfind_files\u001b[0;34m(root, target_filename)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"Return a list of paths to files in 'root' that match the target filename (case-insensitive).\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m matches \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dirpath, _, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(root):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m target_filename\u001b[38;5;241m.\u001b[39mlower():\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/os.py:412\u001b[0m, in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    407\u001b[0m         new_path \u001b[38;5;241m=\u001b[39m join(top, dirname)\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;66;03m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;66;03m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;66;03m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# above.\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m followlinks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mislink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    413\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m walk(new_path, topdown, onerror, followlinks)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# Recurse into sub-directories\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/posixpath.py:167\u001b[0m, in \u001b[0;36mislink\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"Test whether a path is a symbolic link\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_files(root, target_filename):\n",
    "    \"\"\"Return a list of paths to files in 'root' that match the target filename (case-insensitive).\"\"\"\n",
    "    matches = []\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        for file in filenames:\n",
    "            if file.lower() == target_filename.lower():\n",
    "                matches.append(os.path.join(dirpath, file))\n",
    "    return matches\n",
    "\n",
    "# Dictionaries to hold results: keys are paper titles (folder names)\n",
    "main_dict = {}\n",
    "model_dict = {}\n",
    "\n",
    "# Iterate over the folders in the dataset directory\n",
    "for paper in os.listdir(DATASET_PATH):\n",
    "    paper_path = os.path.join(DATASET_PATH, paper)\n",
    "    if os.path.isdir(paper_path):\n",
    "        main_files = find_files(paper_path, \"main.py\")\n",
    "        model_files = find_files(paper_path, \"model.py\")\n",
    "        if main_files:\n",
    "            main_dict[paper] = main_files\n",
    "        if model_files:\n",
    "            model_dict[paper] = model_files\n",
    "\n",
    "# Print the resulting dictionaries\n",
    "print(\"Main Files Dictionary:\")\n",
    "for key, value in main_dict.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nModel Files Dictionary:\")\n",
    "for key, value in model_dict.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d64ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b9fc19d7cf4c9e8d38ca1c187801b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb83885e7b5b49f184f222e86671f331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/539 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8985adb5178f4245893e19a2eb8e9a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a616300ca0a74c8780124b946d3a2be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04056c45eb44e7ca65273b33980fb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28918dd9d98e46cb93300e45ba5bba29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (768,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6a4ef41a4b4dde8c4e614d21ab4ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load GraphCodeBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a6b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_graphcodebert_embedding(code: str):\n",
    "    # Tokenize the input code snippet\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    # Get the model outputs without gradients\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Extract the embedding from the [CLS] token\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "# Example usage:\n",
    "code_snippet = \"\"\"\n",
    "def example_function(x):\n",
    "    return x * 2\n",
    "\"\"\"\n",
    "embedding = get_graphcodebert_embedding(code_snippet)\n",
    "print(\"Embedding shape:\", embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4146feb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function: example_function\n",
      "def example_function(x):\n",
      "    result = x * 2                                \n",
      "    return result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import io\n",
    "import tokenize\n",
    "\n",
    "def remove_comments_and_docstrings(source):\n",
    "    \"\"\"\n",
    "    Returns the source code with comments, docstrings, and blank newlines removed.\n",
    "    This function tokenizes the source and omits tokens corresponding to\n",
    "    comments and docstrings (when they occur as the first statement in a block).\n",
    "    It then removes blank lines from the result.\n",
    "    \"\"\"\n",
    "    io_obj = io.StringIO(source)\n",
    "    output_tokens = []\n",
    "    prev_toktype = tokenize.INDENT\n",
    "    last_lineno = -1\n",
    "    last_col = 0\n",
    "\n",
    "    try:\n",
    "        for tok in tokenize.generate_tokens(io_obj.readline):\n",
    "            token_type, token_string, (srow, scol), (erow, ecol), line = tok\n",
    "            # Reset column when moving to a new line.\n",
    "            if srow > last_lineno:\n",
    "                last_col = 0\n",
    "            # Skip comment tokens.\n",
    "            if token_type == tokenize.COMMENT:\n",
    "                continue\n",
    "            # Skip string tokens that are likely docstrings.\n",
    "            if token_type == tokenize.STRING and prev_toktype == tokenize.INDENT:\n",
    "                continue\n",
    "            if token_type == tokenize.STRING and last_lineno == 0:\n",
    "                continue\n",
    "            # Preserve spacing.\n",
    "            if scol > last_col:\n",
    "                output_tokens.append(\" \" * (scol - last_col))\n",
    "            output_tokens.append(token_string)\n",
    "            prev_toktype = token_type\n",
    "            last_lineno = erow\n",
    "            last_col = ecol\n",
    "    except tokenize.TokenError as e:\n",
    "        print(f\"Token error: {e}\")\n",
    "        return source\n",
    "\n",
    "    # Join the tokens back into a single string.\n",
    "    cleaned_source = \"\".join(output_tokens)\n",
    "    # Remove blank newlines.\n",
    "    cleaned_lines = [line for line in cleaned_source.splitlines() if line.strip()]\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def extract_functions(file_content):\n",
    "    \"\"\"\n",
    "    Parse Python source code and extract functions.\n",
    "    Returns a dictionary where keys are function names and values are the cleaned source code\n",
    "    of the functions (with comments, docstrings, and blank newlines removed).\n",
    "    \"\"\"\n",
    "    functions = {}\n",
    "    try:\n",
    "        tree = ast.parse(file_content)\n",
    "    except SyntaxError as e:\n",
    "        print(f\"SyntaxError while parsing file: {e}\")\n",
    "        return functions\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            function_source = ast.get_source_segment(file_content, node)\n",
    "            if function_source:\n",
    "                cleaned_source = remove_comments_and_docstrings(function_source)\n",
    "                functions[node.name] = cleaned_source\n",
    "    return functions\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    sample_code = '''\n",
    "def example_function(x):\n",
    "    \"\"\"\n",
    "    This docstring should be removed.\n",
    "    It might span multiple lines.\n",
    "    \"\"\"\n",
    "\n",
    "    # This comment should be removed.\n",
    "\n",
    "    result = x * 2  # Inline comment also removed.\n",
    "\n",
    "    return result\n",
    "'''\n",
    "    funcs = extract_functions(sample_code)\n",
    "    for name, code in funcs.items():\n",
    "        print(f\"Function: {name}\\n{code}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c05cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "008ae9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function embeddings:\n",
      "  example_function: shape (768,)\n",
      "\n",
      "Class embeddings:\n",
      "  ExampleClass: shape (768,)\n",
      "\n",
      "Method embeddings:\n",
      "  ExampleClass.method_one: shape (768,)\n",
      "  ExampleClass.method_two: shape (768,)\n",
      "\n",
      "Document embedding shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import io\n",
    "import tokenize\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def get_graphcodebert_embedding(code: str):\n",
    "    # Tokenize the input code snippet.\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    # Get model outputs without gradients.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Extract the embedding from the [CLS] token.\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "def remove_comments_and_docstrings(source):\n",
    "    \"\"\"\n",
    "    Returns the source code with comments, docstrings, and blank newlines removed.\n",
    "    This function tokenizes the source and omits tokens corresponding to\n",
    "    comments and docstrings (when they occur as the first statement in a block),\n",
    "    then removes blank lines.\n",
    "    \"\"\"\n",
    "    io_obj = io.StringIO(source)\n",
    "    output_tokens = []\n",
    "    prev_toktype = tokenize.INDENT\n",
    "    last_lineno = -1\n",
    "    last_col = 0\n",
    "\n",
    "    try:\n",
    "        for tok in tokenize.generate_tokens(io_obj.readline):\n",
    "            token_type, token_string, (srow, scol), (erow, ecol), line = tok\n",
    "            if srow > last_lineno:\n",
    "                last_col = 0\n",
    "            # Skip comments.\n",
    "            if token_type == tokenize.COMMENT:\n",
    "                continue\n",
    "            # Skip string tokens that are likely docstrings.\n",
    "            if token_type == tokenize.STRING and prev_toktype == tokenize.INDENT:\n",
    "                continue\n",
    "            if token_type == tokenize.STRING and last_lineno == 0:\n",
    "                continue\n",
    "            if scol > last_col:\n",
    "                output_tokens.append(\" \" * (scol - last_col))\n",
    "            output_tokens.append(token_string)\n",
    "            prev_toktype = token_type\n",
    "            last_lineno = erow\n",
    "            last_col = ecol\n",
    "    except tokenize.TokenError as e:\n",
    "        print(f\"Token error: {e}\")\n",
    "        return source\n",
    "\n",
    "    cleaned_source = \"\".join(output_tokens)\n",
    "    # Remove blank newlines.\n",
    "    cleaned_lines = [line for line in cleaned_source.splitlines() if line.strip()]\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def extract_functions(file_content):\n",
    "    \"\"\"\n",
    "    Extract standalone (module-level) functions from the file content.\n",
    "    Returns a dictionary mapping function names to their cleaned source code.\n",
    "    \"\"\"\n",
    "    functions = {}\n",
    "    try:\n",
    "        tree = ast.parse(file_content)\n",
    "    except SyntaxError as e:\n",
    "        print(f\"SyntaxError while parsing file: {e}\")\n",
    "        return functions\n",
    "\n",
    "    # Only consider nodes at the module level.\n",
    "    for node in tree.body:\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            function_source = ast.get_source_segment(file_content, node)\n",
    "            if function_source:\n",
    "                cleaned_source = remove_comments_and_docstrings(function_source)\n",
    "                functions[node.name] = cleaned_source\n",
    "    return functions\n",
    "\n",
    "def extract_methods(file_content):\n",
    "    \"\"\"\n",
    "    Extract methods (functions within classes) from the file content.\n",
    "    Returns a dictionary mapping a compound key \"ClassName.method_name\" to the cleaned source code.\n",
    "    \"\"\"\n",
    "    methods = {}\n",
    "    try:\n",
    "        tree = ast.parse(file_content)\n",
    "    except SyntaxError as e:\n",
    "        print(f\"SyntaxError while parsing file: {e}\")\n",
    "        return methods\n",
    "\n",
    "    for node in tree.body:\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            class_name = node.name\n",
    "            for child in node.body:\n",
    "                if isinstance(child, ast.FunctionDef):\n",
    "                    method_source = ast.get_source_segment(file_content, child)\n",
    "                    if method_source:\n",
    "                        cleaned_source = remove_comments_and_docstrings(method_source)\n",
    "                        methods[f\"{class_name}.{child.name}\"] = cleaned_source\n",
    "    return methods\n",
    "\n",
    "def extract_classes(file_content):\n",
    "    \"\"\"\n",
    "    Parse Python source code and extract class definitions.\n",
    "    Returns a dictionary where keys are class names and values are the cleaned source code\n",
    "    of the classes.\n",
    "    \"\"\"\n",
    "    classes = {}\n",
    "    try:\n",
    "        tree = ast.parse(file_content)\n",
    "    except SyntaxError as e:\n",
    "        print(f\"SyntaxError while parsing file: {e}\")\n",
    "        return classes\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            class_source = ast.get_source_segment(file_content, node)\n",
    "            if class_source:\n",
    "                cleaned_source = remove_comments_and_docstrings(class_source)\n",
    "                classes[node.name] = cleaned_source\n",
    "    return classes\n",
    "\n",
    "\n",
    "def get_clean_document(file_content):\n",
    "    \"\"\"\n",
    "    Returns the entire file content cleaned (removing comments, docstrings, and blank lines).\n",
    "    \"\"\"\n",
    "    return remove_comments_and_docstrings(file_content)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    sample_code = '''\n",
    "\"\"\"\n",
    "Module-level docstring that should be removed.\n",
    "\"\"\"\n",
    "\n",
    "# Module-level comment to be removed.\n",
    "\n",
    "def example_function(x):\n",
    "    \"\"\"\n",
    "    Function-level docstring to be removed.\n",
    "    \"\"\"\n",
    "    # This is a comment.\n",
    "    result = x * 2  # Inline comment.\n",
    "    return result\n",
    "\n",
    "class ExampleClass:\n",
    "    \"\"\"\n",
    "    This class docstring should be removed.\n",
    "    \"\"\"\n",
    "    def method_one(self, y):\n",
    "        # Comment inside method.\n",
    "        return y + 1\n",
    "\n",
    "    def method_two(self, z):\n",
    "        \"\"\"Inline docstring in method.\"\"\"\n",
    "        return z - 1\n",
    "'''\n",
    "\n",
    "    # Extract and clean module-level functions.\n",
    "    functions = extract_functions(sample_code)\n",
    "    # Extract and clean methods within classes.\n",
    "    methods = extract_methods(sample_code)\n",
    "    \n",
    "    classes = extract_classes(sample_code)\n",
    "    # Clean the full document.\n",
    "    full_document = get_clean_document(sample_code)\n",
    "\n",
    "    # Get embeddings for standalone functions.\n",
    "    function_embeddings = {}\n",
    "    for func_name, func_source in functions.items():\n",
    "        embedding = get_graphcodebert_embedding(func_source)\n",
    "        function_embeddings[func_name] = embedding\n",
    "    print(\"Function embeddings:\")\n",
    "    for name in function_embeddings:\n",
    "        print(f\"  {name}: shape {function_embeddings[name].shape}\")\n",
    "        \n",
    "    class_embeddings = {}\n",
    "    for class_name, class_source in classes.items():\n",
    "        embedding = get_graphcodebert_embedding(class_source)\n",
    "        class_embeddings[class_name] = embedding\n",
    "    print(\"\\nClass embeddings:\")\n",
    "    for name in class_embeddings:\n",
    "        print(f\"  {name}: shape {class_embeddings[name].shape}\")\n",
    "\n",
    "    # Get embeddings for class methods.\n",
    "    method_embeddings = {}\n",
    "    for method_name, method_source in methods.items():\n",
    "        embedding = get_graphcodebert_embedding(method_source)\n",
    "        method_embeddings[method_name] = embedding\n",
    "    print(\"\\nMethod embeddings:\")\n",
    "    for name in method_embeddings:\n",
    "        print(f\"  {name}: shape {method_embeddings[name].shape}\")\n",
    "\n",
    "    # Get embedding for full document.\n",
    "    document_embedding = get_graphcodebert_embedding(full_document)\n",
    "    print(f\"\\nDocument embedding shape: {document_embedding.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc08272a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AttnGAN__Fine-Grained_Text_to_Image_Generation_with_Attentional_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AttnGAN__Fine-Grained_Text_to_Image_Generation_with_Attentional_Generative_Adversarial_Networks/model.py'],\n",
       " 'StackGAN____Realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StackGAN____Realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StackGAN____Realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks/code/model.py'],\n",
       " 'Online_Deep_Learning__Learning_Deep_Neural_Networks_on_the_Fly': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Online_Deep_Learning__Learning_Deep_Neural_Networks_on_the_Fly/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Online_Deep_Learning__Learning_Deep_Neural_Networks_on_the_Fly/src/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Online_Deep_Learning__Learning_Deep_Neural_Networks_on_the_Fly/src/hbp/model.py'],\n",
       " 'Real-Time_Single_Image_and_Video_Super-Resolution_Using_an_Efficient_Sub-Pixel_Convolutional_Neural_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Real-Time_Single_Image_and_Video_Super-Resolution_Using_an_Efficient_Sub-Pixel_Convolutional_Neural_Network/model.py'],\n",
       " 'CNN_CNN__Convolutional_Decoders_for_Image_Captioning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CNN_CNN__Convolutional_Decoders_for_Image_Captioning/models/model.py'],\n",
       " 'Deep_Residual_Learning_for_Image_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Residual_Learning_for_Image_Recognition/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Residual_Learning_for_Image_Recognition/erfnet/src/model.py'],\n",
       " 'U-Net__Convolutional_Networks_for_Biomedical_Image_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/U-Net__Convolutional_Networks_for_Biomedical_Image_Segmentation/UNet/model.py'],\n",
       " 'Deep_Video_Deblurring': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Video_Deblurring/model.py'],\n",
       " 'Sampling_Generative_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sampling_Generative_Networks/model.py'],\n",
       " 'Atlas__End-to-End_3D_Scene_Reconstruction_from_Posed_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Atlas__End-to-End_3D_Scene_Reconstruction_from_Posed_Images/atlas/model.py'],\n",
       " 'NimbRo-OP2X__Adult-sized_Open-source_3D_Printed_Humanoid_Robot': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NimbRo-OP2X__Adult-sized_Open-source_3D_Printed_Humanoid_Robot/model.py'],\n",
       " 'CatBoost__unbiased_boosting_with_categorical_features': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_no_cat_features_CPU-2__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_no_cat_features_CPU-40__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_with_cat_features_CPU-2__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_with_cat_features_CPU-40__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_with_cat_features_from_pandas_CPU__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_no_cat_features_CPU-2__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_no_cat_features_CPU-40__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_with_cat_features_CPU-2__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_with_cat_features_CPU-40__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_with_cat_features_from_pandas_CPU__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/gpu/canondata/test.test_export_to_python_no_cat_features_GPU-2_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/gpu/canondata/test.test_export_to_python_no_cat_features_GPU-40_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/gpu/canondata/test.test_export_to_python_with_cat_features_GPU-2_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/gpu/canondata/test.test_export_to_python_with_cat_features_GPU-40_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_no_cat_features_CPU-2_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_no_cat_features_CPU-40_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_with_cat_features_CPU-2_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_with_cat_features_CPU-40_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_with_cat_features_from_pandas_CPU_/model.py'],\n",
       " 'If_You_Like_It__GAN_It__Probabilistic_Multivariate_Times_Series_Forecast_With_GAN': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/If_You_Like_It__GAN_It__Probabilistic_Multivariate_Times_Series_Forecast_With_GAN/probcast_tensorflow/model.py'],\n",
       " 'Unpaired_Image-to-Image_Translation_using_Cycle-Consistent_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unpaired_Image-to-Image_Translation_using_Cycle-Consistent_Adversarial_Networks/model.py'],\n",
       " 'Attention_Is_All_You_Need': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Attention_Is_All_You_Need/torchnlp/common/model.py'],\n",
       " 'Learning_2D-3D_Correspondences_To_Solve_The_Blind_Perspective-n-Point_Problem': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_2D-3D_Correspondences_To_Solve_The_Blind_Perspective-n-Point_Problem/model/model.py'],\n",
       " 'DARTS__Differentiable_Architecture_Search': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DARTS__Differentiable_Architecture_Search/cnn/model.py'],\n",
       " 'Sequential_Attend__Infer__Repeat__Generative_Modelling_of_Moving_Objects': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sequential_Attend__Infer__Repeat__Generative_Modelling_of_Moving_Objects/sqair/model.py'],\n",
       " 'End-to-end_Sequence_Labeling_via_Bi-directional_LSTM-CNNs-CRF': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/End-to-end_Sequence_Labeling_via_Bi-directional_LSTM-CNNs-CRF/model.py'],\n",
       " 'Generating_Adversarial_Computer_Programs_using_Optimized_Obfuscations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generating_Adversarial_Computer_Programs_using_Optimized_Obfuscations/models/code2seq-merged/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generating_Adversarial_Computer_Programs_using_Optimized_Obfuscations/models/code2seq-targeting/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generating_Adversarial_Computer_Programs_using_Optimized_Obfuscations/models/code2seq/model.py'],\n",
       " 'Self-Attentive_Sequential_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Self-Attentive_Sequential_Recommendation/model.py'],\n",
       " 'Shape_Robust_Text_Detection_with_Progressive_Scale_Expansion_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Shape_Robust_Text_Detection_with_Progressive_Scale_Expansion_Network/nets/model.py'],\n",
       " 'CapsGAN__Using_Dynamic_Routing_for_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CapsGAN__Using_Dynamic_Routing_for_Generative_Adversarial_Networks/capsule_dcgan_mnist/model.py'],\n",
       " 'Sparse_Label_Smoothing_Regularization_for_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sparse_Label_Smoothing_Regularization_for_Person_Re-Identification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sparse_Label_Smoothing_Regularization_for_Person_Re-Identification/DCGAN/model.py'],\n",
       " 'Efficient_Attention_Mechanism_for_Visual_Dialog_that_can_Handle_All_the_Interactions_between_Multiple_Inputs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Efficient_Attention_Mechanism_for_Visual_Dialog_that_can_Handle_All_the_Interactions_between_Multiple_Inputs/visdial/model.py'],\n",
       " 'Layered_Embeddings_for_Amodal_Instance_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Layered_Embeddings_for_Amodal_Instance_Segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Layered_Embeddings_for_Amodal_Instance_Segmentation/mrcnn/model.py'],\n",
       " 'Mask_R-CNN': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mask_R-CNN/proofOfConcept/mask-rcnn/mrcnn/model.py'],\n",
       " 'Conditional_Generative_Adversarial_Nets': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Conditional_Generative_Adversarial_Nets/mnist/model.py'],\n",
       " 'AFS__An_Attention-based_mechanism_for_Supervised_Feature_Selection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AFS__An_Attention-based_mechanism_for_Supervised_Feature_Selection/model.py'],\n",
       " 'The_Numerics_of_GANs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Numerics_of_GANs/ConsensusOptimization/CoinGame/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Numerics_of_GANs/ConsensusOptimization/GAN/model.py'],\n",
       " 'Semantic_Understanding_of_Scenes_through_the_ADE20K_Dataset': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Understanding_of_Scenes_through_the_ADE20K_Dataset/model.py'],\n",
       " 'Towards_Stable_and_Efficient_Training_of_Verifiably_Robust_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Stable_and_Efficient_Training_of_Verifiably_Robust_Neural_Networks/interval_bound_propagation/src/model.py'],\n",
       " 'Off_Environment_Evaluation_Using_Convex_Risk_Minimization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Off_Environment_Evaluation_Using_Convex_Risk_Minimization/cartpole/baselines/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Off_Environment_Evaluation_Using_Convex_Risk_Minimization/reacher/baselines/model.py'],\n",
       " 'Gaussian_processes_with_linear_operator_inequality_constraints': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Gaussian_processes_with_linear_operator_inequality_constraints/GPConstr/model.py'],\n",
       " 'SSD-6D__Making_RGB-based_3D_detection_and_6D_pose_estimation_great_again': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SSD-6D__Making_RGB-based_3D_detection_and_6D_pose_estimation_great_again/rendering/model.py'],\n",
       " 'Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/DialogueGCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/DialogueRNN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/ICON-end-to-end/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/ICON/IEMOCAP/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/bc-LSTM-pytorch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/COSMIC/erc-training/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/emotion-cause-extraction/RoBERTa Baseline/simpletransformers/model.py'],\n",
       " 'Improving_Review_Representations_with_User_Attention_and_Product_Attention_for_Sentiment_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Review_Representations_with_User_Attention_and_Product_Attention_for_Sentiment_Classification/HUAPA/code/model.py'],\n",
       " 'Can_Who-Edits-What_Predict_Edit_Survival_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Who-Edits-What_Predict_Edit_Survival_/lib/interank/models/model.py'],\n",
       " 'Convolutional_Gaussian_Processes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Gaussian_Processes/gpflow/models/model.py'],\n",
       " 'emoji2vec__Learning_Emoji_Representations_from_their_Description': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/emoji2vec__Learning_Emoji_Representations_from_their_Description/model.py'],\n",
       " 'Learning_Spatiotemporal_Features_with_3D_Convolutional_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Spatiotemporal_Features_with_3D_Convolutional_Networks/ViolanceDetection-Python/model.py'],\n",
       " 'Augmented_CycleGAN__Learning_Many-to-Many_Mappings_from_Unpaired_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Augmented_CycleGAN__Learning_Many-to-Many_Mappings_from_Unpaired_Data/extra/model.py'],\n",
       " 'Objects_as_Points': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Objects_as_Points/src/lib/models/model.py'],\n",
       " 'Unsupervised_Opinion_Summarization_with_Noising_and_Denoising': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Opinion_Summarization_with_Noising_and_Denoising/src/model.py'],\n",
       " 'End-to-end_speech_enhancement_based_on_discrete_cosine_transform': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/End-to-end_speech_enhancement_based_on_discrete_cosine_transform/model.py'],\n",
       " 'Scene_Text_Detection_with_Supervised_Pyramid_Context_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Scene_Text_Detection_with_Supervised_Pyramid_Context_Network/nets/model.py'],\n",
       " 'MA_3___Model_Agnostic_Adversarial_Augmentation_for_Few_Shot_learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MA_3___Model_Agnostic_Adversarial_Augmentation_for_Few_Shot_learning/prototypical-networks/protonets/utils/model.py'],\n",
       " 'Noise_as_Domain_Shift__Denoising_Medical_Images_by_Unpaired_Image_Translation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Noise_as_Domain_Shift__Denoising_Medical_Images_by_Unpaired_Image_Translation/model.py'],\n",
       " 'Scalable_Hierarchical_Clustering_with_Tree_Grafting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Scalable_Hierarchical_Clustering_with_Tree_Grafting/src/python/grinch/model.py'],\n",
       " 'Physics-informed_neural_networks_for_inverse_problems_in_nano-optics_and_metamaterials': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Physics-informed_neural_networks_for_inverse_problems_in_nano-optics_and_metamaterials/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Physics-informed_neural_networks_for_inverse_problems_in_nano-optics_and_metamaterials/deepxde/zcs/model.py'],\n",
       " 'Convolutional_Neural_Networks_on_non-uniform_geometrical_signals_using_Euclidean_spectral_transformation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Neural_Networks_on_non-uniform_geometrical_signals_using_Euclidean_spectral_transformation/experiments/exp2_mnist/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Neural_Networks_on_non-uniform_geometrical_signals_using_Euclidean_spectral_transformation/experiments/exp3_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Neural_Networks_on_non-uniform_geometrical_signals_using_Euclidean_spectral_transformation/experiments/exp4_3drecon/model.py'],\n",
       " 'Benchmarking_TinyML_Systems__Challenges_and_Direction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_TinyML_Systems__Challenges_and_Direction/benchmark/experimental/training_torch/image_classification/utils/model.py'],\n",
       " 'Depth_from_Videos_in_the_Wild__Unsupervised_Monocular_Depth_Learning_from_Unknown_Cameras': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_from_Videos_in_the_Wild__Unsupervised_Monocular_Depth_Learning_from_Unknown_Cameras/model.py'],\n",
       " 'Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/beit2/vqkd_teacher/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/open_clip/src/open_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/GAD/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/GAD/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/GAD/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/GAD/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/IAD/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/IAD/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/IAD/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/IAD/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/infoxlm/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/infoxlm/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/xdoc/fine_tuning/funsd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/xdoc/fine_tuning/websrc/model.py'],\n",
       " 'Deep_Learning_Based_Text_Classification__A_Comprehensive_Review': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/DBNet/src/modules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/luke/src/relation_classification/model.py'],\n",
       " 'Hide_and_Speak__Towards_Deep_Neural_Networks_for_Speech_Steganography': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hide_and_Speak__Towards_Deep_Neural_Networks_for_Speech_Steganography/model.py'],\n",
       " 'LightGCN__Simplifying_and_Powering_Graph_Convolution_Network_for_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LightGCN__Simplifying_and_Powering_Graph_Convolution_Network_for_Recommendation/code/model.py'],\n",
       " 'Multi-View_Attention_Network_for_Visual_Dialog': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-View_Attention_Network_for_Visual_Dialog/visdial/model.py'],\n",
       " 'EAST__An_Efficient_and_Accurate_Scene_Text_Detector': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EAST__An_Efficient_and_Accurate_Scene_Text_Detector/model.py'],\n",
       " 'Semantic_Instance_Segmentation_with_a_Discriminative_Loss_Function': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Instance_Segmentation_with_a_Discriminative_Loss_Function/code/lib/model.py'],\n",
       " 'Environmental_Sound_Classification_on_Microcontrollers_using_Convolutional_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Environmental_Sound_Classification_on_Microcontrollers_using_Convolutional_Neural_Networks/model.py'],\n",
       " 'World_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/World_Models/model.py'],\n",
       " 'Learning_to_do_multiframe_wavefront_sensing_unsupervisedly__applications_to_blind_deconvolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_do_multiframe_wavefront_sensing_unsupervisedly__applications_to_blind_deconvolution/model.py'],\n",
       " 'The_Devil_is_in_the_Decoder__Classification__Regression_and_GANs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Devil_is_in_the_Decoder__Classification__Regression_and_GANs/model.py'],\n",
       " 'CodeSearchNet_Challenge__Evaluating_the_State_of_Semantic_Code_Search': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CodeSearchNet_Challenge__Evaluating_the_State_of_Semantic_Code_Search/codenets/codesearchnet/query_1_code_1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CodeSearchNet_Challenge__Evaluating_the_State_of_Semantic_Code_Search/codenets/codesearchnet/query_1_code_n/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CodeSearchNet_Challenge__Evaluating_the_State_of_Semantic_Code_Search/codenets/codesearchnet/query_code_siamese/model.py'],\n",
       " 'Time_Window_Temporal_Logic': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Time_Window_Temporal_Logic/src/lomap/classes/model.py'],\n",
       " 'Proximal_Mapping_for_Deep_Regularization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Proximal_Mapping_for_Deep_Regularization/img_classify/model.py'],\n",
       " 'DDSL__Deep_Differentiable_Simplex_Layer_for_Learning_Geometric_Signals': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDSL__Deep_Differentiable_Simplex_Layer_for_Learning_Geometric_Signals/experiments/exp2_mnist/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDSL__Deep_Differentiable_Simplex_Layer_for_Learning_Geometric_Signals/experiments/exp3_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDSL__Deep_Differentiable_Simplex_Layer_for_Learning_Geometric_Signals/experiments/exp4_3drecon/model.py'],\n",
       " 'VCWE__Visual_Character-Enhanced_Word_Embeddings': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VCWE__Visual_Character-Enhanced_Word_Embeddings/model.py'],\n",
       " 'Detecting_and_Reducing_Bias_in_a_High_Stakes_Domain': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_and_Reducing_Bias_in_a_High_Stakes_Domain/src/model.py'],\n",
       " 'Data-efficient_Neural_Text_Compression_with_Interactive_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Data-efficient_Neural_Text_Compression_with_Interactive_Learning/onmt/models/model.py'],\n",
       " 'DreamCoder__Growing_generalizable__interpretable_knowledge_with_wake-sleep_Bayesian_program_learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DreamCoder__Growing_generalizable__interpretable_knowledge_with_wake-sleep_Bayesian_program_learning/prototypical-networks/protonets/utils/model.py'],\n",
       " 'Densely_Connected_Convolutional_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Style_Transfer_from_Non-Parallel_Text_by_Cross-Alignment': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Style_Transfer_from_Non-Parallel_Text_by_Cross-Alignment/code-pytorch/model.py'],\n",
       " 'Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/mxnet/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/mxnet/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/capsule/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/dgmg/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/han/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/metapath2vec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/pointcloud/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/rgcn-hetero/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/tensorflow/rgcn/model.py'],\n",
       " 'ComGAN__Toward_GANs_Exploiting_Multiple_Samples': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ComGAN__Toward_GANs_Exploiting_Multiple_Samples/src/models/model.py'],\n",
       " 'A_comprehensive_and_fair_comparison_of_two_neural_operators__with_practical_extensions__based_on_FAIR_data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_comprehensive_and_fair_comparison_of_two_neural_operators__with_practical_extensions__based_on_FAIR_data/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_comprehensive_and_fair_comparison_of_two_neural_operators__with_practical_extensions__based_on_FAIR_data/deepxde/zcs/model.py'],\n",
       " 'Learning_non-Markovian_Decision-Making_from_State-only_Sequences': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_non-Markovian_Decision-Making_from_State-only_Sequences/mujoco/model.py'],\n",
       " 'Delayed_interactions_in_the_noisy_voter_model_through_the_periodic_polling_mechanism': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Delayed_interactions_in_the_noisy_voter_model_through_the_periodic_polling_mechanism/gillespie_sim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Delayed_interactions_in_the_noisy_voter_model_through_the_periodic_polling_mechanism/macro_sim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Delayed_interactions_in_the_noisy_voter_model_through_the_periodic_polling_mechanism/mc_sim/model.py'],\n",
       " 'ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning/RLLG/agents/common/model.py'],\n",
       " 'DeepMPCVS__Deep_Model_Predictive_Control_for_Visual_Servoing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepMPCVS__Deep_Model_Predictive_Control_for_Visual_Servoing/model.py'],\n",
       " 'Arbitrary-Oriented_Ship_Detection_through_Center-Head_Point_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Arbitrary-Oriented_Ship_Detection_through_Center-Head_Point_Extraction/src/lib/models/model.py'],\n",
       " 'Learning_Off-By-One_Mistakes__An_Empirical_Study': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Off-By-One_Mistakes__An_Empirical_Study/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Off-By-One_Mistakes__An_Empirical_Study/bugram/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Off-By-One_Mistakes__An_Empirical_Study/code2seq/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Off-By-One_Mistakes__An_Empirical_Study/offside-webpage/backend/model.py'],\n",
       " 'DAG-based_Scheduling_with_Resource_Sharing_for_Multi-task_Applications_in_a_Polyglot_GPU_Runtime': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAG-based_Scheduling_with_Resource_Sharing_for_Multi-task_Applications_in_a_Polyglot_GPU_Runtime/examples/tensorrt/python/model.py'],\n",
       " 'HarDNet__A_Low_Memory_Traffic_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HarDNet__A_Low_Memory_Traffic_Network/models/model.py'],\n",
       " 'End_to_End_Trainable_Active_Contours_via_Differentiable_Rendering': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/End_to_End_Trainable_Active_Contours_via_Differentiable_Rendering/models/model.py'],\n",
       " 'Modality_to_Modality_Translation__An_Adversarial_Representation_Learning_and_Graph_Fusion_Network_for_Multimodal_Fusion': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Modality_to_Modality_Translation__An_Adversarial_Representation_Learning_and_Graph_Fusion_Network_for_Multimodal_Fusion/ARGF/ARGF_context2/model.py'],\n",
       " 'Guided_Collaborative_Training_for_Pixel-wise_Semi-Supervised_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Guided_Collaborative_Training_for_Pixel-wise_Semi-Supervised_Learning/pixelssl/task_template/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Guided_Collaborative_Training_for_Pixel-wise_Semi-Supervised_Learning/task/sseg/model.py'],\n",
       " 'Semi-supervised_semantic_segmentation_needs_strong__varied_perturbations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_semantic_segmentation_needs_strong__varied_perturbations/pixelssl/task_template/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_semantic_segmentation_needs_strong__varied_perturbations/task/sseg/model.py'],\n",
       " 'Semi-Supervised_Semantic_Segmentation_with_Cross-Consistency_Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-Supervised_Semantic_Segmentation_with_Cross-Consistency_Training/pixelssl/task_template/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-Supervised_Semantic_Segmentation_with_Cross-Consistency_Training/task/sseg/model.py'],\n",
       " 'Improving_Language_Understanding_by_Generative_Pre-Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Language_Understanding_by_Generative_Pre-Training/model.py'],\n",
       " 'Adaptive_Hinge_Balance_Loss_for_Document-Level_Relation_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Hinge_Balance_Loss_for_Document-Level_Relation_Extraction/model.py'],\n",
       " 'You_Only_Watch_Once__A_Unified_CNN_Architecture_for_Real-Time_Spatiotemporal_Action_Localization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/You_Only_Watch_Once__A_Unified_CNN_Architecture_for_Real-Time_Spatiotemporal_Action_Localization/applications/T2VLAD/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/You_Only_Watch_Once__A_Unified_CNN_Architecture_for_Real-Time_Spatiotemporal_Action_Localization/applications/VideoTag/models/model.py'],\n",
       " 'Benchmarking_Graph_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/mxnet/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/mxnet/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/capsule/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/dgmg/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/han/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/metapath2vec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/pointcloud/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/rgcn-hetero/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/tensorflow/rgcn/model.py'],\n",
       " 'High_Quality_Monocular_Depth_Estimation_via_Transfer_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High_Quality_Monocular_Depth_Estimation_via_Transfer_Learning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High_Quality_Monocular_Depth_Estimation_via_Transfer_Learning/PyTorch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High_Quality_Monocular_Depth_Estimation_via_Transfer_Learning/Tensorflow/model.py'],\n",
       " 'Deep_Learning_for_Automatic_Pneumonia_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_for_Automatic_Pneumonia_Detection/src/pytorch_retinanet/model.py'],\n",
       " 'Few-shot_Learning_with_Multilingual_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/models/xmod/model.py'],\n",
       " 'VoxelNet__End-to-End_Learning_for_Point_Cloud_Based_3D_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VoxelNet__End-to-End_Learning_for_Point_Cloud_Based_3D_Object_Detection/sem_seg/model.py'],\n",
       " 'PCPNET__Learning_Local_Shape_Properties_from_Raw_Point_Clouds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PCPNET__Learning_Local_Shape_Properties_from_Raw_Point_Clouds/sem_seg/model.py'],\n",
       " 'PointNet__Deep_Learning_on_Point_Sets_for_3D_Classification_and_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PointNet__Deep_Learning_on_Point_Sets_for_3D_Classification_and_Segmentation/sem_seg/model.py'],\n",
       " 'DeepXDE__A_deep_learning_library_for_solving_differential_equations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepXDE__A_deep_learning_library_for_solving_differential_equations/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepXDE__A_deep_learning_library_for_solving_differential_equations/deepxde/zcs/model.py'],\n",
       " 'A_Higher-Order_Semantic_Dependency_Parser': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Higher-Order_Semantic_Dependency_Parser/supar/models/model.py'],\n",
       " 'SC-FEGAN__Face_Editing_Generative_Adversarial_Network_with_User_s_Sketch_and_Color': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SC-FEGAN__Face_Editing_Generative_Adversarial_Network_with_User_s_Sketch_and_Color/model.py'],\n",
       " 'Neural_Architectures_for_Named_Entity_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Neural_Architectures_for_Named_Entity_Recognition/model.py'],\n",
       " 'YOLOv4__Optimal_Speed_and_Accuracy_of_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/YOLOv4__Optimal_Speed_and_Accuracy_of_Object_Detection/deep_sort_pytorch/deep_sort/deep/model.py'],\n",
       " 'A_Deep_Reinforced_Model_for_Abstractive_Summarization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Deep_Reinforced_Model_for_Abstractive_Summarization/model.py'],\n",
       " 'DGTN__Dual-channel_Graph_Transition_Network_for_Session-based_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DGTN__Dual-channel_Graph_Transition_Network_for_Session-based_Recommendation/model/model.py'],\n",
       " 'Learning_Tree-based_Deep_Model_for_Recommender_Systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Tree-based_Deep_Model_for_Recommender_Systems/backend/model.py'],\n",
       " 'Visual_Dialog': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Visual_Dialog/visdialch/model.py'],\n",
       " 'Hierarchical_Neural_Story_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hierarchical_Neural_Story_Generation/storygeneration/model.py'],\n",
       " 'Robust_Robotic_Pouring_using_Audition_and_Haptics': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robust_Robotic_Pouring_using_Audition_and_Haptics/audio_pouring/model/model.py'],\n",
       " 'Semi-supervised_Formality_Style_Transfer_using_Language_Model_Discriminator_and_Mutual_Information_Maximization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_Formality_Style_Transfer_using_Language_Model_Discriminator_and_Mutual_Information_Maximization/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_Formality_Style_Transfer_using_Language_Model_Discriminator_and_Mutual_Information_Maximization/fairseq/models/roberta/model.py'],\n",
       " 'Deep_Reinforcement_Learning_for_Producing_Furniture_Layout_in_Indoor_Scenes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Reinforcement_Learning_for_Producing_Furniture_Layout_in_Indoor_Scenes/code/model.py'],\n",
       " 'Actor-Attention-Critic_for_Multi-Agent_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Actor-Attention-Critic_for_Multi-Agent_Reinforcement_Learning/MAAC/baselines-master/baselines/ppo2/model.py'],\n",
       " 'On_The_Cross-Modal_Transfer_from_Natural_Language_to_Code_through_Adapter_Modules': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_The_Cross-Modal_Transfer_from_Natural_Language_to_Code_through_Adapter_Modules/CodeCloneDetection-BCB/code/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_The_Cross-Modal_Transfer_from_Natural_Language_to_Code_through_Adapter_Modules/CodeCloneDetection-POJ-104/code/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_The_Cross-Modal_Transfer_from_Natural_Language_to_Code_through_Adapter_Modules/CodeCloneDetection-SCD-88/code/model.py'],\n",
       " 'D2-Net__A_Trainable_CNN_for_Joint_Detection_and_Description_of_Local_Features': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/D2-Net__A_Trainable_CNN_for_Joint_Detection_and_Description_of_Local_Features/lib/model.py'],\n",
       " 'Simple_Online_and_Realtime_Tracking_with_a_Deep_Association_Metric': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Simple_Online_and_Realtime_Tracking_with_a_Deep_Association_Metric/deep_sort_pytorch/deep_sort/deep/model.py'],\n",
       " 'Constructing_A_Flexible_Likelihood_Function_For_Spectroscopic_Inference': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Constructing_A_Flexible_Likelihood_Function_For_Spectroscopic_Inference/Starfish/model.py'],\n",
       " 'Assessing_Pattern_Recognition_Performance_of_Neuronal_Cultures_through_Accurate_Simulation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Assessing_Pattern_Recognition_Performance_of_Neuronal_Cultures_through_Accurate_Simulation/model.py'],\n",
       " 'LERF__Language_Embedded_Radiance_Fields': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/lerf/lerf_sr/model.py'],\n",
       " 'Cross-Domain_Sentiment_Classification_with_In-Domain_Contrastive_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cross-Domain_Sentiment_Classification_with_In-Domain_Contrastive_Learning/model.py'],\n",
       " 'L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/ResNet50/image_classification/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/models/xmod/model.py'],\n",
       " 'Social_NCE__Contrastive_Learning_of_Socially-aware_Motion_Representations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Social_NCE__Contrastive_Learning_of_Socially-aware_Motion_Representations/trajectron/snce/model.py'],\n",
       " 'Learning__Planning__and_Control_in_a_Monolithic_Neural_Event_Inference_Architecture': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning__Planning__and_Control_in_a_Monolithic_Neural_Event_Inference_Architecture/tests/model.py'],\n",
       " 'PS_2-Net__A_Locally_and_Globally_Aware_Network_for_Point-Based_Semantic_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PS_2-Net__A_Locally_and_Globally_Aware_Network_for_Point-Based_Semantic_Segmentation/models/model.py'],\n",
       " 'Hierarchical_Attentive_Recurrent_Tracking': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hierarchical_Attentive_Recurrent_Tracking/neurocity/component/model/model.py'],\n",
       " 'Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding/pyabsa/tasks/ABSAInstruction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding/pyabsa/tasks/AspectSentimentTripletExtraction/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding/pyabsa/tasks/UniversalSentimentAnalysis/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding/pyabsa/tasks/__SubtaskTemplate__/models/model.py'],\n",
       " 'Open_Graph_Benchmark__Datasets_for_Machine_Learning_on_Graphs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Open_Graph_Benchmark__Datasets_for_Machine_Learning_on_Graphs/examples/linkproppred/biokg/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Open_Graph_Benchmark__Datasets_for_Machine_Learning_on_Graphs/examples/linkproppred/wikikg2/model.py'],\n",
       " 'Transferable_Adversarial_Attacks_for_Image_and_Video_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transferable_Adversarial_Attacks_for_Image_and_Video_Object_Detection/api/tog/yolov3_utils/model.py'],\n",
       " 'TOG__Targeted_Adversarial_Objectness_Gradient_Attacks_on_Real-time_Object_Detection_Systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TOG__Targeted_Adversarial_Objectness_Gradient_Attacks_on_Real-time_Object_Detection_Systems/api/tog/yolov3_utils/model.py'],\n",
       " 'Deep_Graph_Infomax': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/P-GNN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/arma/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/bgrl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/capsule/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/caregnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/correct_and_smooth/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/dgmg/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/dtgrnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/eges/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/evolveGCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/gas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/geniepath/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/grace/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/grand/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/graphsage/advanced/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/han/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/hgt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/infograph/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/jknet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/labor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/metapath2vec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/node2vec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/pinsage/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/rect/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/rgcn-hetero/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/seal/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/stgcn_wave/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/vgae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/NGCF/NGCF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/mvgrl/graph/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/mvgrl/node/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/ogb/deepwalk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/ogb/line/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/pointcloud/edgeconv/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/core/Graphormer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/mxnet/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/tensorflow/rgcn/model.py'],\n",
       " 'YOLOv3__An_Incremental_Improvement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/YOLOv3__An_Incremental_Improvement/model.py'],\n",
       " 'PINNs_for_the_Solution_of_the_Hyperbolic_Buckley-Leverett_Problem_with_a_Non-convex_Flux_Function': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PINNs_for_the_Solution_of_the_Hyperbolic_Buckley-Leverett_Problem_with_a_Non-convex_Flux_Function/opt/src/fastspeech2_ms/utils/model.py'],\n",
       " 'NeMo_Inverse_Text_Normalization__From_Development_To_Production': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/diffusion/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/diffusion/models/flux/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/diffusion/models/flux_controlnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/llm/distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/multimodal/modules/stable_diffusion/diffusionmodules/model.py'],\n",
       " 'Assessing_the_Reliability_of_Deep_Learning_Classifiers_Through_Robustness_Evaluation_and_Operational_Profiles': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Assessing_the_Reliability_of_Deep_Learning_Classifiers_Through_Robustness_Evaluation_and_Operational_Profiles/model.py'],\n",
       " 'Session-based_Recommendation_with_Graph_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Session-based_Recommendation_with_Graph_Neural_Networks/src/model.py'],\n",
       " 'From_Canonical_Correlation_Analysis_to_Self-supervised_Graph_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/From_Canonical_Correlation_Analysis_to_Self-supervised_Graph_Neural_Networks/model.py'],\n",
       " 'Pointer_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Pointer_Networks/model.py'],\n",
       " 'DefSent__Sentence_Embeddings_using_Definition_Sentences': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DefSent__Sentence_Embeddings_using_Definition_Sentences/defsent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DefSent__Sentence_Embeddings_using_Definition_Sentences/experiments/src/model.py'],\n",
       " 'Going_Beyond_Linear_Transformers_with_Recurrent_Fast_Weight_Programmers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Going_Beyond_Linear_Transformers_with_Recurrent_Fast_Weight_Programmers/algorithmic/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Going_Beyond_Linear_Transformers_with_Recurrent_Fast_Weight_Programmers/reinforcement_learning/torchbeast/model.py'],\n",
       " 'Swin_Transformer__Hierarchical_Vision_Transformer_using_Shifted_Windows': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Swin_Transformer__Hierarchical_Vision_Transformer_using_Shifted_Windows/swintransformer/model.py'],\n",
       " 'Predictive_Modeling_with_Temporal_Graphical_Representation_on_Electronic_Health_Records': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Predictive_Modeling_with_Temporal_Graphical_Representation_on_Electronic_Health_Records/models/Model.py'],\n",
       " 'DAPPLE__A_Pipelined_Data_Parallel_Approach_for_Training_Large_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAPPLE__A_Pipelined_Data_Parallel_Approach_for_Training_Large_Models/bert/models/nmt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAPPLE__A_Pipelined_Data_Parallel_Approach_for_Training_Large_Models/gnmt/nmt/model.py'],\n",
       " 'REAL-M__Towards_Speech_Separation_on_Real_Mixtures': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/REAL-M__Towards_Speech_Separation_on_Real_Mixtures/speechbrain/lobes/models/g2p/model.py'],\n",
       " 'Emerging_Properties_in_Self-Supervised_Vision_Transformers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emerging_Properties_in_Self-Supervised_Vision_Transformers/self_driving_car/ML Agent/model.py'],\n",
       " 'D-VDAMP__Denoising-based_Approximate_Message_Passing_for_Compressive_MRI': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/D-VDAMP__Denoising-based_Approximate_Message_Passing_for_Compressive_MRI/train/model.py'],\n",
       " 'SUREMap__Predicting_Uncertainty_in_CNN-based_Image_Reconstruction_Using_Stein_s_Unbiased_Risk_Estimate': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SUREMap__Predicting_Uncertainty_in_CNN-based_Image_Reconstruction_Using_Stein_s_Unbiased_Risk_Estimate/train/model.py'],\n",
       " 'DeepMIH__Deep_Invertible_Network_for_MultipleImage_Hiding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepMIH__Deep_Invertible_Network_for_MultipleImage_Hiding/model.py'],\n",
       " 'TPS____Attention-Enhanced_Thin-Plate_Spline_for_Scene_Text_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TPS____Attention-Enhanced_Thin-Plate_Spline_for_Scene_Text_Recognition/mmocr/utils/model.py'],\n",
       " 'Transformer_Transducer__A_Streamable_Speech_Recognition_Model_with_Transformer_Encoders_and_RNN-T_Loss': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_Transducer__A_Streamable_Speech_Recognition_Model_with_Transformer_Encoders_and_RNN-T_Loss/transformer_transducer/model.py'],\n",
       " 'Convolutional_Networks_for_Spherical_Signals': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Networks_for_Spherical_Signals/examples/shrec17/model.py'],\n",
       " 'MVTN__Multi-View_Transformation_Network_for_3D_Shape_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MVTN__Multi-View_Transformation_Network_for_3D_Shape_Recognition/viewGCN/model/Model.py'],\n",
       " 'Causal-aware_Safe_Policy_Improvement_for_Task-oriented_dialogue': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Causal-aware_Safe_Policy_Improvement_for_Task-oriented_dialogue/damd_multiwoz/model.py'],\n",
       " 'Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction/model/model.py'],\n",
       " 'MISA__Modality-Invariant_and_-Specific_Representations_for_Multimodal_Sentiment_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MISA__Modality-Invariant_and_-Specific_Representations_for_Multimodal_Sentiment_Analysis/Low-rank-Multimodal-Fusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MISA__Modality-Invariant_and_-Specific_Representations_for_Multimodal_Sentiment_Analysis/TensorFusionNetworks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MISA__Modality-Invariant_and_-Specific_Representations_for_Multimodal_Sentiment_Analysis/contextual-attention-based-LSTM/model.py'],\n",
       " 'Revisiting_Batch_Normalization_for_Training_Low-latency_Deep_Spiking_Neural_Networks_from_Scratch': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Revisiting_Batch_Normalization_for_Training_Low-latency_Deep_Spiking_Neural_Networks_from_Scratch/model.py'],\n",
       " 'An_Empirical_Study_on_Leveraging_Position_Embeddings_for_Target-oriented_Opinion_Words_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/An_Empirical_Study_on_Leveraging_Position_Embeddings_for_Target-oriented_Opinion_Words_Extraction/model.py'],\n",
       " 'Graph_Representation_Learning_via_Aggregation_Enhancement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Graph_Representation_Learning_via_Aggregation_Enhancement/graph_self_supervised_learning/model.py'],\n",
       " 'Complexity-Weighted_Loss_and_Diverse_Reranking_for_Sentence_Simplification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Complexity-Weighted_Loss_and_Diverse_Reranking_for_Sentence_Simplification/new_scripts/predict_sentence_level/CNN-sentence-classification-pytorch-master/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Complexity-Weighted_Loss_and_Diverse_Reranking_for_Sentence_Simplification/sockeye_loss/sockeye/model.py'],\n",
       " 'StackGAN__Text_to_Photo-realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StackGAN__Text_to_Photo-realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks/model.py'],\n",
       " 'Visual_Attention_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Visual_Attention_Network/examples/llama_inference/model.py'],\n",
       " 'Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/beit2/vqkd_teacher/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/open_clip/src/open_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/GAD/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/GAD/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/GAD/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/GAD/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/IAD/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/IAD/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/IAD/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/IAD/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/infoxlm/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/infoxlm/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/xdoc/fine_tuning/funsd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/xdoc/fine_tuning/websrc/model.py'],\n",
       " 'CheXbert__Combining_Automatic_Labelers_and_Expert_Annotations_for_Accurate_Radiology_Report_Labeling_Using_BERT': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CheXbert__Combining_Automatic_Labelers_and_Expert_Annotations_for_Accurate_Radiology_Report_Labeling_Using_BERT/chexpert_approximator/model.py'],\n",
       " 'Bridging_the_Domain_Gap__Self-Supervised_3D_Scene_Understanding_with_Foundation_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridging_the_Domain_Gap__Self-Supervised_3D_Scene_Understanding_with_Foundation_Models/Pretrain/clip/model.py'],\n",
       " 'Get_To_The_Point__Summarization_with_Pointer-Generator_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Get_To_The_Point__Summarization_with_Pointer-Generator_Networks/model.py'],\n",
       " 'StyleIPSB__Identity-Preserving_Semantic_Basis_of_StyleGAN_for_High_Fidelity_Face_Swapping': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StyleIPSB__Identity-Preserving_Semantic_Basis_of_StyleGAN_for_High_Fidelity_Face_Swapping/stylegan2-pytorch/model.py'],\n",
       " 'Modeling_Graphs_with_Vertex_Replacement_Grammars': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Modeling_Graphs_with_Vertex_Replacement_Grammars/src/vog/MDL/model.py'],\n",
       " 'Studying_the_Usage_of_Text-To-Text_Transfer_Transformer_to_Support_Code-Related_Tasks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Studying_the_Usage_of_Text-To-Text_Transfer_Transformer_to_Support_Code-Related_Tasks/NeuralCodeSum/main/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Studying_the_Usage_of_Text-To-Text_Transfer_Transformer_to_Support_Code-Related_Tasks/CodeBERT/code/model.py'],\n",
       " 'Discrete_Representations_Strengthen_Vision_Transformer_Robustness': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Discrete_Representations_Strengthen_Vision_Transformer_Robustness/benchmarks/imagenet-e/ImageNet-Editing/editing_diffusion/CLIP/clip/model.py'],\n",
       " 'PanoFormer__Panorama_Transformer_for_Indoor_360_Depth_Estimation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PanoFormer__Panorama_Transformer_for_Indoor_360_Depth_Estimation/PanoFormer/network/model.py'],\n",
       " 'Unifying_Multimodal_Transformer_for_Bi-directional_Image_and_Text_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unifying_Multimodal_Transformer_for_Bi-directional_Image_and_Text_Generation/it-generator/evaluation/inception_score/model.py'],\n",
       " 'A_Picture_is_Worth_a_Thousand_Words__A_Unified_System_for_Diverse_Captions_and_Rich_Images_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Picture_is_Worth_a_Thousand_Words__A_Unified_System_for_Diverse_Captions_and_Rich_Images_Generation/it-generator/evaluation/inception_score/model.py'],\n",
       " 'EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/applications/MULLM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/paddlemix/models/audioldm2/clap_module/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/paddlemix/models/audioldm2/hifigan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/paddlemix/models/diffsinger/modules/pe/rmvpe/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/adalora/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/ia3/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/loha/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/lokr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/lora/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/mixed/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/multitask_prompt_tuning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/oft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/p_tuning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/prefix_tuning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/prompt_tuning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/PhotoMaker/photomaker/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/consistency_distillation/lcm_trainer/lcm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/controlnet/control/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/ip_adapter/ip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/stable_diffusion/sd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/t2i-adapter/adapter/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/text_to_image_laion400m/ldm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/text_to_image_mscoco_uvit/ldm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/AnimateAnyone/src/trainer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/Open-Sora/trainer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/autoencoder/vae/ldm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/visual_tokenizer/open-magvit2/taming/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/visual_tokenizer/open-magvit2/taming/modules/discriminator/model.py'],\n",
       " 'HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation/RLLG/agents/common/model.py'],\n",
       " 'Dimensional_Emotion_Detection_from_Categorical_Emotion': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dimensional_Emotion_Detection_from_Categorical_Emotion/src/models/model.py'],\n",
       " 'Generalized_Clustering_and_Multi-Manifold_Learning_with_Geometric_Structure_Preservation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generalized_Clustering_and_Multi-Manifold_Learning_with_Geometric_Structure_Preservation/model.py'],\n",
       " 'TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Improving_Inductive_Link_Prediction_Using_Hyper-Relational_Facts': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Inductive_Link_Prediction_Using_Hyper-Relational_Facts/openke/module/model/Model.py'],\n",
       " 'Analysis_of_Training_Object_Detection_Models_with_Synthetic_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Analysis_of_Training_Object_Detection_Models_with_Synthetic_Data/mrcnn/model.py'],\n",
       " 'Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/Contents/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/aecrnet/src/models/model.py'],\n",
       " 'Deep_Learning_Face_Representation_from_Predicting_10_000_Classes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Multifidelity_deep_neural_operators_for_efficient_learning_of_partial_differential_equations_with_application_to_fast_inverse_design_of_nanoscale_heat_transport': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multifidelity_deep_neural_operators_for_efficient_learning_of_partial_differential_equations_with_application_to_fast_inverse_design_of_nanoscale_heat_transport/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multifidelity_deep_neural_operators_for_efficient_learning_of_partial_differential_equations_with_application_to_fast_inverse_design_of_nanoscale_heat_transport/deepxde/zcs/model.py'],\n",
       " 'Enhancing_Unsupervised_Video_Representation_Learning_by_Decoupling_the_Scene_and_the_Motion': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Unsupervised_Video_Representation_Learning_by_Decoupling_the_Scene_and_the_Motion/src/model/model.py'],\n",
       " 'Spatial_Transformer_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial_Transformer_Networks/src/model/model.py'],\n",
       " 'WOOD__Wasserstein-based_Out-of-Distribution_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/WOOD__Wasserstein-based_Out-of-Distribution_Detection/Model.py'],\n",
       " 'Semi-supervised_teacher-student_deep_neural_network_for_materials_discovery': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_teacher-student_deep_neural_network_for_materials_discovery/pu_cgcnn/cgcnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_teacher-student_deep_neural_network_for_materials_discovery/tsdnn/model.py'],\n",
       " 'Meta_Pseudo_Labels': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Meta_Pseudo_Labels/pu_cgcnn/cgcnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Meta_Pseudo_Labels/tsdnn/model.py'],\n",
       " 'Permutation_Equivariant_Graph_Framelets_for_Heterophilous_Graph_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Permutation_Equivariant_Graph_Framelets_for_Heterophilous_Graph_Learning/model.py'],\n",
       " 'LipNet__End-to-End_Sentence-level_Lipreading': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LipNet__End-to-End_Sentence-level_Lipreading/lipnet/model.py'],\n",
       " 'Rethinking_Negative_Pairs_in_Code_Search': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Rethinking_Negative_Pairs_in_Code_Search/GraphCodeBERT/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Rethinking_Negative_Pairs_in_Code_Search/UniXCoder/model.py'],\n",
       " 'A_Framework_for_Interdomain_and_Multioutput_Gaussian_Processes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Framework_for_Interdomain_and_Multioutput_Gaussian_Processes/gpflow/models/model.py'],\n",
       " 'Detecting_Corrupted_Labels_Without_Training_a_Model_to_Predict': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_Corrupted_Labels_Without_Training_a_Model_to_Predict/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_Corrupted_Labels_Without_Training_a_Model_to_Predict/models/model.py'],\n",
       " 'Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Acceleration_of_Federated_Learning_with_Alleviated_Forgetting_in_Local_Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Acceleration_of_Federated_Learning_with_Alleviated_Forgetting_in_Local_Training/FedUtils/models/transformer/model.py'],\n",
       " 'AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation/RLLG/agents/common/model.py'],\n",
       " 'GPT_Understands__Too': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/data_augmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/feature_vectorization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/geep_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/image2text_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/information_extraction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/language_modeling/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/latent_diffusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/machine_reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/open_domain_dialogue/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/sequence_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/sequence_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/sequence_labeling/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/text2image_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/text2video_retrieval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/text_match/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/video2text_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/wukong_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/modelzoo/models/latent_diffusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/SASA/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/xtremeclip/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/agree/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/fashionklip/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/parasum/finetune_for_CNNDM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/parasum/paraphrase_pretraining/model.py'],\n",
       " 'HLT-NUS_SUBMISSION_FOR_2020_NIST_Conversational_Telephone_Speech_SRE': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HLT-NUS_SUBMISSION_FOR_2020_NIST_Conversational_Telephone_Speech_SRE/model.py'],\n",
       " 'Generate_Like_Experts__Multi-Stage_Font_Generation_by_Incorporating_Font_Transfer_Process_into_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generate_Like_Experts__Multi-Stage_Font_Generation_by_Incorporating_Font_Transfer_Process_into_Diffusion_Models/llama/llama/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generate_Like_Experts__Multi-Stage_Font_Generation_by_Incorporating_Font_Transfer_Process_into_Diffusion_Models/llama2/origin_llama/llama/model.py'],\n",
       " 'Automated_Concatenation_of_Embeddings_for_Structured_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Automated_Concatenation_of_Embeddings_for_Structured_Prediction/flair/parser/model.py'],\n",
       " 'Value-Decomposition_Networks_For_Cooperative_Multi-Agent_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Value-Decomposition_Networks_For_Cooperative_Multi-Agent_Learning/smac/examples/rllib/model.py'],\n",
       " 'Deep_Learning_for_the_Matrix_Element_Method': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_for_the_Matrix_Element_Method/src/deepmem/model.py'],\n",
       " 'Temporal_Transductive_Inference_for_Few-Shot_Video_Object_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Transductive_Inference_for_Few-Shot_Video_Object_Segmentation/src/model/model.py'],\n",
       " 'Hierarchical_Matching_and_Reasoning_for_Multi-Query_Image_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hierarchical_Matching_and_Reasoning_for_Multi-Query_Image_Retrieval/model.py'],\n",
       " 'ESRGAN__Enhanced_Super-Resolution_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ESRGAN__Enhanced_Super-Resolution_Generative_Adversarial_Networks/model.py'],\n",
       " 'Measuring_Perceptual_Color_Differences_of_Smartphone_Photographs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Measuring_Perceptual_Color_Differences_of_Smartphone_Photographs/model.py'],\n",
       " 'Data_augmentation_and_multimodal_learning_for_predicting_drug_response_in_patient-derived_xenografts_from_gene_expressions_and_histology_images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Data_augmentation_and_multimodal_learning_for_predicting_drug_response_in_patient-derived_xenografts_from_gene_expressions_and_histology_images/slideflow/segment/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Data_augmentation_and_multimodal_learning_for_predicting_drug_response_in_patient-derived_xenografts_from_gene_expressions_and_histology_images/slideflow/studio/widgets/model.py'],\n",
       " 'GIT__A_Generative_Image-to-text_Transformer_for_Vision_and_Language': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GIT__A_Generative_Image-to-text_Transformer_for_Vision_and_Language/generativeimage2text/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GIT__A_Generative_Image-to-text_Transformer_for_Vision_and_Language/generativeimage2text/layers/CLIP/model.py'],\n",
       " 'Self-Supervised_Modality-Aware_Multiple_Granularity_Pre-Training_for_RGB-Infrared_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Self-Supervised_Modality-Aware_Multiple_Granularity_Pre-Training_for_RGB-Infrared_Person_Re-Identification/AGW/model.py'],\n",
       " 'Enhancing_Hyperspectral_Images_via_Diffusion_Model_and_Group-Autoencoder_Super-resolution_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Hyperspectral_Images_via_Diffusion_Model_and_Group-Autoencoder_Super-resolution_Network/model/model.py'],\n",
       " 'Learning_to_restore_images_degraded_by_atmospheric_turbulence_using_uncertainty': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_restore_images_degraded_by_atmospheric_turbulence_using_uncertainty/model.py'],\n",
       " 'Assessing_differentially_private_deep_learning_with_Membership_Inference': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Assessing_differentially_private_deep_learning_with_Membership_Inference/MIAttack/mia/core/model.py'],\n",
       " 'Show_Me_What_and_Tell_Me_How__Video_Synthesis_via_Multimodal_Conditioning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show_Me_What_and_Tell_Me_How__Video_Synthesis_via_Multimodal_Conditioning/taming/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show_Me_What_and_Tell_Me_How__Video_Synthesis_via_Multimodal_Conditioning/taming/modules/discriminator/model.py'],\n",
       " 'Generative_Sparse_Detection_Networks_for_3D_Single-shot_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generative_Sparse_Detection_Networks_for_3D_Single-shot_Object_Detection/models/model.py'],\n",
       " 'Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance/code/tools/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance/code/tools/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance/code/tools/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance/code/tools/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'MetaFormer_Is_Actually_What_You_Need_for_Vision': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MetaFormer_Is_Actually_What_You_Need_for_Vision/examples/llama_inference/model.py'],\n",
       " 'Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement/fairseq/models/roberta/model.py'],\n",
       " 'Regression_as_Classification__Influence_of_Task_Formulation_on_Neural_Network_Features': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regression_as_Classification__Influence_of_Task_Formulation_on_Neural_Network_Features/src/model.py'],\n",
       " 'SE_3_-Transformers__3D_Roto-Translation_Equivariant_Attention_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SE_3_-Transformers__3D_Roto-Translation_Equivariant_Attention_Networks/DAN-msa/pyErrorPred/model.py'],\n",
       " 'Learning_Generalisable_Omni-Scale_Representations_for_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Generalisable_Omni-Scale_Representations_for_Person_Re-Identification/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Generalisable_Omni-Scale_Representations_for_Person_Re-Identification/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Generalisable_Omni-Scale_Representations_for_Person_Re-Identification/PatchCore/src/model.py'],\n",
       " 'MetaFormer_Baselines_for_Vision': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MetaFormer_Baselines_for_Vision/examples/llama_inference/model.py'],\n",
       " 'Rethinking_Attention_with_Performers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Rethinking_Attention_with_Performers/examples/llama_inference/model.py'],\n",
       " 'Compositional_Attention__Disentangling_Search_and_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Compositional_Attention__Disentangling_Search_and_Retrieval/examples/llama_inference/model.py'],\n",
       " 'Transformers_without_Tears__Improving_the_Normalization_of_Self-Attention': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformers_without_Tears__Improving_the_Normalization_of_Self-Attention/examples/llama_inference/model.py'],\n",
       " 'A_Dual-level_Detection_Method_for_Video_Copy_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_v106/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_v107/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_v115/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_v68/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_vid_score/video/model.py'],\n",
       " 'Inverting_Gradients_--_How_easy_is_it_to_break_privacy_in_federated_learning_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Inverting_Gradients_--_How_easy_is_it_to_break_privacy_in_federated_learning_/src/model.py'],\n",
       " 'Modularity-Aware_Graph_Autoencoders_for_Joint_Community_Detection_and_Link_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Modularity-Aware_Graph_Autoencoders_for_Joint_Community_Detection_and_Link_Prediction/modularity_aware_gae/model.py'],\n",
       " 'Hard_hat_wearing_detection_based_on_head_keypoint_localization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hard_hat_wearing_detection_based_on_head_keypoint_localization/src/model.py'],\n",
       " 'NestE__Modeling_Nested_Relational_Structures_for_Knowledge_Graph_Reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NestE__Modeling_Nested_Relational_Structures_for_Knowledge_Graph_Reasoning/openke/module/model/Model.py'],\n",
       " 'Out-of-Distribution_Generalization_via_Risk_Extrapolation__REx_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Out-of-Distribution_Generalization_via_Risk_Extrapolation__REx_/model/model.py'],\n",
       " 'Strong_Lensing_Source_Reconstruction_Using_Continuous_Neural_Fields': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Strong_Lensing_Source_Reconstruction_Using_Continuous_Neural_Fields/gigalens/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Strong_Lensing_Source_Reconstruction_Using_Continuous_Neural_Fields/gigalens/jax/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Strong_Lensing_Source_Reconstruction_Using_Continuous_Neural_Fields/gigalens/tf/model.py'],\n",
       " 'MusicBERT__Symbolic_Music_Understanding_with_Large-Scale_Pre-Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MusicBERT__Symbolic_Music_Understanding_with_Large-Scale_Pre-Training/musecoco/1-text2attribute_model/model.py'],\n",
       " 'A_General_Contextualized_Rewriting_Framework_for_Text_Summarization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_General_Contextualized_Rewriting_Framework_for_Text_Summarization/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_General_Contextualized_Rewriting_Framework_for_Text_Summarization/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_General_Contextualized_Rewriting_Framework_for_Text_Summarization/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_General_Contextualized_Rewriting_Framework_for_Text_Summarization/fairseq/models/roberta/model.py'],\n",
       " 'Towards_out_of_distribution_generalization_for_problems_in_mechanics': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_out_of_distribution_generalization_for_problems_in_mechanics/model/model.py'],\n",
       " 'Written_Justifications_are_Key_to_Aggregate_Crowdsourced_Forecasts': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Written_Justifications_are_Key_to_Aggregate_Crowdsourced_Forecasts/model.py'],\n",
       " 'Can_Spatiotemporal_3D_CNNs_Retrace_the_History_of_2D_CNNs_and_ImageNet_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Spatiotemporal_3D_CNNs_Retrace_the_History_of_2D_CNNs_and_ImageNet_/model.py'],\n",
       " 'Actionable_and_Interpretable_Fault_Localization_for_Recurring_Failures_in_Online_Service_Systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Actionable_and_Interpretable_Fault_Localization_for_Recurring_Failures_in_Online_Service_Systems/random_walk_failure_instance/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Actionable_and_Interpretable_Fault_Localization_for_Recurring_Failures_in_Online_Service_Systems/random_walk_single_metric/model.py'],\n",
       " 'Multiresolution_Tree_Networks_for_3D_Point_Cloud_Processing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multiresolution_Tree_Networks_for_3D_Point_Cloud_Processing/models/Model.py'],\n",
       " 'Benchmarking_Compositionality_with_Formal_Languages': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Compositionality_with_Formal_Languages/src/model.py'],\n",
       " 'MDMLP__Image_Classification_from_Scratch_on_Small_Datasets_with_MLP': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MDMLP__Image_Classification_from_Scratch_on_Small_Datasets_with_MLP/timm/utils/model.py'],\n",
       " 'Test_Time_Embedding_Normalization_for_Popularity_Bias_Mitigation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Test_Time_Embedding_Normalization_for_Popularity_Bias_Mitigation/model.py'],\n",
       " 'CLIPA-v2__Scaling_CLIP_Training_with_81_1__Zero-shot_ImageNet_Accuracy_within_a___10_000_Budget__An_Extra___4_000_Unlocks_81_8__Accuracy': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLIPA-v2__Scaling_CLIP_Training_with_81_1__Zero-shot_ImageNet_Accuracy_within_a___10_000_Budget__An_Extra___4_000_Unlocks_81_8__Accuracy/clipa_torch/open_clip/model.py'],\n",
       " 'Embarassingly_Simple_Dataset_Distillation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Embarassingly_Simple_Dataset_Distillation/framework/model.py'],\n",
       " 'Improving_RNN_Transducer_Based_ASR_with_Auxiliary_Tasks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_RNN_Transducer_Based_ASR_with_Auxiliary_Tasks/transformer_transducer/model.py'],\n",
       " 'Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/3DViT/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/3DViT_0_layer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/3DViT_1_layer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/3DViT_LWF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/Hengshuang/model.py'],\n",
       " 'More_than_Words__In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/More_than_Words__In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech/utils/model.py'],\n",
       " 'Optimal_Transport_Guided_Unsupervised_Learning_for_Enhancing_low-quality_Retinal_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Optimal_Transport_Guided_Unsupervised_Learning_for_Enhancing_low-quality_Retinal_Images/Cycle-GAN/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Optimal_Transport_Guided_Unsupervised_Learning_for_Enhancing_low-quality_Retinal_Images/OTE-GAN/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Optimal_Transport_Guided_Unsupervised_Learning_for_Enhancing_low-quality_Retinal_Images/OTTGAN/model/model.py'],\n",
       " 'Spikformer__When_Spiking_Neural_Network_Meets_Transformer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spikformer__When_Spiking_Neural_Network_Meets_Transformer/cifar10/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spikformer__When_Spiking_Neural_Network_Meets_Transformer/cifar10dvs/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spikformer__When_Spiking_Neural_Network_Meets_Transformer/imagenet/model.py'],\n",
       " 'SoccerNet-v2__A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_Soccer_Videos': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet-v2__A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_Soccer_Videos/Benchmarks/SoccerNetv2-ReplayGrounding-CALF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet-v2__A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_Soccer_Videos/Benchmarks/SoccerNetv2-ReplayGrounding-CALF_more_negative/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet-v2__A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_Soccer_Videos/Benchmarks/SoccerNetv2-ReplayGrounding-NetVLAD-More-Negative/model.py'],\n",
       " 'SoccerNet_2022_Challenges_Results': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet_2022_Challenges_Results/Benchmarks/SoccerNetv2-ReplayGrounding-CALF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet_2022_Challenges_Results/Benchmarks/SoccerNetv2-ReplayGrounding-CALF_more_negative/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet_2022_Challenges_Results/Benchmarks/SoccerNetv2-ReplayGrounding-NetVLAD-More-Negative/model.py'],\n",
       " 'Learning_Video-independent_Eye_Contact_Segmentation_from_In-the-Wild_Videos': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Video-independent_Eye_Contact_Segmentation_from_In-the-Wild_Videos/models/MSTCN/model.py'],\n",
       " 'OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/rcnn/src/model.py'],\n",
       " 'Improving_Multi-Task_Deep_Neural_Networks_via_Knowledge_Distillation_for_Natural_Language_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multi-Task_Deep_Neural_Networks_via_Knowledge_Distillation_for_Natural_Language_Understanding/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multi-Task_Deep_Neural_Networks_via_Knowledge_Distillation_for_Natural_Language_Understanding/mt_dnn/model.py'],\n",
       " 'On_the_Variance_of_the_Adaptive_Learning_Rate_and_Beyond': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Variance_of_the_Adaptive_Learning_Rate_and_Beyond/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Variance_of_the_Adaptive_Learning_Rate_and_Beyond/mt_dnn/model.py'],\n",
       " 'SMART__Robust_and_Efficient_Fine-Tuning_for_Pre-trained_Natural_Language_Models_through_Principled_Regularized_Optimization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SMART__Robust_and_Efficient_Fine-Tuning_for_Pre-trained_Natural_Language_Models_through_Principled_Regularized_Optimization/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SMART__Robust_and_Efficient_Fine-Tuning_for_Pre-trained_Natural_Language_Models_through_Principled_Regularized_Optimization/mt_dnn/model.py'],\n",
       " 'The_Microsoft_Toolkit_of_Multi-Task_Deep_Neural_Networks_for_Natural_Language_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Microsoft_Toolkit_of_Multi-Task_Deep_Neural_Networks_for_Natural_Language_Understanding/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Microsoft_Toolkit_of_Multi-Task_Deep_Neural_Networks_for_Natural_Language_Understanding/mt_dnn/model.py'],\n",
       " 'Adversarial_Training_for_Large_Neural_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Training_for_Large_Neural_Language_Models/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Training_for_Large_Neural_Language_Models/mt_dnn/model.py'],\n",
       " 'Posterior_Differential_Regularization_with_f-divergence_for_Improving_Model_Robustness': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Posterior_Differential_Regularization_with_f-divergence_for_Improving_Model_Robustness/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Posterior_Differential_Regularization_with_f-divergence_for_Improving_Model_Robustness/mt_dnn/model.py'],\n",
       " 'A_Hybrid_Neural_Network_Model_for_Commonsense_Reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Hybrid_Neural_Network_Model_for_Commonsense_Reasoning/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Hybrid_Neural_Network_Model_for_Commonsense_Reasoning/mt_dnn/model.py'],\n",
       " 'Incorporating_Bias-aware_Margins_into_Contrastive_Loss_for_Collaborative_Filtering': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Incorporating_Bias-aware_Margins_into_Contrastive_Loss_for_Collaborative_Filtering/model.py'],\n",
       " 'MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/tensorflow/contrib/boosted_trees/estimator_batch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/tensorflow/contrib/timeseries/python/timeseries/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/modelzoo/features/adamasync_optimizer/dien/script/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/modelzoo/features/dynamic_dimension_embedding_variable/dien/script/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/modelzoo/features/embedding_variable/dien/script/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/modelzoo/features/multihash_variable/dien/script/model.py'],\n",
       " 'A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/hubert/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/u2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/u2_kaldi/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/u2_st/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/wav2vec2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/wavlm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/t2s/models/starganv2_vc/AuxiliaryASR/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/t2s/models/starganv2_vc/JDCNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/text/models/ernie_crf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/demos/streaming_tts_serving_fastdeploy/streaming_tts_serving/1/model.py'],\n",
       " 'DilatedSegNet__A_Deep_Dilated_Segmentation_Network_for_Polyp_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DilatedSegNet__A_Deep_Dilated_Segmentation_Network_for_Polyp_Segmentation/model.py'],\n",
       " 'Synthetic_Data_Supervised_Salient_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Synthetic_Data_Supervised_Salient_Object_Detection/models/BigGAN/model.py'],\n",
       " 'Multi-Granularity_Cross-Modality_Representation_Learning_for_Named_Entity_Recognition_on_Social_Media': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-Granularity_Cross-Modality_Representation_Learning_for_Named_Entity_Recognition_on_Social_Media/object_detector/mrcnn/model.py'],\n",
       " 'An_Opponent-Aware_Reinforcement_Learning_Method_for_Team-to-Team_Multi-Vehicle_Pursuit_via_Maximizing_Mutual_Information_Indicator': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/An_Opponent-Aware_Reinforcement_Learning_Method_for_Team-to-Team_Multi-Vehicle_Pursuit_via_Maximizing_Mutual_Information_Indicator/Informer-MVP/models/model.py'],\n",
       " 'A_Learned_Representation_For_Artistic_Style': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/gansynth/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/image_stylization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/onsets_frames_transcription/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/piano_genie/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/shared/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/sketch_rnn/model.py'],\n",
       " 'Explaining_heterogeneity_in_medial_entorhinal_cortex_with_task-driven_neural_networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Explaining_heterogeneity_in_medial_entorhinal_cortex_with_task-driven_neural_networks/mec/models/model.py'],\n",
       " 'ET-AL__Entropy-Targeted_Active_Learning_for_Bias_Mitigation_in_Materials_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ET-AL__Entropy-Targeted_Active_Learning_for_Bias_Mitigation_in_Materials_Data/utils/cgcnn/cgcnn/model.py'],\n",
       " 'Hyper-X__A_Unified_Hypernetwork_for_Multi-Task_Multilingual_Transfer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hyper-X__A_Unified_Hypernetwork_for_Multi-Task_Multilingual_Transfer/src/hyperx/model.py'],\n",
       " 'Real-time_Scene_Text_Detection_with_Differentiable_Binarization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Real-time_Scene_Text_Detection_with_Differentiable_Binarization/modules/model.py'],\n",
       " 'Learning_from_Very_Little_Data__On_the_Value_of_Landscape_Analysis_for_Predicting_Software_Project_Health': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_from_Very_Little_Data__On_the_Value_of_Landscape_Analysis_for_Predicting_Software_Project_Health/baselines/nue_framework/src/modeling/model.py'],\n",
       " 'StrongSORT__Make_DeepSORT_Great_Again': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StrongSORT__Make_DeepSORT_Great_Again/AFLink/model.py'],\n",
       " 'ELSR__Extreme_Low-Power_Super_Resolution_Network_For_Mobile_Devices': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELSR__Extreme_Low-Power_Super_Resolution_Network_For_Mobile_Devices/model.py'],\n",
       " 'SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation/ssc_resnet50/src/network/model.py'],\n",
       " 'LU-Net__Invertible_Neural_Networks_Based_on_Matrix_Factorization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LU-Net__Invertible_Neural_Networks_Based_on_Matrix_Factorization/gaussian mixture/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LU-Net__Invertible_Neural_Networks_Based_on_Matrix_Factorization/mnist/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LU-Net__Invertible_Neural_Networks_Based_on_Matrix_Factorization/realnvp/model.py'],\n",
       " 'Real-time_Wireless_ECG-derived_Respiration_Rate_Estimation_Using_an_Autoencoder_with_a_DCT_Layer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Real-time_Wireless_ECG-derived_Respiration_Rate_Estimation_Using_an_Autoencoder_with_a_DCT_Layer/autoencoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Real-time_Wireless_ECG-derived_Respiration_Rate_Estimation_Using_an_Autoencoder_with_a_DCT_Layer/autoencoder_with_dct/model.py'],\n",
       " 'Discovering_Quantum_Circuit_Components_with_Program_Synthesis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Discovering_Quantum_Circuit_Components_with_Program_Synthesis/prototypical-networks/protonets/utils/model.py'],\n",
       " 'FreeNeRF__Improving_Few-shot_Neural_Rendering_with_Free_Frequency_Regularization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FreeNeRF__Improving_Few-shot_Neural_Rendering_with_Free_Frequency_Regularization/DietNeRF-pytorch/CLIP/clip/model.py'],\n",
       " 'BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/trainer/callbacks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/multimodal/llava/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/multimodal/multimodal_simple/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bert/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bert/classifier/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bert/extractive_summarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bert/token_classifier/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bloom/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/btlm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/dpo/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/dpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/esm2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/falcon/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/gemma2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/gpt2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/gpt3/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/gptj/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/jais/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/llama/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/mistral/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/mixtral/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/santacoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/starcoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/t5/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/vision/dit/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/vision/vision_transformer/model.py'],\n",
       " 'Fourier-DeepONet__Fourier-enhanced_deep_operator_networks_for_full_waveform_inversion_with_improved_accuracy__generalizability__and_robustness': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fourier-DeepONet__Fourier-enhanced_deep_operator_networks_for_full_waveform_inversion_with_improved_accuracy__generalizability__and_robustness/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fourier-DeepONet__Fourier-enhanced_deep_operator_networks_for_full_waveform_inversion_with_improved_accuracy__generalizability__and_robustness/deepxde/zcs/model.py'],\n",
       " 'DAM__Deliberation__Abandon_and_Memory_Networks_for_Generating_Detailed_and_Non-repetitive_Responses_in_Visual_Dialogue': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAM__Deliberation__Abandon_and_Memory_Networks_for_Generating_Detailed_and_Non-repetitive_Responses_in_Visual_Dialogue/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAM__Deliberation__Abandon_and_Memory_Networks_for_Generating_Detailed_and_Non-repetitive_Responses_in_Visual_Dialogue/duconv/src/model.py'],\n",
       " 'Deep_Variational_Bayes_Filters__Unsupervised_Learning_of_State_Space_Models_from_Raw_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Variational_Bayes_Filters__Unsupervised_Learning_of_State_Space_Models_from_Raw_Data/model.py'],\n",
       " 'LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/jasper/src/model.py'],\n",
       " 'Shepherding_Slots_to_Objects__Towards_Stable_and_Robust_Object-Centric_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Shepherding_Slots_to_Objects__Towards_Stable_and_Robust_Object-Centric_Learning/model.py'],\n",
       " 'Knowledge_Rumination_for_Pre-trained_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Knowledge_Rumination_for_Pre-trained_Language_Models/commonsense/model.py'],\n",
       " 'QMIX__Monotonic_Value_Function_Factorisation_for_Deep_Multi-Agent_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QMIX__Monotonic_Value_Function_Factorisation_for_Deep_Multi-Agent_Reinforcement_Learning/smac/examples/rllib/model.py'],\n",
       " 'QPLEX__Duplex_Dueling_Multi-Agent_Q-Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QPLEX__Duplex_Dueling_Multi-Agent_Q-Learning/smac/examples/rllib/model.py'],\n",
       " 'MLPerf_Tiny_Benchmark': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MLPerf_Tiny_Benchmark/benchmark/experimental/training_torch/image_classification/utils/model.py'],\n",
       " 'Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement/clip/model.py'],\n",
       " 'Uncertainty_Quantification_on_Clinical_Trial_Outcome_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Uncertainty_Quantification_on_Clinical_Trial_Outcome_Prediction/HINT/model.py'],\n",
       " 'MaPLe__Multi-modal_Prompt_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaPLe__Multi-modal_Prompt_Learning/Dassl.ProGrad.pytorch/dassl/modeling/backbone/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaPLe__Multi-modal_Prompt_Learning/KgCoOp/clip/model.py'],\n",
       " 'Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Enhancing_Reinforcement_Learning_Agents_with_Local_Guides': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Reinforcement_Learning_Agents_with_Local_Guides/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Reinforcement_Learning_Agents_with_Local_Guides/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Reinforcement_Learning_Agents_with_Local_Guides/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Reinforcement_Learning_Agents_with_Local_Guides/RLLG/agents/common/model.py'],\n",
       " 'PAMTRI__Pose-Aware_Multi-Task_Learning_for_Vehicle_Re-Identification_Using_Highly_Randomized_Synthetic_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PAMTRI__Pose-Aware_Multi-Task_Learning_for_Vehicle_Re-Identification_Using_Highly_Randomized_Synthetic_Data/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PAMTRI__Pose-Aware_Multi-Task_Learning_for_Vehicle_Re-Identification_Using_Highly_Randomized_Synthetic_Data/PaDiM/src/model.py'],\n",
       " 'Large_Language_Models_Are_Reasoning_Teachers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Large_Language_Models_Are_Reasoning_Teachers/src/custom/model.py'],\n",
       " 'Adaptive_Graph_Contrastive_Learning_for_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Graph_Contrastive_Learning_for_Recommendation/Model.py'],\n",
       " 'Align_your_Latents__High-Resolution_Video_Synthesis_with_Latent_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Align_your_Latents__High-Resolution_Video_Synthesis_with_Latent_Diffusion_Models/sgm/modules/autoencoding/lpips/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Align_your_Latents__High-Resolution_Video_Synthesis_with_Latent_Diffusion_Models/sgm/modules/diffusionmodules/model.py'],\n",
       " 'Multi-scale_Semantic_Correlation_Mining_for_Visible-Infrared_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-scale_Semantic_Correlation_Mining_for_Visible-Infrared_Person_Re-Identification/model.py'],\n",
       " 'ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/dpkd/transformers/examples/research_projects/fsner/src/fsner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/uprise/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Towards_Robust_Multi-Modal_Reasoning_via_Model_Selection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Robust_Multi-Modal_Reasoning_via_Model_Selection/MS-GQA/code/models/metagl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Robust_Multi-Modal_Reasoning_via_Model_Selection/MS-OKVQA/code/models/metagl/model.py'],\n",
       " 'A_Goal-Driven_Approach_to_Systems_Neuroscience': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Goal-Driven_Approach_to_Systems_Neuroscience/mec/models/model.py'],\n",
       " 'DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/cdp/model.py'],\n",
       " '3D_Indoor_Instance_Segmentation_in_an_Open-World': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/3D_Indoor_Instance_Segmentation_in_an_Open-World/models/model.py'],\n",
       " 'Localized_Symbolic_Knowledge_Distillation_for_Visual_Commonsense_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Localized_Symbolic_Knowledge_Distillation_for_Visual_Commonsense_Models/lavis/common/annotator/openpose/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Localized_Symbolic_Knowledge_Distillation_for_Visual_Commonsense_Models/lavis/models/clip_models/model.py'],\n",
       " 'A_Gaussian_process_based_approach_for_validation_of_multi-variable_measurement_systems__application_to_SAR_measurement_systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Gaussian_process_based_approach_for_validation_of_multi-variable_measurement_systems__application_to_SAR_measurement_systems/src/iec62209/model.py'],\n",
       " 'Texture_Synthesis_Using_Convolutional_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Texture_Synthesis_Using_Convolutional_Neural_Networks/po/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Texture_Synthesis_Using_Convolutional_Neural_Networks/beta/po/model.py'],\n",
       " 'DiffusionEdge__Diffusion_Probabilistic_Model_for_Crisp_Edge_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiffusionEdge__Diffusion_Probabilistic_Model_for_Crisp_Edge_Detection/taming/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiffusionEdge__Diffusion_Probabilistic_Model_for_Crisp_Edge_Detection/taming/modules/discriminator/model.py'],\n",
       " 'UniRec__A_Dual_Enhancement_of_Uniformity_and_Frequency_in_Sequential_Recommendations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UniRec__A_Dual_Enhancement_of_Uniformity_and_Frequency_in_Sequential_Recommendations/UniRec/unirec/models/model.py'],\n",
       " 'HyperFast__Instant_Classification_for_Tabular_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HyperFast__Instant_Classification_for_Tabular_Data/hyperfast/model.py'],\n",
       " 'EarthPT__a_time_series_foundation_model_for_Earth_Observation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EarthPT__a_time_series_foundation_model_for_Earth_Observation/src/model.py'],\n",
       " 'Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation/MovieLens/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation/Taobao/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation/Tianchi/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation/Yelp/model.py'],\n",
       " 'VocaLiST__An_Audio-Visual_Synchronisation_Model_for_Lips_and_Voices': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VocaLiST__An_Audio-Visual_Synchronisation_Model_for_Lips_and_Voices/models/model.py'],\n",
       " 'QuEST__Low-bit_Diffusion_Model_Quantization_via_Efficient_Selective_Finetuning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuEST__Low-bit_Diffusion_Model_Quantization_via_Efficient_Selective_Finetuning/ldm/modules/diffusionmodules/model.py'],\n",
       " 'Radiative_transfer_with_POLARIS__I__Analysis_of_magnetic_fields_through_synthetic_dust_continuum_polarization_measurements': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Radiative_transfer_with_POLARIS__I__Analysis_of_magnetic_fields_through_synthetic_dust_continuum_polarization_measurements/tools/polaris_tools_custom/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Radiative_transfer_with_POLARIS__I__Analysis_of_magnetic_fields_through_synthetic_dust_continuum_polarization_measurements/tools/polaris_tools_modules/model.py'],\n",
       " 'GISTEmbed__Guided_In-sample_Selection_of_Training_Negatives_for_Text_Embedding_Fine-tuning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GISTEmbed__Guided_In-sample_Selection_of_Training_Negatives_for_Text_Embedding_Fine-tuning/gist_embed/trainer/arguments/model.py'],\n",
       " 'One_Embedder__Any_Task__Instruction-Finetuned_Text_Embeddings': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/One_Embedder__Any_Task__Instruction-Finetuned_Text_Embeddings/gist_embed/trainer/arguments/model.py'],\n",
       " 'NextLevelBERT__Masked_Language_Modeling_with_Higher-Level_Representations_for_Long_Documents': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NextLevelBERT__Masked_Language_Modeling_with_Higher-Level_Representations_for_Long_Documents/src/model.py'],\n",
       " 'A_Teacher-Free_Graph_Knowledge_Distillation_Framework_with_Dual_Self-Distillation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Teacher-Free_Graph_Knowledge_Distillation_Framework_with_Dual_Self-Distillation/code/model.py'],\n",
       " 'LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/GNNs/GCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/GNNs/MLP/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/GNNs/MixHop/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/GNNs/SAGE/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/LMs/model.py'],\n",
       " 'First-Pass_Large_Vocabulary_Continuous_Speech_Recognition_using_Bi-Directional_Recurrent_DNNs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/First-Pass_Large_Vocabulary_Continuous_Speech_Recognition_using_Bi-Directional_Recurrent_DNNs/model.py'],\n",
       " 'Accelerating_Geo-distributed_Machine_Learning_with_Network-Aware_Adaptive_Tree_and_Auxiliary_Route': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Geo-distributed_Machine_Learning_with_Network-Aware_Adaptive_Tree_and_Auxiliary_Route/python/mxnet/model.py'],\n",
       " 'Application_of_Neural_Ordinary_Differential_Equations_for_Tokamak_Plasma_Dynamics_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Application_of_Neural_Ordinary_Differential_Equations_for_Tokamak_Plasma_Dynamics_Analysis/src/model.py'],\n",
       " 'Application_of_Neural_Ordinary_Differential_Equations_for_ITER_Burning_Plasma_Dynamics': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Application_of_Neural_Ordinary_Differential_Equations_for_ITER_Burning_Plasma_Dynamics/src/model.py'],\n",
       " 'Safe_Multi-Agent_Reinforcement_Learning_with_Bilevel_Optimization_in_Autonomous_Driving': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Safe_Multi-Agent_Reinforcement_Learning_with_Bilevel_Optimization_in_Autonomous_Driving/bilevel_maddpg/model.py'],\n",
       " 'Resource_Constrained_Semantic_Segmentation_for_Waste_Sorting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Resource_Constrained_Semantic_Segmentation_for_Waste_Sorting/project-WasteSemSeg/model.py'],\n",
       " 'Finetuning_Generative_Large_Language_Models_with_Discrimination_Instructions_for_Knowledge_Graph_Completion': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Finetuning_Generative_Large_Language_Models_with_Discrimination_Instructions_for_Knowledge_Graph_Completion/model.py'],\n",
       " 'QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression/core/CAE/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression/core/PVCAE/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression/core/QCAE/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression/core/VCAE/model.py'],\n",
       " 'MobileNetV4_-_Universal_Models_for_the_Mobile_Ecosystem': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MobileNetV4_-_Universal_Models_for_the_Mobile_Ecosystem/timm/utils/model.py'],\n",
       " 'Transformer_neural_networks_and_quantum_simulators__a_hybrid_approach_for_simulating_strongly_correlated_systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_neural_networks_and_quantum_simulators__a_hybrid_approach_for_simulating_strongly_correlated_systems/src/model.py'],\n",
       " 'Deciphering_Oracle_Bone_Language_with_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deciphering_Oracle_Bone_Language_with_Diffusion_Models/OBS_Diffusion/FontDiffuser/src/model.py'],\n",
       " 'Plug-and-Play_Adaptation_for_Continuously-updated_QA': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Plug-and-Play_Adaptation_for_Continuously-updated_QA/model.py'],\n",
       " 'Understanding_Multi-Granularity_for_Open-Vocabulary_Part_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Understanding_Multi-Granularity_for_Open-Vocabulary_Part_Segmentation/baselines/modeling/transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Understanding_Multi-Granularity_for_Open-Vocabulary_Part_Segmentation/baselines/third_party/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Understanding_Multi-Granularity_for_Open-Vocabulary_Part_Segmentation/open_clip/src/open_clip/model.py'],\n",
       " 'Sign_Language_Sense_Disambiguation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sign_Language_Sense_Disambiguation/signjoey/model.py'],\n",
       " 'Improving_Diffusion_Inverse_Problem_Solving_with_Decoupled_Noise_Annealing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Diffusion_Inverse_Problem_Solving_with_Decoupled_Noise_Annealing/model/ldm/modules/diffusionmodules/model.py'],\n",
       " 'Learning_from_Emergence__A_Study_on_Proactively_Inhibiting_the_Monosemantic_Neurons_of_Artificial_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_from_Emergence__A_Study_on_Proactively_Inhibiting_the_Monosemantic_Neurons_of_Artificial_Neural_Networks/physics/now/models/model.py'],\n",
       " 'Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/dpkd/transformers/examples/research_projects/fsner/src/fsner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/uprise/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Chain-of-Thought_Unfaithfulness_as_Disguised_Accuracy': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Chain-of-Thought_Unfaithfulness_as_Disguised_Accuracy/src/model.py'],\n",
       " 'Language_Models_are_Few-Shot_Learners': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Language_Models_are_Few-Shot_Learners/lm_eval/api/model.py'],\n",
       " 'Gender_Bias_Detection_in_Court_Decisions__A_Brazilian_Case_Study': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Gender_Bias_Detection_in_Court_Decisions__A_Brazilian_Case_Study/exp/model.py'],\n",
       " 'Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'Utilizing_Self-supervised_Representations_for_MOS_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'Explaining_Spectrograms_in_Machine_Learning__A_Study_on_Neural_Networks_for_Speech_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Explaining_Spectrograms_in_Machine_Learning__A_Study_on_Neural_Networks_for_Speech_Classification/ResNet101/model.py'],\n",
       " 'Boosting_Vision-Language_Models_for_Histopathology_Classification__Predict_all_at_once': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Boosting_Vision-Language_Models_for_Histopathology_Classification__Predict_all_at_once/clip/model.py'],\n",
       " 'Modeling_Relational_Data_with_Graph_Convolutional_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Modeling_Relational_Data_with_Graph_Convolutional_Networks/gae/model.py'],\n",
       " 'Learning_to_Generate_Chairs__Tables_and_Cars_with_Convolutional_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_Generate_Chairs__Tables_and_Cars_with_Convolutional_Networks/faces/model.py'],\n",
       " 'ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games/atari/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games/rts/game_CF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games/rts/game_MC/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games/rts/game_TD/model.py'],\n",
       " 'Variational_Graph_Auto-Encoders': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Variational_Graph_Auto-Encoders/gae/model.py'],\n",
       " 'Multi-Level_Contextual_Network_for_Biomedical_Image_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-Level_Contextual_Network_for_Biomedical_Image_Segmentation/model.py'],\n",
       " 'Semantic_Instance_Segmentation_via_Deep_Metric_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Instance_Segmentation_via_Deep_Metric_Learning/model.py'],\n",
       " 'SqueezeNet__AlexNet-level_accuracy_with_50x_fewer_parameters_and__0_5MB_model_size': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SqueezeNet__AlexNet-level_accuracy_with_50x_fewer_parameters_and__0_5MB_model_size/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SqueezeNet__AlexNet-level_accuracy_with_50x_fewer_parameters_and__0_5MB_model_size/patch400/model.py'],\n",
       " 'Recurrent_Neural_Networks_for_Polyphonic_Sound_Event_Detection_in_Real_Life_Recordings': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Neural_Networks_for_Polyphonic_Sound_Event_Detection_in_Real_Life_Recordings/src/tweetynet/model.py'],\n",
       " 'End-to-end_Recovery_of_Human_Shape_and_Pose': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/End-to-end_Recovery_of_Human_Shape_and_Pose/src/model.py'],\n",
       " 'Metadata_Embeddings_for_User_and_Item_Cold-start_Recommendations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metadata_Embeddings_for_User_and_Item_Cold-start_Recommendations/experiments/movielens/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metadata_Embeddings_for_User_and_Item_Cold-start_Recommendations/experiments/stackexchange/model.py'],\n",
       " 'Road_Extraction_by_Deep_Residual_U-Net': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Road_Extraction_by_Deep_Residual_U-Net/patch400/model.py'],\n",
       " 'EmotionFlow__Capture_the_Dialogue_Level_Emotion_Transitions': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EmotionFlow__Capture_the_Dialogue_Level_Emotion_Transitions/model.py'],\n",
       " 'PyTorch-BigGraph__A_Large-scale_Graph_Embedding_System': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyTorch-BigGraph__A_Large-scale_Graph_Embedding_System/torchbiggraph/model.py'],\n",
       " 'Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/deeplab/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/object_detection/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/pcl_rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/vid2depth/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/attention_ocr/python/model.py'],\n",
       " 'Defense_against_Adversarial_Attacks_Using_High-Level_Representation_Guided_Denoiser': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_against_Adversarial_Attacks_Using_High-Level_Representation_Guided_Denoiser/Exps/sample/model.py'],\n",
       " 'A_Multilayer_Convolutional_Encoder-Decoder_Neural_Network_for_Grammatical_Error_Correction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multilayer_Convolutional_Encoder-Decoder_Neural_Network_for_Grammatical_Error_Correction/caption_model/model.py'],\n",
       " 'A_Note_on_the_Inception_Score': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Note_on_the_Inception_Score/mnist/model.py'],\n",
       " 'Multi-view_to_Novel_view__Synthesizing_Novel_Views_with_Self-Learned_Confidence': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-view_to_Novel_view__Synthesizing_Novel_Views_with_Self-Learned_Confidence/model.py'],\n",
       " 'Exploring_Social_Media_for_Early_Detection_of_Depression_in_COVID-19_Patients': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Exploring_Social_Media_for_Early_Detection_of_Depression_in_COVID-19_Patients/model/model.py'],\n",
       " 'Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/deeplab/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/object_detection/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/pcl_rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/vid2depth/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/attention_ocr/python/model.py'],\n",
       " 'Multiagent_Reinforcement_Learning_Based_on_Fusion-Multiactor-Attention-Critic_for_Multiple-Unmanned-Aerial-Vehicle_Navigation_Control': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multiagent_Reinforcement_Learning_Based_on_Fusion-Multiactor-Attention-Critic_for_Multiple-Unmanned-Aerial-Vehicle_Navigation_Control/MAAC/baselines-master/baselines/ppo2/model.py'],\n",
       " 'Weakly_Supervised_Domain_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly_Supervised_Domain_Detection/src/frame/model.py'],\n",
       " 'PYRO-NN__Python_Reconstruction_Operators_in_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PYRO-NN__Python_Reconstruction_Operators_in_Neural_Networks/examples/ct_reconstruction/example_learning_tensorflow/model/model.py'],\n",
       " 'XNAS__Neural_Architecture_Search_with_Expert_Advice': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/XNAS__Neural_Architecture_Search_with_Expert_Advice/model.py'],\n",
       " 'Learning_with_Opponent-Learning_Awareness': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_with_Opponent-Learning_Awareness/ConsensusOptimization/CoinGame/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_with_Opponent-Learning_Awareness/ConsensusOptimization/GAN/model.py'],\n",
       " 'Unite_the_People__Closing_the_Loop_Between_3D_and_2D_Human_Representations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unite_the_People__Closing_the_Loop_Between_3D_and_2D_Human_Representations/src/model.py'],\n",
       " 'UNI-EM__An_Environment_for_Deep_Neural_Network-Based_Automated_Segmentation_of_Neuronal_Electron_Microscopic_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNI-EM__An_Environment_for_Deep_Neural_Network-Based_Automated_Segmentation_of_Neuronal_Electron_Microscopic_Images/segment/_3D_FFN/ffn/ffn/training/model.py'],\n",
       " 'StarGAN__Unified_Generative_Adversarial_Networks_for_Multi-Domain_Image-to-Image_Translation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StarGAN__Unified_Generative_Adversarial_Networks_for_Multi-Domain_Image-to-Image_Translation/model.py'],\n",
       " 'Tighter_Variational_Bounds_are_Not_Necessarily_Better__A_Research_Report_on_Implementation__Ablation_Study__and_Extensions': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tighter_Variational_Bounds_are_Not_Necessarily_Better__A_Research_Report_on_Implementation__Ablation_Study__and_Extensions/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tighter_Variational_Bounds_are_Not_Necessarily_Better__A_Research_Report_on_Implementation__Ablation_Study__and_Extensions/plotting_utils/1_reference_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tighter_Variational_Bounds_are_Not_Necessarily_Better__A_Research_Report_on_Implementation__Ablation_Study__and_Extensions/plotting_utils/2_bigger_model/model.py'],\n",
       " 'Extreme_Memorization_via_Scale_of_Initialization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/cnn_quantization/tf_cnn_benchmarks/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/imp/max/projects/imp/config/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/meta_reward_learning/textworld/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/stacked_capsule_autoencoders/capsules/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/table_rag/agent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/tf3d/instance_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/tf3d/object_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/tf3d/semantic_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/video_timeline_modeling/vtm/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/cache_replacement/policy_learning/cache_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/fairness_teaching/in_progress/rl_a2c/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/graph_embedding/huge/model.py'],\n",
       " 'The_effects_of_regularisation_on_RNN_models_for_time_series_forecasting__Covid-19_as_an_example': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_effects_of_regularisation_on_RNN_models_for_time_series_forecasting__Covid-19_as_an_example/COVID-19/model.py'],\n",
       " 'fPINNs__Fractional_Physics-Informed_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/fPINNs__Fractional_Physics-Informed_Neural_Networks/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/fPINNs__Fractional_Physics-Informed_Neural_Networks/deepxde/zcs/model.py'],\n",
       " 'HandAugment__A_Simple_Data_Augmentation_Method_for_Depth-Based_3D_Hand_Pose_Estimation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HandAugment__A_Simple_Data_Augmentation_Method_for_Depth-Based_3D_Hand_Pose_Estimation/model/efficientnet_pytorch/model.py'],\n",
       " 'Are_We_Falling_in_a_Middle-Intelligence_Trap__An_Analysis_and_Mitigation_of_the_Reversal_Curse': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Are_We_Falling_in_a_Middle-Intelligence_Trap__An_Analysis_and_Mitigation_of_the_Reversal_Curse/transformers/examples/research_projects/fsner/src/fsner/model.py'],\n",
       " 'EEG-GAN__Generative_adversarial_networks_for_electroencephalograhic__EEG__brain_signals': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EEG-GAN__Generative_adversarial_networks_for_electroencephalograhic__EEG__brain_signals/GAN/eeggan/examples/conv_lin/model.py'],\n",
       " 'Imprints_of_cosmological_tensions_in_reconstructed_gravity': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Imprints_of_cosmological_tensions_in_reconstructed_gravity/camb/camb/model.py'],\n",
       " 'Dual_Path_Multi-Scale_Fusion_Networks_with_Attention_for_Crowd_Counting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Multi-Scale_Fusion_Networks_with_Attention_for_Crowd_Counting/model.py'],\n",
       " 'A_Multigrid_Method_for_Efficiently_Training_Video_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multigrid_Method_for_Efficiently_Training_Video_Models/train/model.py'],\n",
       " 'Probabilistic_Logic_Neural_Networks_for_Reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Probabilistic_Logic_Neural_Networks_for_Reasoning/kge/model.py'],\n",
       " 'Iterative_Projection_and_Matching__Finding_Structure-preserving_Representatives_and_Its_Application_to_Computer_Vision': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Iterative_Projection_and_Matching__Finding_Structure-preserving_Representatives_and_Its_Application_to_Computer_Vision/model.py'],\n",
       " 'Deep_Speech__Scaling_up_end-to-end_speech_recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Speech__Scaling_up_end-to-end_speech_recognition/src/deepspeech/models/model.py'],\n",
       " 'Adversarial_Color_Enhancement__Generating_Unrestricted_Adversarial_Images_by_Optimizing_a_Color_Filter': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Color_Enhancement__Generating_Unrestricted_Adversarial_Images_by_Optimizing_a_Color_Filter/Journal_version/AdvTrain_ACE/src/model/model.py'],\n",
       " 'Attribute-based_Regularization_of_Latent_Spaces_for_Variational_Auto-Encoders': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Attribute-based_Regularization_of_Latent_Spaces_for_Variational_Auto-Encoders/utils/model.py'],\n",
       " 'Detecting_Oriented_Text_in_Natural_Images_by_Linking_Segments': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_Oriented_Text_in_Natural_Images_by_Linking_Segments/seglink/model.py'],\n",
       " 'Enabling_more_efficient_and_cost-effective_AI_ML_systems_with_Collective_Mind__virtualized_MLOps__MLPerf__Collective_Knowledge_Playground_and_reproducible_optimization_tournaments': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enabling_more_efficient_and_cost-effective_AI_ML_systems_with_Collective_Mind__virtualized_MLOps__MLPerf__Collective_Knowledge_Playground_and_reproducible_optimization_tournaments/cm-mlops/script/app-loadgen-generic-python/src/loadgen/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enabling_more_efficient_and_cost-effective_AI_ML_systems_with_Collective_Mind__virtualized_MLOps__MLPerf__Collective_Knowledge_Playground_and_reproducible_optimization_tournaments/cmx4mlops/cmx4mlops/repo/script/app-loadgen-generic-python/src/loadgen/model.py'],\n",
       " 'DiffBlender__Scalable_and_Composable_Multimodal_Text-to-Image_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiffBlender__Scalable_and_Composable_Multimodal_Text-to-Image_Diffusion_Models/ldm/modules/diffusionmodules/model.py'],\n",
       " 'CAT-Seg__Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CAT-Seg__Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation/cat_seg/modeling/transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CAT-Seg__Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation/cat_seg/third_party/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CAT-Seg__Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation/open_clip/src/open_clip/model.py'],\n",
       " 'Crowd-Powered_Photo_Enhancement_Featuring_an_Active_Learning_Based_Local_Filter': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Crowd-Powered_Photo_Enhancement_Featuring_an_Active_Learning_Based_Local_Filter/NBNet/model.py'],\n",
       " 'DiffTalk__Crafting_Diffusion_Models_for_Generalized_Audio-Driven_Portraits_Animation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiffTalk__Crafting_Diffusion_Models_for_Generalized_Audio-Driven_Portraits_Animation/ldm/modules/diffusionmodules/model.py'],\n",
       " 'Hiera__A_Hierarchical_Vision_Transformer_without_the_Bells-and-Whistles': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hiera__A_Hierarchical_Vision_Transformer_without_the_Bells-and-Whistles/timm/utils/model.py'],\n",
       " 'Class-Adaptive_Self-Training_for_Relation_Extraction_with_Incompletely_Annotated_Training_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Class-Adaptive_Self-Training_for_Relation_Extraction_with_Incompletely_Annotated_Training_Data/model.py'],\n",
       " 'Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation/RLLG/agents/common/model.py'],\n",
       " 'Effects_of_Safety_State_Augmentation_on_Safe_Exploration': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Effects_of_Safety_State_Augmentation_on_Safe_Exploration/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Effects_of_Safety_State_Augmentation_on_Safe_Exploration/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Effects_of_Safety_State_Augmentation_on_Safe_Exploration/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Effects_of_Safety_State_Augmentation_on_Safe_Exploration/RLLG/agents/common/model.py'],\n",
       " 'Maximum_diffusion_reinforcement_learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Maximum_diffusion_reinforcement_learning/mpc_lib/model.py'],\n",
       " 'Recurrent_Back-Projection_Network_for_Video_Super-Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Back-Projection_Network_for_Video_Super-Resolution/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Back-Projection_Network_for_Video_Super-Resolution/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Back-Projection_Network_for_Video_Super-Resolution/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Back-Projection_Network_for_Video_Super-Resolution/ras/src/model.py'],\n",
       " 'Boosting_Feedback_Efficiency_of_Interactive_Reinforcement_Learning_by_Adaptive_Learning_from_Scores': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Boosting_Feedback_Efficiency_of_Interactive_Reinforcement_Learning_by_Adaptive_Learning_from_Scores/model.py'],\n",
       " 'Scene-centric_vs__Object-centric_Image-Text_Cross-modal_Retrieval__A_Reproducibility_Study': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Scene-centric_vs__Object-centric_Image-Text_Cross-modal_Retrieval__A_Reproducibility_Study/CLIP/src/model.py'],\n",
       " 'Interleaving_GANs_with_knowledge_graphs_to_support_design_creativity_for_book_covers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Interleaving_GANs_with_knowledge_graphs_to_support_design_creativity_for_book_covers/model.py'],\n",
       " 'GOES_GLM__Biased_Bolides__and_Debiased_Distributions': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GOES_GLM__Biased_Bolides__and_Debiased_Distributions/model.py'],\n",
       " 'GPL__Generative_Pseudo_Labeling_for_Unsupervised_Domain_Adaptation_of_Dense_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPL__Generative_Pseudo_Labeling_for_Unsupervised_Domain_Adaptation_of_Dense_Retrieval/income/bpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPL__Generative_Pseudo_Labeling_for_Unsupervised_Domain_Adaptation_of_Dense_Retrieval/income/bpr/gpl/model.py'],\n",
       " 'Unsupervised_Dense_Information_Retrieval_with_Contrastive_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Dense_Information_Retrieval_with_Contrastive_Learning/income/bpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Dense_Information_Retrieval_with_Contrastive_Learning/income/bpr/gpl/model.py'],\n",
       " 'Efficiently_Teaching_an_Effective_Dense_Retriever_with_Balanced_Topic_Aware_Sampling': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Efficiently_Teaching_an_Effective_Dense_Retriever_with_Balanced_Topic_Aware_Sampling/income/bpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Efficiently_Teaching_an_Effective_Dense_Retriever_with_Balanced_Topic_Aware_Sampling/income/bpr/gpl/model.py'],\n",
       " 'Injecting_Domain_Adaptation_with_Learning-to-hash_for_Effective_and_Efficient_Zero-shot_Dense_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Injecting_Domain_Adaptation_with_Learning-to-hash_for_Effective_and_Efficient_Zero-shot_Dense_Retrieval/income/bpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Injecting_Domain_Adaptation_with_Learning-to-hash_for_Effective_and_Efficient_Zero-shot_Dense_Retrieval/income/bpr/gpl/model.py'],\n",
       " 'CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages/classla/models/depparse/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages/classla/models/ner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages/classla/models/pos/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages/classla/models/srl/model.py'],\n",
       " 'MatchXML__An_Efficient_Text-label_Matching_Framework_for_Extreme_Multi-label_Text_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MatchXML__An_Efficient_Text-label_Matching_Framework_for_Extreme_Multi-label_Text_Classification/model.py'],\n",
       " 'Adversarial_Erasing_with_Pruned_Elements__Towards_Better_Graph_Lottery_Ticket': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Erasing_with_Pruned_Elements__Towards_Better_Graph_Lottery_Ticket/large_scale/ogbn_arxiv/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Erasing_with_Pruned_Elements__Towards_Better_Graph_Lottery_Ticket/large_scale/ogbn_proteins/model.py'],\n",
       " 'CenterNet___for_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/cdp/model.py'],\n",
       " 'FLEE-GNN__A_Federated_Learning_System_for_Edge-Enhanced_Graph_Neural_Network_in_Analyzing_Geospatial_Resilience_of_Multicommodity_Food_Flows': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FLEE-GNN__A_Federated_Learning_System_for_Edge-Enhanced_Graph_Neural_Network_in_Analyzing_Geospatial_Resilience_of_Multicommodity_Food_Flows/scripts/model.py'],\n",
       " 'XVir__A_Transformer-Based_Architecture_for_Identifying_Viral_Reads_from_Cancer_Samples': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/XVir__A_Transformer-Based_Architecture_for_Identifying_Viral_Reads_from_Cancer_Samples/model.py'],\n",
       " 'Style-Based_Global_Appearance_Flow_for_Virtual_Try-On': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Style-Based_Global_Appearance_Flow_for_Virtual_Try-On/exp/runtime/ViTPose/models/model.py'],\n",
       " 'Parser-Free_Virtual_Try-on_via_Distilling_Appearance_Flows': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Parser-Free_Virtual_Try-on_via_Distilling_Appearance_Flows/exp/runtime/ViTPose/models/model.py'],\n",
       " 'Adaptive_Path-Memory_Network_for_Temporal_Knowledge_Graph_Reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Path-Memory_Network_for_Temporal_Knowledge_Graph_Reasoning/src/model.py'],\n",
       " 'Fast_Texture_Synthesis_via_Pseudo_Optimizer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fast_Texture_Synthesis_via_Pseudo_Optimizer/po/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fast_Texture_Synthesis_via_Pseudo_Optimizer/beta/po/model.py'],\n",
       " 'Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_Few-Shot_Model_Adaption': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_Few-Shot_Model_Adaption/clip/model.py'],\n",
       " 'Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/EigenTrajectory/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/agentformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/gpgraphsgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/gpgraphstgcnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/graphtern/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/implicit/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/lbebm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/pecnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/sgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/stgcnn/model.py'],\n",
       " 'HetuMoE__An_Efficient_Trillion-scale_Mixture-of-Expert_Distributed_Training_System': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HetuMoE__An_Efficient_Trillion-scale_Mixture-of-Expert_Distributed_Training_System/python/hetu/peft/lora/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HetuMoE__An_Efficient_Trillion-scale_Mixture-of-Expert_Distributed_Training_System/hetu/v1/examples/gnn/gnn_model/model.py'],\n",
       " 'Learning_Transferable_Architectures_for_Scalable_Image_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/cdp/model.py'],\n",
       " 'POV-Surgery__A_Dataset_for_Egocentric_Hand_and_Tool_Pose_Estimation_During_Surgical_Activities': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/POV-Surgery__A_Dataset_for_Egocentric_Hand_and_Tool_Pose_Estimation_During_Surgical_Activities/MANO/mano/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/POV-Surgery__A_Dataset_for_Egocentric_Hand_and_Tool_Pose_Estimation_During_Surgical_Activities/HandOccNet_ft/main/model.py'],\n",
       " 'PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/rcnn/src/model.py'],\n",
       " 'Dior-CVAE__Pre-trained_Language_Models_and_Diffusion_Priors_for_Variational_Dialog_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dior-CVAE__Pre-trained_Language_Models_and_Diffusion_Priors_for_Variational_Dialog_Generation/model.py'],\n",
       " 'ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/lerf/lerf_sr/model.py'],\n",
       " 'Ask_the_Right_Questions__Active_Question_Reformulation_with_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Ask_the_Right_Questions__Active_Question_Reformulation_with_Reinforcement_Learning/active-qa/px/nmt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Ask_the_Right_Questions__Active_Question_Reformulation_with_Reinforcement_Learning/active-qa/third_party/bi_att_flow/basic/model.py'],\n",
       " 'EVNet__An_Explainable_Deep_Network_for_Dimension_Reduction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVNet__An_Explainable_Deep_Network_for_Dimension_Reduction/model/model.py'],\n",
       " 'PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis/pyabsa/tasks/ABSAInstruction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis/pyabsa/tasks/AspectSentimentTripletExtraction/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis/pyabsa/tasks/UniversalSentimentAnalysis/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis/pyabsa/tasks/__SubtaskTemplate__/models/model.py'],\n",
       " 'Robust_Natural_Language_Understanding_with_Residual_Attention_Debiasing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robust_Natural_Language_Understanding_with_Residual_Attention_Debiasing/model.py'],\n",
       " 'Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/cnn_quantization/tf_cnn_benchmarks/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/imp/max/projects/imp/config/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/meta_reward_learning/textworld/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/stacked_capsule_autoencoders/capsules/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/table_rag/agent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/tf3d/instance_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/tf3d/object_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/tf3d/semantic_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/video_timeline_modeling/vtm/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/cache_replacement/policy_learning/cache_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/fairness_teaching/in_progress/rl_a2c/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/graph_embedding/huge/model.py'],\n",
       " 'Interpretable_Time-series_Classification_on_Few-shot_Samples': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Interpretable_Time-series_Classification_on_Few-shot_Samples/SFA_Python-master/src/LibLinear/Model.py'],\n",
       " 'Specifying_Object_Attributes_and_Relations_in_Interactive_Scene_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Specifying_Object_Attributes_and_Relations_in_Interactive_Scene_Generation/scene_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Specifying_Object_Attributes_and_Relations_in_Interactive_Scene_Generation/scripts/gui/model.py'],\n",
       " 'Recursive_Visual_Attention_in_Visual_Dialog': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recursive_Visual_Attention_in_Visual_Dialog/visdialch/model.py'],\n",
       " 'Self-Attention_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Self-Attention_Generative_Adversarial_Networks/model.py'],\n",
       " 'When_Relation_Networks_meet_GANs__Relation_GANs_with_Triplet_Loss': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/When_Relation_Networks_meet_GANs__Relation_GANs_with_Triplet_Loss/super_resolution/model.py'],\n",
       " 'Heterogeneous_Graph_Neural_Networks_for_Malicious_Account_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Heterogeneous_Graph_Neural_Networks_for_Malicious_Account_Detection/algorithms/HACUD/model.py'],\n",
       " 'ContCap__A_scalable_framework_for_continual_image_captioning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ContCap__A_scalable_framework_for_continual_image_captioning/model.py'],\n",
       " 'Mean_teachers_are_better_role_models__Weight-averaged_consistency_targets_improve_semi-supervised_deep_learning_results': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mean_teachers_are_better_role_models__Weight-averaged_consistency_targets_improve_semi-supervised_deep_learning_results/pixelssl/task_template/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mean_teachers_are_better_role_models__Weight-averaged_consistency_targets_improve_semi-supervised_deep_learning_results/task/sseg/model.py'],\n",
       " 'CheXpert____Approximating_the_CheXpert_labeler_for_Speed_Differentiability__and_Probabilistic_Output': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CheXpert____Approximating_the_CheXpert_labeler_for_Speed_Differentiability__and_Probabilistic_Output/chexpert_approximator/model.py'],\n",
       " 'Diversifying_Task-oriented_Dialogue_Response_Generation_with_Prototype_Guided_Paraphrasing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Diversifying_Task-oriented_Dialogue_Response_Generation_with_Prototype_Guided_Paraphrasing/code/unsupervised_models/model.py'],\n",
       " 'Alpha-Refine__Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Alpha-Refine__Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation/external/RT_MDNet/modules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Alpha-Refine__Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation/ltr/models/backbone/efficientnet/model.py'],\n",
       " 'Parallel-Data-Free_Voice_Conversion_Using_Cycle-Consistent_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Parallel-Data-Free_Voice_Conversion_Using_Cycle-Consistent_Adversarial_Networks/model.py'],\n",
       " 'Light_bending_and_X-ray_echoes_from_behind_a_supermassive_black_hole': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Light_bending_and_X-ray_echoes_from_behind_a_supermassive_black_hole/pylag/model.py'],\n",
       " 'Action_sequencing_using_visual_permutations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Action_sequencing_using_visual_permutations/scrabble/model.py'],\n",
       " 'Spatial_As_Deep__Spatial_CNN_for_Traffic_Scene_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial_As_Deep__Spatial_CNN_for_Traffic_Scene_Understanding/model.py'],\n",
       " 'Hamilton-Jacobi_Deep_Q-Learning_for_Deterministic_Continuous-Time_Systems_with_Lipschitz_Continuous_Controls': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hamilton-Jacobi_Deep_Q-Learning_for_Deterministic_Continuous-Time_Systems_with_Lipschitz_Continuous_Controls/algorithms/model.py'],\n",
       " 'FANG__Leveraging_Social_Context_for_Fake_News_Detection_Using_Graph_Representation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FANG__Leveraging_Social_Context_for_Fake_News_Detection_Using_Graph_Representation/graph/ngcn/model.py'],\n",
       " 'Automatic_Grading_of_Individual_Knee_Osteoarthritis_Features_in_Plain_Radiographs_using_Deep_Convolutional_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Automatic_Grading_of_Individual_Knee_Osteoarthritis_Features_in_Plain_Radiographs_using_Deep_Convolutional_Neural_Networks/oarsigrading/training/model.py'],\n",
       " 'Light_Multi-segment_Activation_for_Model_Compression': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Light_Multi-segment_Activation_for_Model_Compression/translation_models/model.py'],\n",
       " 'Deep_Anomaly_Detection_with_Outlier_Exposure': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Anomaly_Detection_with_Outlier_Exposure/NLP_language_modeling/model.py'],\n",
       " 'Robustness_of_Conditional_GANs_to_Noisy_Labels': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robustness_of_Conditional_GANs_to_Noisy_Labels/mnist/model.py'],\n",
       " 'Open-World_Semi-Supervised_Learning_for_Node_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Open-World_Semi-Supervised_Learning_for_Node_Classification/networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Open-World_Semi-Supervised_Learning_for_Node_Classification/networks_large/model.py'],\n",
       " 'Population_Based_Augmentation__Efficient_Learning_of_Augmentation_Policy_Schedules': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Population_Based_Augmentation__Efficient_Learning_of_Augmentation_Policy_Schedules/pba/model.py'],\n",
       " 'Variational_Autoencoder_with_Arbitrary_Conditioning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Variational_Autoencoder_with_Arbitrary_Conditioning/celeba_model/model.py'],\n",
       " 'DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/DialogueGCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/DialogueRNN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/ICON-end-to-end/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/ICON/IEMOCAP/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/bc-LSTM-pytorch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/COSMIC/erc-training/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/emotion-cause-extraction/RoBERTa Baseline/simpletransformers/model.py'],\n",
       " 'Smoothed_Dilated_Convolutions_for_Improved_Dense_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Smoothed_Dilated_Convolutions_for_Improved_Dense_Prediction/model.py'],\n",
       " 'Distribution-induced_Bidirectional_Generative_Adversarial_Network_for_Graph_Representation_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Distribution-induced_Bidirectional_Generative_Adversarial_Network_for_Graph_Representation_Learning/DBGAN_cluster/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Distribution-induced_Bidirectional_Generative_Adversarial_Network_for_Graph_Representation_Learning/DBGAN_link/model.py'],\n",
       " 'Deep_Reinforcement_Learning_for_List-wise_Recommendations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Reinforcement_Learning_for_List-wise_Recommendations/src/model.py'],\n",
       " 'Proposal_for_a_Leaky-Integrate-Fire_Spiking_Neuron_based_on_Magneto-Electric_Switching_of_Ferro-magnets': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Proposal_for_a_Leaky-Integrate-Fire_Spiking_Neuron_based_on_Magneto-Electric_Switching_of_Ferro-magnets/model.py'],\n",
       " 'DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/CURL/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/DeepLPF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/SteReFo/blur_CV_refinement/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/SteReFo/blur_baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/SteReFo/blur_refinement/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/SteReFo/stereonet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/NLP/EntityCS/wsd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/NLP/UniMS/unims/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/noahnmt/multiuat/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/noahnmt/multiuat/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/noahnmt/multiuat/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/noahnmt/multiuat/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Learning_to_Ask__Neural_Question_Generation_for_Reading_Comprehension': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_Ask__Neural_Question_Generation_for_Reading_Comprehension/model.py'],\n",
       " 'SQuAD__100_000__Questions_for_Machine_Comprehension_of_Text': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SQuAD__100_000__Questions_for_Machine_Comprehension_of_Text/model.py'],\n",
       " 'Machine_Comprehension_by_Text-to-Text_Neural_Question_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Machine_Comprehension_by_Text-to-Text_Neural_Question_Generation/model.py'],\n",
       " 'Discriminative_Deep_Dyna-Q__Robust_Planning_for_Dialogue_Policy_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Discriminative_Deep_Dyna-Q__Robust_Planning_for_Dialogue_Policy_Learning/D3Q/src/deep_dialog/usersims/model.py'],\n",
       " 'Show__Attend_and_Tell__Neural_Image_Caption_Generation_with_Visual_Attention': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show__Attend_and_Tell__Neural_Image_Caption_Generation_with_Visual_Attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show__Attend_and_Tell__Neural_Image_Caption_Generation_with_Visual_Attention/Image_Captioning/model.py'],\n",
       " 'VQA__Visual_Question_Answering': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VQA__Visual_Question_Answering/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VQA__Visual_Question_Answering/Image_Captioning/model.py'],\n",
       " 'Automatic_Temporally_Coherent_Video_Colorization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Automatic_Temporally_Coherent_Video_Colorization/keras_noise2noise/model.py'],\n",
       " 'Applying_Deep_Learning_to_the_Newsvendor_Problem': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Applying_Deep_Learning_to_the_Newsvendor_Problem/model.py'],\n",
       " 'On_the_Effectiveness_of_Weight-Encoded_Neural_Implicit_3D_Shapes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Effectiveness_of_Weight-Encoded_Neural_Implicit_3D_Shapes/neuralImplicitTools/src/model.py'],\n",
       " 'Probing_Linguistic_Information_For_Logical_Inference_In_Pre-trained_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Probing_Linguistic_Information_For_Logical_Inference_In_Pre-trained_Language_Models/inform_prob/model.py'],\n",
       " 'DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/DialogueGCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/DialogueRNN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/ICON-end-to-end/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/ICON/IEMOCAP/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/bc-LSTM-pytorch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/COSMIC/erc-training/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/emotion-cause-extraction/RoBERTa Baseline/simpletransformers/model.py'],\n",
       " 'DeepFaceLab__Integrated__flexible_and_extensible_face-swapping_framework': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepFaceLab__Integrated__flexible_and_extensible_face-swapping_framework/model.py'],\n",
       " 'Show_and_Tell__A_Neural_Image_Caption_Generator': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show_and_Tell__A_Neural_Image_Caption_Generator/model.py'],\n",
       " 'Unsupervised_Extractive_Summarization_by_Pre-training_Hierarchical_Transformers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Extractive_Summarization_by_Pre-training_Hierarchical_Transformers/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Extractive_Summarization_by_Pre-training_Hierarchical_Transformers/fairseq/models/roberta/model.py'],\n",
       " 'High-Performance_Large-Scale_Image_Recognition_Without_Normalization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High-Performance_Large-Scale_Image_Recognition_Without_Normalization/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High-Performance_Large-Scale_Image_Recognition_Without_Normalization/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High-Performance_Large-Scale_Image_Recognition_Without_Normalization/PatchCore/src/model.py'],\n",
       " 'MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/lerf/lerf_sr/model.py'],\n",
       " 'Multi-Facet_Recommender_Networks_with_Spherical_Optimization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-Facet_Recommender_Networks_with_Spherical_Optimization/models/model.py'],\n",
       " 'Direct_Speech-to-image_Translation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Direct_Speech-to-image_Translation/StackGAN_v2/model.py'],\n",
       " 'Mitigating_Memorization_of_Noisy_Labels_via_Regularization_between_Representations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mitigating_Memorization_of_Noisy_Labels_via_Regularization_between_Representations/model.py'],\n",
       " 'BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/jasper/src/model.py'],\n",
       " 'Single-Stage_6D_Object_Pose_Estimation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Single-Stage_6D_Object_Pose_Estimation/model.py'],\n",
       " 'How_baryons_can_significantly_bias_cluster_count_cosmology': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/How_baryons_can_significantly_bias_cluster_count_cosmology/lensing_haloes/halo/model.py'],\n",
       " 'Dual_Path_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/erfnet/src/model.py'],\n",
       " 'Projecting_Your_View_Attentively__Monocular_Road_Scene_Layout_Estimation_via_Cross-View_Transformation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Projecting_Your_View_Attentively__Monocular_Road_Scene_Layout_Estimation_via_Cross-View_Transformation/crossView/model.py'],\n",
       " 'UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning/CV/Effective Transformer-based Solution for RSNA Intracranial Hemorrhage Detection/easymia/model/brain_intracranial_hemorrhage_clas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning/CV/PWCNet/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning/KG/DuKEVU_Baseline/paddle-video-classify-tag/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning/NLP/ACL2019-JEMT/model.py'],\n",
       " '3DSNet__Unsupervised_Shape-to-Shape_3D_Style_Transfer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/3DSNet__Unsupervised_Shape-to-Shape_3D_Style_Transfer/model/model.py'],\n",
       " 'Single_Image_Reflection_Removal_With_Absorption_Effect': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Single_Image_Reflection_Removal_With_Absorption_Effect/model.py'],\n",
       " 'Conditional_Image_Synthesis_With_Auxiliary_Classifier_GANs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Conditional_Image_Synthesis_With_Auxiliary_Classifier_GANs/model.py'],\n",
       " 'Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/cnn_quantization/tf_cnn_benchmarks/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/imp/max/projects/imp/config/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/meta_reward_learning/textworld/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/stacked_capsule_autoencoders/capsules/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/table_rag/agent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/tf3d/instance_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/tf3d/object_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/tf3d/semantic_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/video_timeline_modeling/vtm/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/cache_replacement/policy_learning/cache_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/fairness_teaching/in_progress/rl_a2c/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/graph_embedding/huge/model.py'],\n",
       " 'Code_to_Comment_Translation__A_Comparative_Study_on_Model_Effectiveness___Errors': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Code_to_Comment_Translation__A_Comparative_Study_on_Model_Effectiveness___Errors/NeuralCodeSum/main/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Code_to_Comment_Translation__A_Comparative_Study_on_Model_Effectiveness___Errors/CodeBERT/code/model.py'],\n",
       " 'Joint_entity_recognition_and_relation_extraction_as_a_multi-head_selection_problem': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Joint_entity_recognition_and_relation_extraction_as_a_multi-head_selection_problem/model.py'],\n",
       " 'VALUE__A_Multi-Task_Benchmark_for_Video-and-Language_Understanding_Evaluation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VALUE__A_Multi-Task_Benchmark_for_Video-and-Language_Understanding_Evaluation/model/model.py'],\n",
       " 'DoubleEnsemble__A_New_Ensemble_Method_Based_on_Sample_Reweighting_and_Feature_Selection_for_Financial_Data_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DoubleEnsemble__A_New_Ensemble_Method_Based_on_Sample_Reweighting_and_Feature_Selection_for_Financial_Data_Analysis/examples/benchmarks/TRA/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DoubleEnsemble__A_New_Ensemble_Method_Based_on_Sample_Reweighting_and_Feature_Selection_for_Financial_Data_Analysis/qlib/contrib/meta/data_selection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DoubleEnsemble__A_New_Ensemble_Method_Based_on_Sample_Reweighting_and_Feature_Selection_for_Financial_Data_Analysis/qlib/model/meta/model.py'],\n",
       " 'Designing_Network_Design_Spaces': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Normed_Spaces_for_Graph_Embedding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Normed_Spaces_for_Graph_Embedding/recosys/sympa/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Normed_Spaces_for_Graph_Embedding/sympa/model.py'],\n",
       " 'FastSpeech__Fast__Robust_and_Controllable_Text_to_Speech': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FastSpeech__Fast__Robust_and_Controllable_Text_to_Speech/src/lib/model.py'],\n",
       " 'Semantically_Self-Aligned_Network_for_Text-to-Image_Part-aware_Person_Re-identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantically_Self-Aligned_Network_for_Text-to-Image_Part-aware_Person_Re-identification/src/model/model.py'],\n",
       " 'DenseFuse__A_Fusion_Approach_to_Infrared_and_Visible_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseFuse__A_Fusion_Approach_to_Infrared_and_Visible_Images/FusionGAN/model.py'],\n",
       " 'LLVIP__A_Visible-infrared_Paired_Dataset_for_Low-light_Vision': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LLVIP__A_Visible-infrared_Paired_Dataset_for_Low-light_Vision/FusionGAN/model.py'],\n",
       " 'NeuroCartography__Scalable_Automatic_Visual_Summarization_of_Concepts_in_Deep_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeuroCartography__Scalable_Automatic_Visual_Summarization_of_Concepts_in_Deep_Neural_Networks/src/python/utils/model.py'],\n",
       " 'Bi-Bimodal_Modality_Fusion_for_Correlation-Controlled_Multimodal_Sentiment_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bi-Bimodal_Modality_Fusion_for_Correlation-Controlled_Multimodal_Sentiment_Analysis/Low-rank-Multimodal-Fusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bi-Bimodal_Modality_Fusion_for_Correlation-Controlled_Multimodal_Sentiment_Analysis/TensorFusionNetworks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bi-Bimodal_Modality_Fusion_for_Correlation-Controlled_Multimodal_Sentiment_Analysis/contextual-attention-based-LSTM/model.py'],\n",
       " 'Improving_Multimodal_Fusion_with_Hierarchical_Mutual_Information_Maximization_for_Multimodal_Sentiment_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multimodal_Fusion_with_Hierarchical_Mutual_Information_Maximization_for_Multimodal_Sentiment_Analysis/Low-rank-Multimodal-Fusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multimodal_Fusion_with_Hierarchical_Mutual_Information_Maximization_for_Multimodal_Sentiment_Analysis/TensorFusionNetworks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multimodal_Fusion_with_Hierarchical_Mutual_Information_Maximization_for_Multimodal_Sentiment_Analysis/contextual-attention-based-LSTM/model.py'],\n",
       " 'A_composite_neural_network_that_learns_from_multi-fidelity_data__Application_to_function_approximation_and_inverse_PDE_problems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_composite_neural_network_that_learns_from_multi-fidelity_data__Application_to_function_approximation_and_inverse_PDE_problems/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_composite_neural_network_that_learns_from_multi-fidelity_data__Application_to_function_approximation_and_inverse_PDE_problems/deepxde/zcs/model.py'],\n",
       " 'Micro_Expression_Generation_with_Thin-plate_Spline_Motion_Model_and_Face_Parsing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Micro_Expression_Generation_with_Thin-plate_Spline_Motion_Model_and_Face_Parsing/modules/model.py'],\n",
       " 'GoalNet__Inferring_Conjunctive_Goal_Predicates_from_Human_Plan_Demonstrations_for_Robot_Instruction_Following': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GoalNet__Inferring_Conjunctive_Goal_Predicates_from_Human_Plan_Demonstrations_for_Robot_Instruction_Following/src/model.py'],\n",
       " 'Low_frequency_X-ray_timing_with_Gaussian_processes_and_reverberation_in_the_radio-loud_AGN_3C_120': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Low_frequency_X-ray_timing_with_Gaussian_processes_and_reverberation_in_the_radio-loud_AGN_3C_120/pylag/model.py'],\n",
       " 'Neighbor2Seq__Deep_Learning_on_Massive_Graphs_by_Transforming_Neighbors_to_Sequences': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Neighbor2Seq__Deep_Learning_on_Massive_Graphs_by_Transforming_Neighbors_to_Sequences/Neighbor2Seq/model.py'],\n",
       " 'A_comprehensive_study_of_non-adaptive_and_residual-based_adaptive_sampling_for_physics-informed_neural_networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_comprehensive_study_of_non-adaptive_and_residual-based_adaptive_sampling_for_physics-informed_neural_networks/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_comprehensive_study_of_non-adaptive_and_residual-based_adaptive_sampling_for_physics-informed_neural_networks/deepxde/zcs/model.py'],\n",
       " 'Learning_Sparse_Analytic_Filters_for_Piano_Transcription': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Sparse_Analytic_Filters_for_Piano_Transcription/scripts/model.py'],\n",
       " 'Object-Centric_Learning_with_Slot_Attention': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Object-Centric_Learning_with_Slot_Attention/model.py'],\n",
       " 'Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/coref/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/depparse/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/langid/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/ner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/pos/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/tokenization/model.py'],\n",
       " 'Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/coref/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/depparse/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/langid/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/ner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/pos/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/tokenization/model.py'],\n",
       " 'UNITER__UNiversal_Image-TExt_Representation_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNITER__UNiversal_Image-TExt_Representation_Learning/src/model/model.py'],\n",
       " 'CFSum__A_Coarse-to-Fine_Contribution_Network_for_Multimodal_Summarization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CFSum__A_Coarse-to-Fine_Contribution_Network_for_Multimodal_Summarization/src/model/model.py'],\n",
       " 'Interaction-Aware_Planning_With_Deep_Inverse_Reinforcement_Learning_for_Human-Like_Autonomous_Driving_in_Merge_Scenarios': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Interaction-Aware_Planning_With_Deep_Inverse_Reinforcement_Learning_for_Human-Like_Autonomous_Driving_in_Merge_Scenarios/model.py'],\n",
       " 'Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief/RLLG/agents/common/model.py'],\n",
       " 'New_Frontiers_in_Graph_Autoencoders__Joint_Community_Detection_and_Link_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/New_Frontiers_in_Graph_Autoencoders__Joint_Community_Detection_and_Link_Prediction/modularity_aware_gae/model.py'],\n",
       " 'SageMix__Saliency-Guided_Mixup_for_Point_Clouds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SageMix__Saliency-Guided_Mixup_for_Point_Clouds/pointcloud/model.py'],\n",
       " 'Thinking_Two_Moves_Ahead__Anticipating_Other_Users_Improves_Backdoor_Attacks_in_Federated_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Thinking_Two_Moves_Ahead__Anticipating_Other_Users_Improves_Backdoor_Attacks_in_Federated_Learning/models/model.py'],\n",
       " 'AutoVideo__An_Automated_Video_Action_Recognition_System': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoVideo__An_Automated_Video_Action_Recognition_System/autovideo/recognition/R2p1D/model.py'],\n",
       " 'Pseudo-Inverted_Bottleneck_Convolution_for_DARTS_Search_Space': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Pseudo-Inverted_Bottleneck_Convolution_for_DARTS_Search_Space/cnn/model.py'],\n",
       " 'OmDet__Large-scale_vision-language_multi-dataset_pre-training_with_multimodal_detection_network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OmDet__Large-scale_vision-language_multi-dataset_pre-training_with_multimodal_detection_network/omdet/modeling/language_backbone/clip/models/model.py'],\n",
       " 'From_Sky_to_the_Ground__A_Large-scale_Benchmark_and_Simple_Baseline_Towards_Real_Rain_Removal': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/From_Sky_to_the_Ground__A_Large-scale_Benchmark_and_Simple_Baseline_Towards_Real_Rain_Removal/SCD-Former/model.py'],\n",
       " 'New_MGCAMB_tests_of_gravity_with_CosmoMC_and_Cobaya': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/New_MGCAMB_tests_of_gravity_with_CosmoMC_and_Cobaya/camb/camb/model.py'],\n",
       " 'Masked_Autoencoders_Are_Scalable_Vision_Learners': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Masked_Autoencoders_Are_Scalable_Vision_Learners/visionts/model.py'],\n",
       " 'Recurrent_Environment_Simulators': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Environment_Simulators/forward_models/model.py'],\n",
       " 'SepLUT__Separable_Image-adaptive_Lookup_Tables_for_Real-time_Image_Enhancement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SepLUT__Separable_Image-adaptive_Lookup_Tables_for_Real-time_Image_Enhancement/seplut/model.py'],\n",
       " 'Joint_Admission_Control_and_Resource_Allocation_of_Virtual_Network_Embedding_via_Hierarchical_Deep_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Joint_Admission_Control_and_Resource_Allocation_of_Virtual_Network_Embedding_via_Hierarchical_Deep_Reinforcement_Learning/solver/learning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Joint_Admission_Control_and_Resource_Allocation_of_Virtual_Network_Embedding_via_Hierarchical_Deep_Reinforcement_Learning/solver/learning/gae_vne/model.py'],\n",
       " 'Towards_a_Holistic_Understanding_of_Mathematical_Questions_with_Contrastive_Pre-training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_a_Holistic_Understanding_of_Mathematical_Questions_with_Contrastive_Pre-training/src/model.py'],\n",
       " 'Learning_from_Unlabeled_3D_Environments_for_Vision-and-Language_Navigation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_from_Unlabeled_3D_Environments_for_Vision-and-Language_Navigation/map_nav_src/models/model.py'],\n",
       " 'Gated-ViGAT__Efficient_Bottom-Up_Event_Recognition_and_Explanation_Using_a_New_Frame_Selection_Policy_and_Gating_Mechanism': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Gated-ViGAT__Efficient_Bottom-Up_Event_Recognition_and_Explanation_Using_a_New_Frame_Selection_Policy_and_Gating_Mechanism/model.py'],\n",
       " 'L2CS-Net__Fine-Grained_Gaze_Estimation_in_Unconstrained_Environments': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L2CS-Net__Fine-Grained_Gaze_Estimation_in_Unconstrained_Environments/l2cs/model.py'],\n",
       " 'Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/dpkd/transformers/examples/research_projects/fsner/src/fsner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/uprise/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Fully_transformer-based_biomarker_prediction_from_colorectal_cancer_histology__a_large-scale_multicentric_study': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fully_transformer-based_biomarker_prediction_from_colorectal_cancer_histology__a_large-scale_multicentric_study/marugoto/mil/model.py'],\n",
       " 'RAFaRe__Learning_Robust_and_Accurate_Non-parametric_3D_Face_Reconstruction_from_Pseudo_2D_3D_Pairs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RAFaRe__Learning_Robust_and_Accurate_Non-parametric_3D_Face_Reconstruction_from_Pseudo_2D_3D_Pairs/engineer/face_parse/model.py'],\n",
       " 'Do_graph_neural_networks_learn_traditional_jet_substructure_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Do_graph_neural_networks_learn_traditional_jet_substructure_/xai4hep/mlpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Do_graph_neural_networks_learn_traditional_jet_substructure_/xai4hep/particlenet/model.py'],\n",
       " 'A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction/pyabsa/tasks/ABSAInstruction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction/pyabsa/tasks/AspectSentimentTripletExtraction/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction/pyabsa/tasks/UniversalSentimentAnalysis/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction/pyabsa/tasks/__SubtaskTemplate__/models/model.py'],\n",
       " 'Deep_Quantigraphic_Image_Enhancement_via_Comparametric_Equations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Quantigraphic_Image_Enhancement_via_Comparametric_Equations/model.py'],\n",
       " 'Caption_Anything__Interactive_Image_Description_with_Diverse_Multimodal_Controls': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Caption_Anything__Interactive_Image_Description_with_Diverse_Multimodal_Controls/caption_anything/model.py'],\n",
       " 'RoSteALS__Robust_Steganography_using_Autoencoder_Latent_Space': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RoSteALS__Robust_Steganography_using_Autoencoder_Latent_Space/annotator/openpose/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RoSteALS__Robust_Steganography_using_Autoencoder_Latent_Space/cldm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RoSteALS__Robust_Steganography_using_Autoencoder_Latent_Space/ldm/modules/diffusionmodules/model.py'],\n",
       " 'AU-aware_graph_convolutional_network_for_Macro-_and_Micro-expression_spotting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AU-aware_graph_convolutional_network_for_Macro-_and_Micro-expression_spotting/model.py'],\n",
       " 'RiDDLE__Reversible_and_Diversified_De-identification_with_Latent_Encryptor': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RiDDLE__Reversible_and_Diversified_De-identification_with_Latent_Encryptor/models/stylegan2/model.py'],\n",
       " 'On_the_number_of_subproblem_iterations_per_coupling_step_in_partitioned_fluid-structure_interaction_simulations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_number_of_subproblem_iterations_per_coupling_step_in_partitioned_fluid-structure_interaction_simulations/data_structure/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_number_of_subproblem_iterations_per_coupling_step_in_partitioned_fluid-structure_interaction_simulations/tests/coupled_solvers/models/model.py'],\n",
       " 'Initiative_Defense_against_Facial_Manipulation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Initiative_Defense_against_Facial_Manipulation/model.py'],\n",
       " 'Weakly_Supervised_Clustering_by_Exploiting_Unique_Class_Count': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly_Supervised_Clustering_by_Exploiting_Unique_Class_Count/ucc/model.py'],\n",
       " 'Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/trainer/callbacks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/multimodal/llava/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/multimodal/multimodal_simple/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bert/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bert/classifier/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bert/extractive_summarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bert/token_classifier/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bloom/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/btlm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/dpo/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/dpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/esm2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/falcon/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/gemma2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/gpt2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/gpt3/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/gptj/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/jais/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/llama/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/mistral/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/mixtral/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/santacoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/starcoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/t5/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/vision/dit/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/vision/vision_transformer/model.py'],\n",
       " 'Regression-based_Deep-Learning_predicts_molecular_biomarkers_from_pathology_slides': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regression-based_Deep-Learning_predicts_molecular_biomarkers_from_pathology_slides/marugoto/mil/model.py'],\n",
       " 'Learning_to_Fly_in_Seconds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_Fly_in_Seconds/tests/src/nn/layers/gru/pytorch/model.py'],\n",
       " 'Reliable_extrapolation_of_deep_neural_operators_informed_by_physics_or_sparse_observations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Reliable_extrapolation_of_deep_neural_operators_informed_by_physics_or_sparse_observations/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Reliable_extrapolation_of_deep_neural_operators_informed_by_physics_or_sparse_observations/deepxde/zcs/model.py'],\n",
       " 'Fourier-MIONet__Fourier-enhanced_multiple-input_neural_operators_for_multiphase_modeling_of_geological_carbon_sequestration': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fourier-MIONet__Fourier-enhanced_multiple-input_neural_operators_for_multiphase_modeling_of_geological_carbon_sequestration/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fourier-MIONet__Fourier-enhanced_multiple-input_neural_operators_for_multiphase_modeling_of_geological_carbon_sequestration/deepxde/zcs/model.py'],\n",
       " 'Unicom__Universal_and_Compact_Representation_Learning_for_Image_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unicom__Universal_and_Compact_Representation_Learning_for_Image_Retrieval/llava/model/multimodal_encoder/dev_eva_clip/eva_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unicom__Universal_and_Compact_Representation_Learning_for_Image_Retrieval/unicom/unicom/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unicom__Universal_and_Compact_Representation_Learning_for_Image_Retrieval/downstream/llava/model/multimodal_encoder/dev_eva_clip/eva_clip/model.py'],\n",
       " 'Omni-Scale_Feature_Learning_for_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Omni-Scale_Feature_Learning_for_Person_Re-Identification/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Omni-Scale_Feature_Learning_for_Person_Re-Identification/PaDiM/src/model.py'],\n",
       " 'FedFA__Federated_Learning_with_Feature_Anchors_to_Align_Features_and_Classifiers_for_Heterogeneous_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FedFA__Federated_Learning_with_Feature_Anchors_to_Align_Features_and_Classifiers_for_Heterogeneous_Data/model.py'],\n",
       " 'One-shot_Joint_Extraction__Registration_and_Segmentation_of_Neuroimaging_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/One-shot_Joint_Extraction__Registration_and_Segmentation_of_Neuroimaging_Data/model.py'],\n",
       " 'The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/3/AECRNet/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/4/ACGNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/4/Fourier-Features-Let-Networks-Learn-High-Frequency/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/LECF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/LIE-IQA/networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/UColor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/Cybertron/cybertron/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/informer/model/model.py'],\n",
       " 'Evolution_Strategies_as_a_Scalable_Alternative_to_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Evolution_Strategies_as_a_Scalable_Alternative_to_Reinforcement_Learning/model.py'],\n",
       " 'Can_Bad_Teaching_Induce_Forgetting__Unlearning_in_Deep_Networks_using_an_Incompetent_Teacher': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Bad_Teaching_Induce_Forgetting__Unlearning_in_Deep_Networks_using_an_Incompetent_Teacher/model.py'],\n",
       " 'A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_v106/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_v107/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_v115/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_v68/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_vid_score/video/model.py'],\n",
       " 'Feature_Fusion_from_Head_to_Tail_for_Long-Tailed_Visual_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Feature_Fusion_from_Head_to_Tail_for_Long-Tailed_Visual_Recognition/models/ride_model/model.py'],\n",
       " 'The_Tensor_Brain__A_Unified_Theory_of_Perception__Memory_and_Semantic_Decoding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Tensor_Brain__A_Unified_Theory_of_Perception__Memory_and_Semantic_Decoding/tensorbrain/model.py'],\n",
       " 'AI-accelerated_Discovery_of_Altermagnetic_Materials': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AI-accelerated_Discovery_of_Altermagnetic_Materials/model.py'],\n",
       " 'Constructing_Boundary-identical_Microstructures_by_Guided_Diffusion_for_Fast_Multiscale_Designs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Constructing_Boundary-identical_Microstructures_by_Guided_Diffusion_for_Fast_Multiscale_Designs/network/model.py'],\n",
       " 'Deep_Reinforcement_Learning_with_Task-Adaptive_Retrieval_via_Hypernetwork': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Reinforcement_Learning_with_Task-Adaptive_Retrieval_via_Hypernetwork/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Reinforcement_Learning_with_Task-Adaptive_Retrieval_via_Hypernetwork/torch_ac/model.py'],\n",
       " 'EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/EigenTrajectory/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/agentformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/gpgraphsgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/gpgraphstgcnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/graphtern/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/implicit/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/lbebm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/pecnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/sgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/stgcnn/model.py'],\n",
       " 'Your_Negative_May_not_Be_True_Negative__Boosting_Image-Text_Matching_with_False_Negative_Elimination': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Your_Negative_May_not_Be_True_Negative__Boosting_Image-Text_Matching_with_False_Negative_Elimination/model.py'],\n",
       " 'OTRE__Where_Optimal_Transport_Guided_Unpaired_Image-to-Image_Translation_Meets_Regularization_by_Enhancing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OTRE__Where_Optimal_Transport_Guided_Unpaired_Image-to-Image_Translation_Meets_Regularization_by_Enhancing/Cycle-GAN/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OTRE__Where_Optimal_Transport_Guided_Unpaired_Image-to-Image_Translation_Meets_Regularization_by_Enhancing/OTE-GAN/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OTRE__Where_Optimal_Transport_Guided_Unpaired_Image-to-Image_Translation_Meets_Regularization_by_Enhancing/OTTGAN/model/model.py'],\n",
       " 'Differentiable_Modelling_of_Percussive_Audio_with_Transient_and_Spectral_Synthesis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Differentiable_Modelling_of_Percussive_Audio_with_Transient_and_Spectral_Synthesis/drumblender/utils/model.py'],\n",
       " 'High-Resolution_Spatial_Transcriptomics_from_Histology_Images_using_HisToSGE': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High-Resolution_Spatial_Transcriptomics_from_Histology_Images_using_HisToSGE/model.py'],\n",
       " 'DM-VTON__Distilled_Mobile_Real-time_Virtual_Try-On': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DM-VTON__Distilled_Mobile_Real-time_Virtual_Try-On/exp/runtime/ViTPose/models/model.py'],\n",
       " 'Seq2seq_Dependency_Parsing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/cdp/model.py'],\n",
       " 'Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/cdp/model.py'],\n",
       " 'Self-optimizing_Feature_Generation_via_Categorical_Hashing_Representation_and_Hierarchical_Reinforcement_Crossing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Self-optimizing_Feature_Generation_via_Categorical_Hashing_Representation_and_Hierarchical_Reinforcement_Crossing/model.py'],\n",
       " 'BlazeNeo__Blazing_fast_polyp_segmentation_and_neoplasm_detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BlazeNeo__Blazing_fast_polyp_segmentation_and_neoplasm_detection/models/blazeneo/model.py'],\n",
       " 'Progressive_Attention_Guidance_for_Whole_Slide_Vulvovaginal_Candidiasis_Screening': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Progressive_Attention_Guidance_for_Whole_Slide_Vulvovaginal_Candidiasis_Screening/codes/image_level/retinanet/model.py'],\n",
       " 'BeatNet__CRNN_and_Particle_Filtering_for_Online_Joint_Beat_Downbeat_and_Meter_Tracking': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BeatNet__CRNN_and_Particle_Filtering_for_Online_Joint_Beat_Downbeat_and_Meter_Tracking/DBNet/src/modules/model.py'],\n",
       " 'Fast__Expressive_SE__n___Equivariant_Networks_through_Weight-Sharing_in_Position-Orientation_Space': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fast__Expressive_SE__n___Equivariant_Networks_through_Weight-Sharing_in_Position-Orientation_Space/n_body_system/model.py'],\n",
       " 'AutoAugment__Learning_Augmentation_Policies_from_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/cdp/model.py'],\n",
       " 'Neural_Structure_Fields_with_Application_to_Crystal_Structure_Autoencoders': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Neural_Structure_Fields_with_Application_to_Crystal_Structure_Autoencoders/src/model.py'],\n",
       " 'A_Diffusion_Weighted_Graph_Framework_for_New_Intent_Discovery': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Diffusion_Weighted_Graph_Framework_for_New_Intent_Discovery/model.py'],\n",
       " 'SATO__Stable_Text-to-Motion_Framework': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SATO__Stable_Text-to-Motion_Framework/CLIP/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SATO__Stable_Text-to-Motion_Framework/visualization/CLIP/clip/model.py'],\n",
       " 'DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib/base/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib/unet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib_extended/base/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib_extended/base_with_class_head/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib_extended/unet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib_extended/unet_with_class_head/model.py'],\n",
       " 'Whispering_LLaMA__A_Cross-Modal_Generative_Error_Correction_Framework_for_Speech_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Whispering_LLaMA__A_Cross-Modal_Generative_Error_Correction_Framework_for_Speech_Recognition/lit_llama/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Whispering_LLaMA__A_Cross-Modal_Generative_Error_Correction_Framework_for_Speech_Recognition/whisper_openAI/whisper/model.py'],\n",
       " 'Language_Agent_Tree_Search_Unifies_Reasoning_Acting_and_Planning_in_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Language_Agent_Tree_Search_Unifies_Reasoning_Acting_and_Planning_in_Language_Models/programming/generators/model.py'],\n",
       " 'DDM__2___Self-Supervised_Diffusion_MRI_Denoising_with_Generative_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDM__2___Self-Supervised_Diffusion_MRI_Denoising_with_Generative_Diffusion_Models/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDM__2___Self-Supervised_Diffusion_MRI_Denoising_with_Generative_Diffusion_Models/DeepID/src/model.py'],\n",
       " 'Large-Scale_and_Multi-Perspective_Opinion_Summarization_with_Diverse_Review_Subsets': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Large-Scale_and_Multi-Perspective_Opinion_Summarization_with_Diverse_Review_Subsets/shared_lib/utils/helpers/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Large-Scale_and_Multi-Perspective_Opinion_Summarization_with_Diverse_Review_Subsets/subsumm/utils/constants/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Large-Scale_and_Multi-Perspective_Opinion_Summarization_with_Diverse_Review_Subsets/subsumm/utils/helpers/model.py'],\n",
       " 'DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics/codebases/stable-diffusion/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics/codebases/stable-diffusion/src/clip/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics/codebases/stable-diffusion/src/taming-transformers/taming/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics/codebases/stable-diffusion/src/taming-transformers/taming/modules/discriminator/model.py'],\n",
       " 'Concept-free_Causal_Disentanglement_with_Variational_Graph_Auto-Encoder': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Concept-free_Causal_Disentanglement_with_Variational_Graph_Auto-Encoder/model.py'],\n",
       " 'Domain-Specific_Code_Language_Models__Unraveling_the_Potential_for_HPC_Codes_and_Tasks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Domain-Specific_Code_Language_Models__Unraveling_the_Potential_for_HPC_Codes_and_Tasks/CompAI/OMPify/model.py'],\n",
       " 'Contrastive_variational_information_bottleneck_for_aspect-based_sentiment_analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Contrastive_variational_information_bottleneck_for_aspect-based_sentiment_analysis/model.py'],\n",
       " 'FishNet__A_Versatile_Backbone_for_Image__Region__and_Pixel_Level_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FishNet__A_Versatile_Backbone_for_Image__Region__and_Pixel_Level_Prediction/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FishNet__A_Versatile_Backbone_for_Image__Region__and_Pixel_Level_Prediction/erfnet/src/model.py'],\n",
       " 'Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers/uprise/src/models/model.py'],\n",
       " 'Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/understand_icl/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/understand_icl/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/uprise/src/models/model.py'],\n",
       " 'Machine-Generated_Text_Localization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Machine-Generated_Text_Localization/gradio_utils/fastdetectgpt_scripts/model.py'],\n",
       " 'Multimodal_Transformer_Distillation_for_Audio-Visual_Synchronization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multimodal_Transformer_Distillation_for_Audio-Visual_Synchronization/models/conformer/model.py'],\n",
       " 'INSANet__INtra-INter_Spectral_Attention_Network_for_Effective_Feature_Fusion_of_Multispectral_Pedestrian_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/INSANet__INtra-INter_Spectral_Attention_Network_for_Effective_Feature_Fusion_of_Multispectral_Pedestrian_Detection/src/model.py'],\n",
       " 'PETA__Evaluating_the_Impact_of_Protein_Transfer_Learning_with_Sub-word_Tokenization_on_Downstream_Applications': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PETA__Evaluating_the_Impact_of_Protein_Transfer_Learning_with_Sub-word_Tokenization_on_Downstream_Applications/peta/model.py'],\n",
       " 'LOGO__A_Long-Form_Video_Dataset_for_Group_Action_Quality_Assessment': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGO__A_Long-Form_Video_Dataset_for_Group_Action_Quality_Assessment/StreamE-main/model/Model.py'],\n",
       " 'On_the_Continuity_of_Rotation_Representations_in_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Continuity_of_Rotation_Representations_in_Neural_Networks/Inverse_Kinematics/code/Model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Continuity_of_Rotation_Representations_in_Neural_Networks/sanity_test/code/model.py'],\n",
       " 'Personalizing_Session-based_Recommendations_with_Hierarchical_Recurrent_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Personalizing_Session-based_Recommendations_with_Hierarchical_Recurrent_Neural_Networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Personalizing_Session-based_Recommendations_with_Hierarchical_Recurrent_Neural_Networks/model/legacy/model.py'],\n",
       " 'Deep_Probabilistic_Modeling_of_Glioma_Growth': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Probabilistic_Modeling_of_Glioma_Growth/probunet/model.py'],\n",
       " 'Deep_Speech_2__End-to-End_Speech_Recognition_in_English_and_Mandarin': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Speech_2__End-to-End_Speech_Recognition_in_English_and_Mandarin/model.py'],\n",
       " 'Locally_Differentially_Private__Contextual__Bandits_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Locally_Differentially_Private__Contextual__Bandits_Learning/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Locally_Differentially_Private__Contextual__Bandits_Learning/lite-hrnet/src/model.py'],\n",
       " 'Detecting_Text_in_Natural_Image_with_Connectionist_Text_Proposal_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_Text_in_Natural_Image_with_Connectionist_Text_Proposal_Network/densenet/model.py'],\n",
       " 'Metrics_and_continuity_in_reinforcement_learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/graph_embedding/huge/model.py'],\n",
       " 'Bootstrap_your_own_latent__A_new_approach_to_self-supervised_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bootstrap_your_own_latent__A_new_approach_to_self-supervised_Learning/self_driving_car/ML Agent/model.py'],\n",
       " 'On_Adaptive_Attacks_to_Adversarial_Example_Defenses': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_Adaptive_Attacks_to_Adversarial_Example_Defenses/07_ensemble_diversity/model.py'],\n",
       " 'LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/beit2/vqkd_teacher/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/kosmos-2/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/kosmos-2/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/kosmos-2/open_clip/src/open_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/decoding/GAD/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/decoding/GAD/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/infoxlm/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/infoxlm/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/xdoc/fine_tuning/funsd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/xdoc/fine_tuning/websrc/model.py'],\n",
       " 'RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/rtmdet/projects/easydeploy/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/rtmdet/tests/test_deploy/data/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/engine/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/fastsam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/nas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/rtdetr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/sam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/yolo/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/engine/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/fastsam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/nas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/rtdetr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/sam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/yolo/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/engine/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/fastsam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/nas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/rtdetr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/sam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/yolo/model.py'],\n",
       " 'Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement/src/model.py'],\n",
       " 'Gaze360__Physically_Unconstrained_Gaze_Estimation_in_the_Wild': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Gaze360__Physically_Unconstrained_Gaze_Estimation_in_the_Wild/code/model.py'],\n",
       " 'AutoML_Segmentation_for_3D_Medical_Image_Data__Contribution_to_the_MSD_Challenge_2018': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoML_Segmentation_for_3D_Medical_Image_Data__Contribution_to_the_MSD_Challenge_2018/model.py'],\n",
       " 'AV_Taris__Online_Audio-Visual_Speech_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AV_Taris__Online_Audio-Visual_Speech_Recognition/avsr/transformer/model.py'],\n",
       " 'Can_Autonomous_Vehicles_Identify__Recover_From__and_Adapt_to_Distribution_Shifts_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Autonomous_Vehicles_Identify__Recover_From__and_Adapt_to_Distribution_Shifts_/oatomobile/baselines/torch/cil/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Autonomous_Vehicles_Identify__Recover_From__and_Adapt_to_Distribution_Shifts_/oatomobile/baselines/torch/dim/model.py'],\n",
       " 'Permutation-equivariant_and_Proximity-aware_Graph_Neural_Networks_with_Stochastic_Message_Passing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Permutation-equivariant_and_Proximity-aware_Graph_Neural_Networks_with_Stochastic_Message_Passing/models/model.py'],\n",
       " 'Reviving_Iterative_Training_with_Mask_Guidance_for_Interactive_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Reviving_Iterative_Training_with_Mask_Guidance_for_Interactive_Segmentation/deploy/fastdeploy/semantic_segmentation/serving/fastdeploy_serving/models/postprocess/1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Reviving_Iterative_Training_with_Mask_Guidance_for_Interactive_Segmentation/deploy/fastdeploy/semantic_segmentation/serving/fastdeploy_serving/models/preprocess/1/model.py'],\n",
       " 'SiftingGAN__Generating_and_Sifting_Labeled_Samples_to_Improve_the_Remote_Sensing_Image_Scene_Classification_Baseline_in_vitro': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SiftingGAN__Generating_and_Sifting_Labeled_Samples_to_Improve_the_Remote_Sensing_Image_Scene_Classification_Baseline_in_vitro/model.py'],\n",
       " 'Multi-Pointer_Co-Attention_Networks_for_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-Pointer_Co-Attention_Networks_for_Recommendation/MPCN/tf_models/model.py'],\n",
       " 'PDNet__Prior-model_Guided_Depth-enhanced_Network_for_Salient_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PDNet__Prior-model_Guided_Depth-enhanced_Network_for_Salient_Object_Detection/model.py'],\n",
       " 'Robust_Deep_Reinforcement_Learning_through_Adversarial_Loss': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robust_Deep_Reinforcement_Learning_through_Adversarial_Loss/A3C/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robust_Deep_Reinforcement_Learning_through_Adversarial_Loss/DQN/model.py'],\n",
       " 'Investigating_Saturation_Effects_in_Integrated_Gradients': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Investigating_Saturation_Effects_in_Integrated_Gradients/captum/_utils/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Investigating_Saturation_Effects_in_Integrated_Gradients/captum/_utils/models/linear_model/model.py'],\n",
       " 'Perceptual_Extreme_Super_Resolution_Network_with_Receptive_Field_Block': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Perceptual_Extreme_Super_Resolution_Network_with_Receptive_Field_Block/model.py'],\n",
       " 'ParSeNet__A_Parametric_Surface_Fitting_Network_for_3D_Point_Clouds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ParSeNet__A_Parametric_Surface_Fitting_Network_for_3D_Point_Clouds/src/model.py'],\n",
       " 'Learning_explanations_that_are_hard_to_vary': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_explanations_that_are_hard_to_vary/examples/super_resolution/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_explanations_that_are_hard_to_vary/examples/transformers/model.py'],\n",
       " 'Neural_Twins_Talk': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Neural_Twins_Talk/misc/model.py'],\n",
       " 'A_Brief_Survey_and_Comparative_Study_of_Recent_Development_of_Pronoun_Coreference_Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Brief_Survey_and_Comparative_Study_of_Recent_Development_of_Pronoun_Coreference_Resolution/hard_PCR (WSC)/gpt2/src/model.py'],\n",
       " 'Cosine_meets_Softmax__A_tough-to-beat_baseline_for_visual_grounding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cosine_meets_Softmax__A_tough-to-beat_baseline_for_visual_grounding/efficientnet_pytorch/model.py'],\n",
       " 'Networks_with_pixels_embedding__a_method_to_improve_noise_resistance_in_images_classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Networks_with_pixels_embedding__a_method_to_improve_noise_resistance_in_images_classification/Apackage_image_classify_minist_test_noise/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Networks_with_pixels_embedding__a_method_to_improve_noise_resistance_in_images_classification/image_classify_minist_embedding_test_noise/model.py'],\n",
       " 'How_Useful_are_Reviews_for_Recommendation__A_Critical_Review_and_Potential_Improvements': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/How_Useful_are_Reviews_for_Recommendation__A_Critical_Review_and_Potential_Improvements/MPCN/tf_models/model.py'],\n",
       " 'Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/lerf/lerf_sr/model.py'],\n",
       " 'Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/cnn_quantization/tf_cnn_benchmarks/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/imp/max/projects/imp/config/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/meta_reward_learning/textworld/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/stacked_capsule_autoencoders/capsules/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/table_rag/agent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/tf3d/instance_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/tf3d/object_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/tf3d/semantic_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/video_timeline_modeling/vtm/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/cache_replacement/policy_learning/cache_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/fairness_teaching/in_progress/rl_a2c/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/graph_embedding/huge/model.py'],\n",
       " 'Character-level_White-Box_Adversarial_Attacks_against_Transformers_via_Attachable_Subwords_Substitution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Character-level_White-Box_Adversarial_Attacks_against_Transformers_via_Attachable_Subwords_Substitution/token_level_attack/pretrainkit/model.py'],\n",
       " 'UPB_at_SemEval-2020_Task_6__Pretrained_Language_Models_for_Definition_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UPB_at_SemEval-2020_Task_6__Pretrained_Language_Models_for_Definition_Extraction/model.py'],\n",
       " 'Learning_Energy-Based_Models_by_Diffusion_Recovery_Likelihood': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Energy-Based_Models_by_Diffusion_Recovery_Likelihood/model.py'],\n",
       " 'Bayesian_Diffusion_Models_for_3D_Shape_Reconstruction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bayesian_Diffusion_Models_for_3D_Shape_Reconstruction/experiments/model/model.py'],\n",
       " 'Sentence-Incremental_Neural_Coreference_Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sentence-Incremental_Neural_Coreference_Resolution/model.py'],\n",
       " 'Value_Iteration_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Value_Iteration_Networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Value_Iteration_Networks/a2c_ppo_acktr/model.py'],\n",
       " 'BraggNN__Fast_X-ray_Bragg_Peak_Analysis_Using_Deep_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BraggNN__Fast_X-ray_Bragg_Peak_Analysis_Using_Deep_Learning/model.py'],\n",
       " 'Adaptive_Personalized_Federated_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Personalized_Federated_Learning/fedtorch/components/model.py'],\n",
       " 'Federated_Learning_with_Compression__Unified_Analysis_and_Sharp_Guarantees': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Federated_Learning_with_Compression__Unified_Analysis_and_Sharp_Guarantees/fedtorch/components/model.py'],\n",
       " 'Agnostic_Federated_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Agnostic_Federated_Learning/fedtorch/components/model.py'],\n",
       " 'Federated_Optimization_in_Heterogeneous_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Federated_Optimization_in_Heterogeneous_Networks/fedtorch/components/model.py'],\n",
       " 'PU-GAN__a_Point_Cloud_Upsampling_Adversarial_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PU-GAN__a_Point_Cloud_Upsampling_Adversarial_Network/Upsampling/model.py'],\n",
       " 'Transformer_in_Transformer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_in_Transformer/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_in_Transformer/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_in_Transformer/wdsr/src/model.py'],\n",
       " 'TabAug__Data_Driven_Augmentation_for_Enhanced_Table_Structure_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TabAug__Data_Driven_Augmentation_for_Enhanced_Table_Structure_Recognition/libs/model.py'],\n",
       " 'Semantic_Photo_Manipulation_with_a_Generative_Image_Prior': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Photo_Manipulation_with_a_Generative_Image_Prior/editing/styleclip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Photo_Manipulation_with_a_Generative_Image_Prior/models/stylegan2/model.py'],\n",
       " 'Improved_StyleGAN_Embedding__Where_are_the_Good_Latents_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improved_StyleGAN_Embedding__Where_are_the_Good_Latents_/editing/styleclip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improved_StyleGAN_Embedding__Where_are_the_Good_Latents_/models/stylegan2/model.py'],\n",
       " 'Image2StyleGAN__How_to_Embed_Images_Into_the_StyleGAN_Latent_Space_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Image2StyleGAN__How_to_Embed_Images_Into_the_StyleGAN_Latent_Space_/editing/styleclip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Image2StyleGAN__How_to_Embed_Images_Into_the_StyleGAN_Latent_Space_/models/stylegan2/model.py'],\n",
       " 'Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Assessment_LM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Description_LM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Detection_LM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Location_LLM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Location_LM/model.py'],\n",
       " 'A_Multi-View_Deep_Learning_Approach_for_Cross_Domain_User_Modeling_in_Recommendation_Systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-View_Deep_Learning_Approach_for_Cross_Domain_User_Modeling_in_Recommendation_Systems/models/treebased/tdm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-View_Deep_Learning_Approach_for_Cross_Domain_User_Modeling_in_Recommendation_Systems/uapi_rec/base/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-View_Deep_Learning_Approach_for_Cross_Domain_User_Modeling_in_Recommendation_Systems/uapi_rec/rank/model.py'],\n",
       " 'Fast_Nearest_Convolution_for_Real-Time_Efficient_Image_Super-Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fast_Nearest_Convolution_for_Real-Time_Efficient_Image_Super-Resolution/src/model.py'],\n",
       " 'Segment_Anything': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Segment_Anything/deploy/fastdeploy/semantic_segmentation/serving/fastdeploy_serving/models/postprocess/1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Segment_Anything/deploy/fastdeploy/semantic_segmentation/serving/fastdeploy_serving/models/preprocess/1/model.py'],\n",
       " 'Dynamical_Mechanism_of_Sampling-based_Stochastic_Inference_under_Probabilistic_Population_Codes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dynamical_Mechanism_of_Sampling-based_Stochastic_Inference_under_Probabilistic_Population_Codes/probabilistic_inference/model.py'],\n",
       " 'LMOT__Efficient_Light-Weight_Detection_and_Tracking_in_Crowds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LMOT__Efficient_Light-Weight_Detection_and_Tracking_in_Crowds/src/lib/model/model.py'],\n",
       " 'Adaptive_Ranking-based_Sample_Selection_for_Weakly_Supervised_Class-imbalanced_Text_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Ranking-based_Sample_Selection_for_Weakly_Supervised_Class-imbalanced_Text_Classification/wrench/seq_labelmodel/chmm_src/CHMM/Model.py'],\n",
       " 'ShuffleNet__An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ShuffleNet__An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices/model.py'],\n",
       " 'Drafting_and_Revision__Laplacian_Pyramid_Network_for_Fast_High-Quality_Artistic_Style_Transfer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Drafting_and_Revision__Laplacian_Pyramid_Network_for_Fast_High-Quality_Artistic_Style_Transfer/WebDemo/PaddleGAN/ppgan/faceutils/mask/model.py'],\n",
       " 'Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition/simple_pose/src/model.py'],\n",
       " 'Simple_Hardware-Efficient_Long_Convolutions_for_Sequence_Modeling': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Simple_Hardware-Efficient_Long_Convolutions_for_Sequence_Modeling/src/models/sequence/model.py'],\n",
       " 'RAF__Holistic_Compilation_for_Deep_Learning_Model_Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RAF__Holistic_Compilation_for_Deep_Learning_Model_Training/python/raf/frontend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RAF__Holistic_Compilation_for_Deep_Learning_Model_Training/python/raf/model/model.py'],\n",
       " 'Spatial-temporal_Hierarchical_Reinforcement_Learning_for_Interpretable_Pathology_Image_Super-Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial-temporal_Hierarchical_Reinforcement_Learning_for_Interpretable_Pathology_Image_Super-Resolution/PW/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial-temporal_Hierarchical_Reinforcement_Learning_for_Interpretable_Pathology_Image_Super-Resolution/spM_tpW/model.py'],\n",
       " 'Weakly-Supervised_Video_Anomaly_Detection_with_Snippet_Anomalous_Attention': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly-Supervised_Video_Anomaly_Detection_with_Snippet_Anomalous_Attention/FBPrompt-main/eval_scripts/pykp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly-Supervised_Video_Anomaly_Detection_with_Snippet_Anomalous_Attention/SPCTNet-main/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly-Supervised_Video_Anomaly_Detection_with_Snippet_Anomalous_Attention/WS-VAD-mindspore-main/model.py'],\n",
       " 'DivClust__Controlling_Diversity_in_Deep_Clustering': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DivClust__Controlling_Diversity_in_Deep_Clustering/engine/model.py']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40f747cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AttnGAN__Fine-Grained_Text_to_Image_Generation_with_Attentional_Generative_Adversarial_Networks/model.py']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c52ce06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing papers:   2%|▍                      | 11/664 [00:09<09:09,  1.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m class_embeddings \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_name, class_source \u001b[38;5;129;01min\u001b[39;00m classes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 32\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43mget_graphcodebert_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     class_embeddings[class_name] \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Get embeddings for class methods.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [32], line 12\u001b[0m, in \u001b[0;36mget_graphcodebert_embedding\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get model outputs without gradients.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Extract the embedding from the [CLS] token.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m cls_embedding \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    622\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m         output_attentions,\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:562\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    559\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    560\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 562\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:575\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    574\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 575\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:486\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 486\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    488\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/SICC_AUG_22/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dictionary to store embeddings: { paper_title: { file_path: {function_name: embedding} } }\n",
    "model_embeddings_function = {}\n",
    "model_embeddings_class = {}\n",
    "model_embeddings_method = {}\n",
    "model_embeddings_document = {}\n",
    "\n",
    "for paper_title, file_list in tqdm(model_dict.items(), desc=\"Processing papers\"):\n",
    "    paper_results_function={}\n",
    "    paper_results_class={}\n",
    "    paper_results_method={}\n",
    "    paper_results_document={}\n",
    "    for f, file_path in enumerate(file_list):\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "            continue        \n",
    "        \n",
    "        functions = extract_functions(sample_code)\n",
    "        methods = extract_methods(sample_code)\n",
    "        classes = extract_classes(sample_code)\n",
    "        full_document = get_clean_document(sample_code)\n",
    "\n",
    "        # Get embeddings for standalone functions.\n",
    "        function_embeddings = {}\n",
    "        for func_name, func_source in functions.items():\n",
    "            embedding = get_graphcodebert_embedding(func_source)\n",
    "            function_embeddings[func_name] = embedding\n",
    "        class_embeddings = {}\n",
    "        for class_name, class_source in classes.items():\n",
    "            embedding = get_graphcodebert_embedding(class_source)\n",
    "            class_embeddings[class_name] = embedding\n",
    "        # Get embeddings for class methods.\n",
    "        method_embeddings = {}\n",
    "        for method_name, method_source in methods.items():\n",
    "            embedding = get_graphcodebert_embedding(method_source)\n",
    "            method_embeddings[method_name] = embedding\n",
    "\n",
    "        document_embedding = get_graphcodebert_embedding(full_document)\n",
    "\n",
    "        paper_results_function[file_path] = function_embeddings\n",
    "        paper_results_class[file_path] = class_embeddings\n",
    "        paper_results_method[file_path] = method_embeddings\n",
    "        paper_results_document[file_path] = document_embedding\n",
    "\n",
    "        \n",
    "    model_embeddings_function[paper_title] = paper_results_function\n",
    "    model_embeddings_class[paper_title] = paper_results_class\n",
    "    model_embeddings_method[paper_title] = paper_results_method\n",
    "    model_embeddings_document[paper_title] = paper_results_document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a467c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_code_embedding(code: str):\n",
    "    # Tokenize input code\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    # Get model outputs without gradients\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the [CLS] token's embedding as the representation\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b63a663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AttnGAN__Fine-Grained_Text_to_Image_Generation_with_Attentional_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AttnGAN__Fine-Grained_Text_to_Image_Generation_with_Attentional_Generative_Adversarial_Networks/model.py'],\n",
       " 'StackGAN____Realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StackGAN____Realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StackGAN____Realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks/code/model.py'],\n",
       " 'Online_Deep_Learning__Learning_Deep_Neural_Networks_on_the_Fly': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Online_Deep_Learning__Learning_Deep_Neural_Networks_on_the_Fly/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Online_Deep_Learning__Learning_Deep_Neural_Networks_on_the_Fly/src/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Online_Deep_Learning__Learning_Deep_Neural_Networks_on_the_Fly/src/hbp/model.py'],\n",
       " 'Real-Time_Single_Image_and_Video_Super-Resolution_Using_an_Efficient_Sub-Pixel_Convolutional_Neural_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Real-Time_Single_Image_and_Video_Super-Resolution_Using_an_Efficient_Sub-Pixel_Convolutional_Neural_Network/model.py'],\n",
       " 'CNN_CNN__Convolutional_Decoders_for_Image_Captioning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CNN_CNN__Convolutional_Decoders_for_Image_Captioning/models/model.py'],\n",
       " 'Deep_Residual_Learning_for_Image_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Residual_Learning_for_Image_Recognition/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Residual_Learning_for_Image_Recognition/erfnet/src/model.py'],\n",
       " 'U-Net__Convolutional_Networks_for_Biomedical_Image_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/U-Net__Convolutional_Networks_for_Biomedical_Image_Segmentation/UNet/model.py'],\n",
       " 'Deep_Video_Deblurring': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Video_Deblurring/model.py'],\n",
       " 'Sampling_Generative_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sampling_Generative_Networks/model.py'],\n",
       " 'Atlas__End-to-End_3D_Scene_Reconstruction_from_Posed_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Atlas__End-to-End_3D_Scene_Reconstruction_from_Posed_Images/atlas/model.py'],\n",
       " 'NimbRo-OP2X__Adult-sized_Open-source_3D_Printed_Humanoid_Robot': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NimbRo-OP2X__Adult-sized_Open-source_3D_Printed_Humanoid_Robot/model.py'],\n",
       " 'CatBoost__unbiased_boosting_with_categorical_features': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_no_cat_features_CPU-2__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_no_cat_features_CPU-40__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_with_cat_features_CPU-2__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_with_cat_features_CPU-40__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.5-test_export_to_python_with_cat_features_from_pandas_CPU__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_no_cat_features_CPU-2__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_no_cat_features_CPU-40__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_with_cat_features_CPU-2__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_with_cat_features_CPU-40__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/large/canondata/run_python3_tests.test_3.6-test_export_to_python_with_cat_features_from_pandas_CPU__/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/gpu/canondata/test.test_export_to_python_no_cat_features_GPU-2_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/gpu/canondata/test.test_export_to_python_no_cat_features_GPU-40_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/gpu/canondata/test.test_export_to_python_with_cat_features_GPU-2_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/gpu/canondata/test.test_export_to_python_with_cat_features_GPU-40_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_no_cat_features_CPU-2_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_no_cat_features_CPU-40_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_with_cat_features_CPU-2_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_with_cat_features_CPU-40_/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CatBoost__unbiased_boosting_with_categorical_features/catboost/python-package/ut/medium/canondata/test.test_export_to_python_with_cat_features_from_pandas_CPU_/model.py'],\n",
       " 'If_You_Like_It__GAN_It__Probabilistic_Multivariate_Times_Series_Forecast_With_GAN': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/If_You_Like_It__GAN_It__Probabilistic_Multivariate_Times_Series_Forecast_With_GAN/probcast_tensorflow/model.py'],\n",
       " 'Unpaired_Image-to-Image_Translation_using_Cycle-Consistent_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unpaired_Image-to-Image_Translation_using_Cycle-Consistent_Adversarial_Networks/model.py'],\n",
       " 'Attention_Is_All_You_Need': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Attention_Is_All_You_Need/torchnlp/common/model.py'],\n",
       " 'Learning_2D-3D_Correspondences_To_Solve_The_Blind_Perspective-n-Point_Problem': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_2D-3D_Correspondences_To_Solve_The_Blind_Perspective-n-Point_Problem/model/model.py'],\n",
       " 'DARTS__Differentiable_Architecture_Search': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DARTS__Differentiable_Architecture_Search/cnn/model.py'],\n",
       " 'Sequential_Attend__Infer__Repeat__Generative_Modelling_of_Moving_Objects': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sequential_Attend__Infer__Repeat__Generative_Modelling_of_Moving_Objects/sqair/model.py'],\n",
       " 'End-to-end_Sequence_Labeling_via_Bi-directional_LSTM-CNNs-CRF': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/End-to-end_Sequence_Labeling_via_Bi-directional_LSTM-CNNs-CRF/model.py'],\n",
       " 'Generating_Adversarial_Computer_Programs_using_Optimized_Obfuscations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generating_Adversarial_Computer_Programs_using_Optimized_Obfuscations/models/code2seq-merged/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generating_Adversarial_Computer_Programs_using_Optimized_Obfuscations/models/code2seq-targeting/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generating_Adversarial_Computer_Programs_using_Optimized_Obfuscations/models/code2seq/model.py'],\n",
       " 'Self-Attentive_Sequential_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Self-Attentive_Sequential_Recommendation/model.py'],\n",
       " 'Shape_Robust_Text_Detection_with_Progressive_Scale_Expansion_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Shape_Robust_Text_Detection_with_Progressive_Scale_Expansion_Network/nets/model.py'],\n",
       " 'CapsGAN__Using_Dynamic_Routing_for_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CapsGAN__Using_Dynamic_Routing_for_Generative_Adversarial_Networks/capsule_dcgan_mnist/model.py'],\n",
       " 'Sparse_Label_Smoothing_Regularization_for_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sparse_Label_Smoothing_Regularization_for_Person_Re-Identification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sparse_Label_Smoothing_Regularization_for_Person_Re-Identification/DCGAN/model.py'],\n",
       " 'Efficient_Attention_Mechanism_for_Visual_Dialog_that_can_Handle_All_the_Interactions_between_Multiple_Inputs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Efficient_Attention_Mechanism_for_Visual_Dialog_that_can_Handle_All_the_Interactions_between_Multiple_Inputs/visdial/model.py'],\n",
       " 'Layered_Embeddings_for_Amodal_Instance_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Layered_Embeddings_for_Amodal_Instance_Segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Layered_Embeddings_for_Amodal_Instance_Segmentation/mrcnn/model.py'],\n",
       " 'Mask_R-CNN': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mask_R-CNN/proofOfConcept/mask-rcnn/mrcnn/model.py'],\n",
       " 'Conditional_Generative_Adversarial_Nets': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Conditional_Generative_Adversarial_Nets/mnist/model.py'],\n",
       " 'AFS__An_Attention-based_mechanism_for_Supervised_Feature_Selection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AFS__An_Attention-based_mechanism_for_Supervised_Feature_Selection/model.py'],\n",
       " 'The_Numerics_of_GANs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Numerics_of_GANs/ConsensusOptimization/CoinGame/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Numerics_of_GANs/ConsensusOptimization/GAN/model.py'],\n",
       " 'Semantic_Understanding_of_Scenes_through_the_ADE20K_Dataset': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Understanding_of_Scenes_through_the_ADE20K_Dataset/model.py'],\n",
       " 'Towards_Stable_and_Efficient_Training_of_Verifiably_Robust_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Stable_and_Efficient_Training_of_Verifiably_Robust_Neural_Networks/interval_bound_propagation/src/model.py'],\n",
       " 'Off_Environment_Evaluation_Using_Convex_Risk_Minimization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Off_Environment_Evaluation_Using_Convex_Risk_Minimization/cartpole/baselines/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Off_Environment_Evaluation_Using_Convex_Risk_Minimization/reacher/baselines/model.py'],\n",
       " 'Gaussian_processes_with_linear_operator_inequality_constraints': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Gaussian_processes_with_linear_operator_inequality_constraints/GPConstr/model.py'],\n",
       " 'SSD-6D__Making_RGB-based_3D_detection_and_6D_pose_estimation_great_again': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SSD-6D__Making_RGB-based_3D_detection_and_6D_pose_estimation_great_again/rendering/model.py'],\n",
       " 'Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/DialogueGCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/DialogueRNN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/ICON-end-to-end/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/ICON/IEMOCAP/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/bc-LSTM-pytorch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/COSMIC/erc-training/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emotion_Recognition_in_Conversation__Research_Challenges__Datasets__and_Recent_Advances/emotion-cause-extraction/RoBERTa Baseline/simpletransformers/model.py'],\n",
       " 'Improving_Review_Representations_with_User_Attention_and_Product_Attention_for_Sentiment_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Review_Representations_with_User_Attention_and_Product_Attention_for_Sentiment_Classification/HUAPA/code/model.py'],\n",
       " 'Can_Who-Edits-What_Predict_Edit_Survival_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Who-Edits-What_Predict_Edit_Survival_/lib/interank/models/model.py'],\n",
       " 'Convolutional_Gaussian_Processes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Gaussian_Processes/gpflow/models/model.py'],\n",
       " 'emoji2vec__Learning_Emoji_Representations_from_their_Description': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/emoji2vec__Learning_Emoji_Representations_from_their_Description/model.py'],\n",
       " 'Learning_Spatiotemporal_Features_with_3D_Convolutional_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Spatiotemporal_Features_with_3D_Convolutional_Networks/ViolanceDetection-Python/model.py'],\n",
       " 'Augmented_CycleGAN__Learning_Many-to-Many_Mappings_from_Unpaired_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Augmented_CycleGAN__Learning_Many-to-Many_Mappings_from_Unpaired_Data/extra/model.py'],\n",
       " 'Objects_as_Points': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Objects_as_Points/src/lib/models/model.py'],\n",
       " 'Unsupervised_Opinion_Summarization_with_Noising_and_Denoising': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Opinion_Summarization_with_Noising_and_Denoising/src/model.py'],\n",
       " 'End-to-end_speech_enhancement_based_on_discrete_cosine_transform': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/End-to-end_speech_enhancement_based_on_discrete_cosine_transform/model.py'],\n",
       " 'Scene_Text_Detection_with_Supervised_Pyramid_Context_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Scene_Text_Detection_with_Supervised_Pyramid_Context_Network/nets/model.py'],\n",
       " 'MA_3___Model_Agnostic_Adversarial_Augmentation_for_Few_Shot_learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MA_3___Model_Agnostic_Adversarial_Augmentation_for_Few_Shot_learning/prototypical-networks/protonets/utils/model.py'],\n",
       " 'Noise_as_Domain_Shift__Denoising_Medical_Images_by_Unpaired_Image_Translation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Noise_as_Domain_Shift__Denoising_Medical_Images_by_Unpaired_Image_Translation/model.py'],\n",
       " 'Scalable_Hierarchical_Clustering_with_Tree_Grafting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Scalable_Hierarchical_Clustering_with_Tree_Grafting/src/python/grinch/model.py'],\n",
       " 'Physics-informed_neural_networks_for_inverse_problems_in_nano-optics_and_metamaterials': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Physics-informed_neural_networks_for_inverse_problems_in_nano-optics_and_metamaterials/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Physics-informed_neural_networks_for_inverse_problems_in_nano-optics_and_metamaterials/deepxde/zcs/model.py'],\n",
       " 'Convolutional_Neural_Networks_on_non-uniform_geometrical_signals_using_Euclidean_spectral_transformation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Neural_Networks_on_non-uniform_geometrical_signals_using_Euclidean_spectral_transformation/experiments/exp2_mnist/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Neural_Networks_on_non-uniform_geometrical_signals_using_Euclidean_spectral_transformation/experiments/exp3_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Neural_Networks_on_non-uniform_geometrical_signals_using_Euclidean_spectral_transformation/experiments/exp4_3drecon/model.py'],\n",
       " 'Benchmarking_TinyML_Systems__Challenges_and_Direction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_TinyML_Systems__Challenges_and_Direction/benchmark/experimental/training_torch/image_classification/utils/model.py'],\n",
       " 'Depth_from_Videos_in_the_Wild__Unsupervised_Monocular_Depth_Learning_from_Unknown_Cameras': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_from_Videos_in_the_Wild__Unsupervised_Monocular_Depth_Learning_from_Unknown_Cameras/model.py'],\n",
       " 'Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/beit2/vqkd_teacher/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/edgelm/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/kosmos-2/open_clip/src/open_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/GAD/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/GAD/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/GAD/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/GAD/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/IAD/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/IAD/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/IAD/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/decoding/IAD/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/infoxlm/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/infoxlm/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/xdoc/fine_tuning/funsd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Document_Image_Classification_with_Intra-Domain_Transfer_Learning_and_Stacked_Generalization_of_Deep_Convolutional_Neural_Networks/xdoc/fine_tuning/websrc/model.py'],\n",
       " 'Deep_Learning_Based_Text_Classification__A_Comprehensive_Review': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/DBNet/src/modules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Based_Text_Classification__A_Comprehensive_Review/luke/src/relation_classification/model.py'],\n",
       " 'Hide_and_Speak__Towards_Deep_Neural_Networks_for_Speech_Steganography': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hide_and_Speak__Towards_Deep_Neural_Networks_for_Speech_Steganography/model.py'],\n",
       " 'LightGCN__Simplifying_and_Powering_Graph_Convolution_Network_for_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LightGCN__Simplifying_and_Powering_Graph_Convolution_Network_for_Recommendation/code/model.py'],\n",
       " 'Multi-View_Attention_Network_for_Visual_Dialog': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-View_Attention_Network_for_Visual_Dialog/visdial/model.py'],\n",
       " 'EAST__An_Efficient_and_Accurate_Scene_Text_Detector': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EAST__An_Efficient_and_Accurate_Scene_Text_Detector/model.py'],\n",
       " 'Semantic_Instance_Segmentation_with_a_Discriminative_Loss_Function': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Instance_Segmentation_with_a_Discriminative_Loss_Function/code/lib/model.py'],\n",
       " 'Environmental_Sound_Classification_on_Microcontrollers_using_Convolutional_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Environmental_Sound_Classification_on_Microcontrollers_using_Convolutional_Neural_Networks/model.py'],\n",
       " 'World_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/World_Models/model.py'],\n",
       " 'Learning_to_do_multiframe_wavefront_sensing_unsupervisedly__applications_to_blind_deconvolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_do_multiframe_wavefront_sensing_unsupervisedly__applications_to_blind_deconvolution/model.py'],\n",
       " 'The_Devil_is_in_the_Decoder__Classification__Regression_and_GANs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Devil_is_in_the_Decoder__Classification__Regression_and_GANs/model.py'],\n",
       " 'CodeSearchNet_Challenge__Evaluating_the_State_of_Semantic_Code_Search': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CodeSearchNet_Challenge__Evaluating_the_State_of_Semantic_Code_Search/codenets/codesearchnet/query_1_code_1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CodeSearchNet_Challenge__Evaluating_the_State_of_Semantic_Code_Search/codenets/codesearchnet/query_1_code_n/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CodeSearchNet_Challenge__Evaluating_the_State_of_Semantic_Code_Search/codenets/codesearchnet/query_code_siamese/model.py'],\n",
       " 'Time_Window_Temporal_Logic': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Time_Window_Temporal_Logic/src/lomap/classes/model.py'],\n",
       " 'Proximal_Mapping_for_Deep_Regularization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Proximal_Mapping_for_Deep_Regularization/img_classify/model.py'],\n",
       " 'DDSL__Deep_Differentiable_Simplex_Layer_for_Learning_Geometric_Signals': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDSL__Deep_Differentiable_Simplex_Layer_for_Learning_Geometric_Signals/experiments/exp2_mnist/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDSL__Deep_Differentiable_Simplex_Layer_for_Learning_Geometric_Signals/experiments/exp3_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDSL__Deep_Differentiable_Simplex_Layer_for_Learning_Geometric_Signals/experiments/exp4_3drecon/model.py'],\n",
       " 'VCWE__Visual_Character-Enhanced_Word_Embeddings': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VCWE__Visual_Character-Enhanced_Word_Embeddings/model.py'],\n",
       " 'Detecting_and_Reducing_Bias_in_a_High_Stakes_Domain': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_and_Reducing_Bias_in_a_High_Stakes_Domain/src/model.py'],\n",
       " 'Data-efficient_Neural_Text_Compression_with_Interactive_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Data-efficient_Neural_Text_Compression_with_Interactive_Learning/onmt/models/model.py'],\n",
       " 'DreamCoder__Growing_generalizable__interpretable_knowledge_with_wake-sleep_Bayesian_program_learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DreamCoder__Growing_generalizable__interpretable_knowledge_with_wake-sleep_Bayesian_program_learning/prototypical-networks/protonets/utils/model.py'],\n",
       " 'Densely_Connected_Convolutional_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Densely_Connected_Convolutional_Networks/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Style_Transfer_from_Non-Parallel_Text_by_Cross-Alignment': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Style_Transfer_from_Non-Parallel_Text_by_Cross-Alignment/code-pytorch/model.py'],\n",
       " 'Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/mxnet/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/mxnet/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/capsule/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/dgmg/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/han/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/metapath2vec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/pointcloud/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/rgcn-hetero/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/pytorch/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Library__A_Graph-Centric__Highly-Performant_Package_for_Graph_Neural_Networks/examples/tensorflow/rgcn/model.py'],\n",
       " 'ComGAN__Toward_GANs_Exploiting_Multiple_Samples': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ComGAN__Toward_GANs_Exploiting_Multiple_Samples/src/models/model.py'],\n",
       " 'A_comprehensive_and_fair_comparison_of_two_neural_operators__with_practical_extensions__based_on_FAIR_data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_comprehensive_and_fair_comparison_of_two_neural_operators__with_practical_extensions__based_on_FAIR_data/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_comprehensive_and_fair_comparison_of_two_neural_operators__with_practical_extensions__based_on_FAIR_data/deepxde/zcs/model.py'],\n",
       " 'Learning_non-Markovian_Decision-Making_from_State-only_Sequences': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_non-Markovian_Decision-Making_from_State-only_Sequences/mujoco/model.py'],\n",
       " 'Delayed_interactions_in_the_noisy_voter_model_through_the_periodic_polling_mechanism': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Delayed_interactions_in_the_noisy_voter_model_through_the_periodic_polling_mechanism/gillespie_sim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Delayed_interactions_in_the_noisy_voter_model_through_the_periodic_polling_mechanism/macro_sim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Delayed_interactions_in_the_noisy_voter_model_through_the_periodic_polling_mechanism/mc_sim/model.py'],\n",
       " 'ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ROS-LLM__A_ROS_framework_for_embodied_AI_with_task_feedback_and_structured_reasoning/RLLG/agents/common/model.py'],\n",
       " 'DeepMPCVS__Deep_Model_Predictive_Control_for_Visual_Servoing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepMPCVS__Deep_Model_Predictive_Control_for_Visual_Servoing/model.py'],\n",
       " 'Arbitrary-Oriented_Ship_Detection_through_Center-Head_Point_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Arbitrary-Oriented_Ship_Detection_through_Center-Head_Point_Extraction/src/lib/models/model.py'],\n",
       " 'Learning_Off-By-One_Mistakes__An_Empirical_Study': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Off-By-One_Mistakes__An_Empirical_Study/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Off-By-One_Mistakes__An_Empirical_Study/bugram/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Off-By-One_Mistakes__An_Empirical_Study/code2seq/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Off-By-One_Mistakes__An_Empirical_Study/offside-webpage/backend/model.py'],\n",
       " 'DAG-based_Scheduling_with_Resource_Sharing_for_Multi-task_Applications_in_a_Polyglot_GPU_Runtime': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAG-based_Scheduling_with_Resource_Sharing_for_Multi-task_Applications_in_a_Polyglot_GPU_Runtime/examples/tensorrt/python/model.py'],\n",
       " 'HarDNet__A_Low_Memory_Traffic_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HarDNet__A_Low_Memory_Traffic_Network/models/model.py'],\n",
       " 'End_to_End_Trainable_Active_Contours_via_Differentiable_Rendering': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/End_to_End_Trainable_Active_Contours_via_Differentiable_Rendering/models/model.py'],\n",
       " 'Modality_to_Modality_Translation__An_Adversarial_Representation_Learning_and_Graph_Fusion_Network_for_Multimodal_Fusion': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Modality_to_Modality_Translation__An_Adversarial_Representation_Learning_and_Graph_Fusion_Network_for_Multimodal_Fusion/ARGF/ARGF_context2/model.py'],\n",
       " 'Guided_Collaborative_Training_for_Pixel-wise_Semi-Supervised_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Guided_Collaborative_Training_for_Pixel-wise_Semi-Supervised_Learning/pixelssl/task_template/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Guided_Collaborative_Training_for_Pixel-wise_Semi-Supervised_Learning/task/sseg/model.py'],\n",
       " 'Semi-supervised_semantic_segmentation_needs_strong__varied_perturbations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_semantic_segmentation_needs_strong__varied_perturbations/pixelssl/task_template/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_semantic_segmentation_needs_strong__varied_perturbations/task/sseg/model.py'],\n",
       " 'Semi-Supervised_Semantic_Segmentation_with_Cross-Consistency_Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-Supervised_Semantic_Segmentation_with_Cross-Consistency_Training/pixelssl/task_template/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-Supervised_Semantic_Segmentation_with_Cross-Consistency_Training/task/sseg/model.py'],\n",
       " 'Improving_Language_Understanding_by_Generative_Pre-Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Language_Understanding_by_Generative_Pre-Training/model.py'],\n",
       " 'Adaptive_Hinge_Balance_Loss_for_Document-Level_Relation_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Hinge_Balance_Loss_for_Document-Level_Relation_Extraction/model.py'],\n",
       " 'You_Only_Watch_Once__A_Unified_CNN_Architecture_for_Real-Time_Spatiotemporal_Action_Localization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/You_Only_Watch_Once__A_Unified_CNN_Architecture_for_Real-Time_Spatiotemporal_Action_Localization/applications/T2VLAD/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/You_Only_Watch_Once__A_Unified_CNN_Architecture_for_Real-Time_Spatiotemporal_Action_Localization/applications/VideoTag/models/model.py'],\n",
       " 'Benchmarking_Graph_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/mxnet/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/mxnet/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/capsule/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/dgmg/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/han/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/metapath2vec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/pointcloud/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/rgcn-hetero/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/pytorch/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Graph_Neural_Networks/examples/tensorflow/rgcn/model.py'],\n",
       " 'High_Quality_Monocular_Depth_Estimation_via_Transfer_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High_Quality_Monocular_Depth_Estimation_via_Transfer_Learning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High_Quality_Monocular_Depth_Estimation_via_Transfer_Learning/PyTorch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High_Quality_Monocular_Depth_Estimation_via_Transfer_Learning/Tensorflow/model.py'],\n",
       " 'Deep_Learning_for_Automatic_Pneumonia_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_for_Automatic_Pneumonia_Detection/src/pytorch_retinanet/model.py'],\n",
       " 'Few-shot_Learning_with_Multilingual_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Few-shot_Learning_with_Multilingual_Language_Models/fairseq/models/xmod/model.py'],\n",
       " 'VoxelNet__End-to-End_Learning_for_Point_Cloud_Based_3D_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VoxelNet__End-to-End_Learning_for_Point_Cloud_Based_3D_Object_Detection/sem_seg/model.py'],\n",
       " 'PCPNET__Learning_Local_Shape_Properties_from_Raw_Point_Clouds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PCPNET__Learning_Local_Shape_Properties_from_Raw_Point_Clouds/sem_seg/model.py'],\n",
       " 'PointNet__Deep_Learning_on_Point_Sets_for_3D_Classification_and_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PointNet__Deep_Learning_on_Point_Sets_for_3D_Classification_and_Segmentation/sem_seg/model.py'],\n",
       " 'DeepXDE__A_deep_learning_library_for_solving_differential_equations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepXDE__A_deep_learning_library_for_solving_differential_equations/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepXDE__A_deep_learning_library_for_solving_differential_equations/deepxde/zcs/model.py'],\n",
       " 'A_Higher-Order_Semantic_Dependency_Parser': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Higher-Order_Semantic_Dependency_Parser/supar/models/model.py'],\n",
       " 'SC-FEGAN__Face_Editing_Generative_Adversarial_Network_with_User_s_Sketch_and_Color': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SC-FEGAN__Face_Editing_Generative_Adversarial_Network_with_User_s_Sketch_and_Color/model.py'],\n",
       " 'Neural_Architectures_for_Named_Entity_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Neural_Architectures_for_Named_Entity_Recognition/model.py'],\n",
       " 'YOLOv4__Optimal_Speed_and_Accuracy_of_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/YOLOv4__Optimal_Speed_and_Accuracy_of_Object_Detection/deep_sort_pytorch/deep_sort/deep/model.py'],\n",
       " 'A_Deep_Reinforced_Model_for_Abstractive_Summarization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Deep_Reinforced_Model_for_Abstractive_Summarization/model.py'],\n",
       " 'DGTN__Dual-channel_Graph_Transition_Network_for_Session-based_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DGTN__Dual-channel_Graph_Transition_Network_for_Session-based_Recommendation/model/model.py'],\n",
       " 'Learning_Tree-based_Deep_Model_for_Recommender_Systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Tree-based_Deep_Model_for_Recommender_Systems/backend/model.py'],\n",
       " 'Visual_Dialog': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Visual_Dialog/visdialch/model.py'],\n",
       " 'Hierarchical_Neural_Story_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hierarchical_Neural_Story_Generation/storygeneration/model.py'],\n",
       " 'Robust_Robotic_Pouring_using_Audition_and_Haptics': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robust_Robotic_Pouring_using_Audition_and_Haptics/audio_pouring/model/model.py'],\n",
       " 'Semi-supervised_Formality_Style_Transfer_using_Language_Model_Discriminator_and_Mutual_Information_Maximization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_Formality_Style_Transfer_using_Language_Model_Discriminator_and_Mutual_Information_Maximization/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_Formality_Style_Transfer_using_Language_Model_Discriminator_and_Mutual_Information_Maximization/fairseq/models/roberta/model.py'],\n",
       " 'Deep_Reinforcement_Learning_for_Producing_Furniture_Layout_in_Indoor_Scenes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Reinforcement_Learning_for_Producing_Furniture_Layout_in_Indoor_Scenes/code/model.py'],\n",
       " 'Actor-Attention-Critic_for_Multi-Agent_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Actor-Attention-Critic_for_Multi-Agent_Reinforcement_Learning/MAAC/baselines-master/baselines/ppo2/model.py'],\n",
       " 'On_The_Cross-Modal_Transfer_from_Natural_Language_to_Code_through_Adapter_Modules': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_The_Cross-Modal_Transfer_from_Natural_Language_to_Code_through_Adapter_Modules/CodeCloneDetection-BCB/code/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_The_Cross-Modal_Transfer_from_Natural_Language_to_Code_through_Adapter_Modules/CodeCloneDetection-POJ-104/code/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_The_Cross-Modal_Transfer_from_Natural_Language_to_Code_through_Adapter_Modules/CodeCloneDetection-SCD-88/code/model.py'],\n",
       " 'D2-Net__A_Trainable_CNN_for_Joint_Detection_and_Description_of_Local_Features': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/D2-Net__A_Trainable_CNN_for_Joint_Detection_and_Description_of_Local_Features/lib/model.py'],\n",
       " 'Simple_Online_and_Realtime_Tracking_with_a_Deep_Association_Metric': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Simple_Online_and_Realtime_Tracking_with_a_Deep_Association_Metric/deep_sort_pytorch/deep_sort/deep/model.py'],\n",
       " 'Constructing_A_Flexible_Likelihood_Function_For_Spectroscopic_Inference': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Constructing_A_Flexible_Likelihood_Function_For_Spectroscopic_Inference/Starfish/model.py'],\n",
       " 'Assessing_Pattern_Recognition_Performance_of_Neuronal_Cultures_through_Accurate_Simulation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Assessing_Pattern_Recognition_Performance_of_Neuronal_Cultures_through_Accurate_Simulation/model.py'],\n",
       " 'LERF__Language_Embedded_Radiance_Fields': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LERF__Language_Embedded_Radiance_Fields/lerf/lerf_sr/model.py'],\n",
       " 'Cross-Domain_Sentiment_Classification_with_In-Domain_Contrastive_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cross-Domain_Sentiment_Classification_with_In-Domain_Contrastive_Learning/model.py'],\n",
       " 'L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/ResNet50/image_classification/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L-GreCo__Layerwise-Adaptive_Gradient_Compression_for_Efficient_and_Accurate_Deep_Learning/Transformer-LM/fairseq/models/xmod/model.py'],\n",
       " 'Social_NCE__Contrastive_Learning_of_Socially-aware_Motion_Representations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Social_NCE__Contrastive_Learning_of_Socially-aware_Motion_Representations/trajectron/snce/model.py'],\n",
       " 'Learning__Planning__and_Control_in_a_Monolithic_Neural_Event_Inference_Architecture': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning__Planning__and_Control_in_a_Monolithic_Neural_Event_Inference_Architecture/tests/model.py'],\n",
       " 'PS_2-Net__A_Locally_and_Globally_Aware_Network_for_Point-Based_Semantic_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PS_2-Net__A_Locally_and_Globally_Aware_Network_for_Point-Based_Semantic_Segmentation/models/model.py'],\n",
       " 'Hierarchical_Attentive_Recurrent_Tracking': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hierarchical_Attentive_Recurrent_Tracking/neurocity/component/model/model.py'],\n",
       " 'Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding/pyabsa/tasks/ABSAInstruction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding/pyabsa/tasks/AspectSentimentTripletExtraction/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding/pyabsa/tasks/UniversalSentimentAnalysis/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Fine-grained_Sentiment_Classification_Exploiting_Local_Context_Embedding/pyabsa/tasks/__SubtaskTemplate__/models/model.py'],\n",
       " 'Open_Graph_Benchmark__Datasets_for_Machine_Learning_on_Graphs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Open_Graph_Benchmark__Datasets_for_Machine_Learning_on_Graphs/examples/linkproppred/biokg/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Open_Graph_Benchmark__Datasets_for_Machine_Learning_on_Graphs/examples/linkproppred/wikikg2/model.py'],\n",
       " 'Transferable_Adversarial_Attacks_for_Image_and_Video_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transferable_Adversarial_Attacks_for_Image_and_Video_Object_Detection/api/tog/yolov3_utils/model.py'],\n",
       " 'TOG__Targeted_Adversarial_Objectness_Gradient_Attacks_on_Real-time_Object_Detection_Systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TOG__Targeted_Adversarial_Objectness_Gradient_Attacks_on_Real-time_Object_Detection_Systems/api/tog/yolov3_utils/model.py'],\n",
       " 'Deep_Graph_Infomax': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/P-GNN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/arma/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/bgrl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/capsule/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/caregnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/correct_and_smooth/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/dgmg/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/dtgrnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/eges/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/evolveGCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/gas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/gcmc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/geniepath/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/grace/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/grand/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/graphsage/advanced/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/han/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/hgt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/infograph/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/jknet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/labor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/metapath2vec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/node2vec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/pinsage/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/rect/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/rgcn-hetero/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/seal/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/stgcn_wave/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/vgae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/NGCF/NGCF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/mvgrl/graph/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/mvgrl/node/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/ogb/deepwalk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/ogb/line/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/pytorch/pointcloud/edgeconv/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/core/Graphormer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/mxnet/rgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Graph_Infomax/examples/tensorflow/rgcn/model.py'],\n",
       " 'YOLOv3__An_Incremental_Improvement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/YOLOv3__An_Incremental_Improvement/model.py'],\n",
       " 'PINNs_for_the_Solution_of_the_Hyperbolic_Buckley-Leverett_Problem_with_a_Non-convex_Flux_Function': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PINNs_for_the_Solution_of_the_Hyperbolic_Buckley-Leverett_Problem_with_a_Non-convex_Flux_Function/opt/src/fastspeech2_ms/utils/model.py'],\n",
       " 'NeMo_Inverse_Text_Normalization__From_Development_To_Production': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/diffusion/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/diffusion/models/flux/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/diffusion/models/flux_controlnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/llm/distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeMo_Inverse_Text_Normalization__From_Development_To_Production/nemo/collections/multimodal/modules/stable_diffusion/diffusionmodules/model.py'],\n",
       " 'Assessing_the_Reliability_of_Deep_Learning_Classifiers_Through_Robustness_Evaluation_and_Operational_Profiles': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Assessing_the_Reliability_of_Deep_Learning_Classifiers_Through_Robustness_Evaluation_and_Operational_Profiles/model.py'],\n",
       " 'Session-based_Recommendation_with_Graph_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Session-based_Recommendation_with_Graph_Neural_Networks/src/model.py'],\n",
       " 'From_Canonical_Correlation_Analysis_to_Self-supervised_Graph_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/From_Canonical_Correlation_Analysis_to_Self-supervised_Graph_Neural_Networks/model.py'],\n",
       " 'Pointer_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Pointer_Networks/model.py'],\n",
       " 'DefSent__Sentence_Embeddings_using_Definition_Sentences': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DefSent__Sentence_Embeddings_using_Definition_Sentences/defsent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DefSent__Sentence_Embeddings_using_Definition_Sentences/experiments/src/model.py'],\n",
       " 'Going_Beyond_Linear_Transformers_with_Recurrent_Fast_Weight_Programmers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Going_Beyond_Linear_Transformers_with_Recurrent_Fast_Weight_Programmers/algorithmic/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Going_Beyond_Linear_Transformers_with_Recurrent_Fast_Weight_Programmers/reinforcement_learning/torchbeast/model.py'],\n",
       " 'Swin_Transformer__Hierarchical_Vision_Transformer_using_Shifted_Windows': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Swin_Transformer__Hierarchical_Vision_Transformer_using_Shifted_Windows/swintransformer/model.py'],\n",
       " 'Predictive_Modeling_with_Temporal_Graphical_Representation_on_Electronic_Health_Records': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Predictive_Modeling_with_Temporal_Graphical_Representation_on_Electronic_Health_Records/models/Model.py'],\n",
       " 'DAPPLE__A_Pipelined_Data_Parallel_Approach_for_Training_Large_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAPPLE__A_Pipelined_Data_Parallel_Approach_for_Training_Large_Models/bert/models/nmt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAPPLE__A_Pipelined_Data_Parallel_Approach_for_Training_Large_Models/gnmt/nmt/model.py'],\n",
       " 'REAL-M__Towards_Speech_Separation_on_Real_Mixtures': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/REAL-M__Towards_Speech_Separation_on_Real_Mixtures/speechbrain/lobes/models/g2p/model.py'],\n",
       " 'Emerging_Properties_in_Self-Supervised_Vision_Transformers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Emerging_Properties_in_Self-Supervised_Vision_Transformers/self_driving_car/ML Agent/model.py'],\n",
       " 'D-VDAMP__Denoising-based_Approximate_Message_Passing_for_Compressive_MRI': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/D-VDAMP__Denoising-based_Approximate_Message_Passing_for_Compressive_MRI/train/model.py'],\n",
       " 'SUREMap__Predicting_Uncertainty_in_CNN-based_Image_Reconstruction_Using_Stein_s_Unbiased_Risk_Estimate': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SUREMap__Predicting_Uncertainty_in_CNN-based_Image_Reconstruction_Using_Stein_s_Unbiased_Risk_Estimate/train/model.py'],\n",
       " 'DeepMIH__Deep_Invertible_Network_for_MultipleImage_Hiding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepMIH__Deep_Invertible_Network_for_MultipleImage_Hiding/model.py'],\n",
       " 'TPS____Attention-Enhanced_Thin-Plate_Spline_for_Scene_Text_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TPS____Attention-Enhanced_Thin-Plate_Spline_for_Scene_Text_Recognition/mmocr/utils/model.py'],\n",
       " 'Transformer_Transducer__A_Streamable_Speech_Recognition_Model_with_Transformer_Encoders_and_RNN-T_Loss': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_Transducer__A_Streamable_Speech_Recognition_Model_with_Transformer_Encoders_and_RNN-T_Loss/transformer_transducer/model.py'],\n",
       " 'Convolutional_Networks_for_Spherical_Signals': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Convolutional_Networks_for_Spherical_Signals/examples/shrec17/model.py'],\n",
       " 'MVTN__Multi-View_Transformation_Network_for_3D_Shape_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MVTN__Multi-View_Transformation_Network_for_3D_Shape_Recognition/viewGCN/model/Model.py'],\n",
       " 'Causal-aware_Safe_Policy_Improvement_for_Task-oriented_dialogue': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Causal-aware_Safe_Policy_Improvement_for_Task-oriented_dialogue/damd_multiwoz/model.py'],\n",
       " 'Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction/model/model.py'],\n",
       " 'MISA__Modality-Invariant_and_-Specific_Representations_for_Multimodal_Sentiment_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MISA__Modality-Invariant_and_-Specific_Representations_for_Multimodal_Sentiment_Analysis/Low-rank-Multimodal-Fusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MISA__Modality-Invariant_and_-Specific_Representations_for_Multimodal_Sentiment_Analysis/TensorFusionNetworks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MISA__Modality-Invariant_and_-Specific_Representations_for_Multimodal_Sentiment_Analysis/contextual-attention-based-LSTM/model.py'],\n",
       " 'Revisiting_Batch_Normalization_for_Training_Low-latency_Deep_Spiking_Neural_Networks_from_Scratch': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Revisiting_Batch_Normalization_for_Training_Low-latency_Deep_Spiking_Neural_Networks_from_Scratch/model.py'],\n",
       " 'An_Empirical_Study_on_Leveraging_Position_Embeddings_for_Target-oriented_Opinion_Words_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/An_Empirical_Study_on_Leveraging_Position_Embeddings_for_Target-oriented_Opinion_Words_Extraction/model.py'],\n",
       " 'Graph_Representation_Learning_via_Aggregation_Enhancement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Graph_Representation_Learning_via_Aggregation_Enhancement/graph_self_supervised_learning/model.py'],\n",
       " 'Complexity-Weighted_Loss_and_Diverse_Reranking_for_Sentence_Simplification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Complexity-Weighted_Loss_and_Diverse_Reranking_for_Sentence_Simplification/new_scripts/predict_sentence_level/CNN-sentence-classification-pytorch-master/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Complexity-Weighted_Loss_and_Diverse_Reranking_for_Sentence_Simplification/sockeye_loss/sockeye/model.py'],\n",
       " 'StackGAN__Text_to_Photo-realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StackGAN__Text_to_Photo-realistic_Image_Synthesis_with_Stacked_Generative_Adversarial_Networks/model.py'],\n",
       " 'Visual_Attention_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Visual_Attention_Network/examples/llama_inference/model.py'],\n",
       " 'Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/beit2/vqkd_teacher/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/edgelm/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/kosmos-2/open_clip/src/open_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/GAD/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/GAD/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/GAD/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/GAD/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/IAD/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/IAD/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/IAD/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/decoding/IAD/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/infoxlm/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/infoxlm/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/xdoc/fine_tuning/funsd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cutting_the_Error_by_Half__Investigation_of_Very_Deep_CNN_and_Advanced_Training_Strategies_for_Document_Image_Classification/xdoc/fine_tuning/websrc/model.py'],\n",
       " 'CheXbert__Combining_Automatic_Labelers_and_Expert_Annotations_for_Accurate_Radiology_Report_Labeling_Using_BERT': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CheXbert__Combining_Automatic_Labelers_and_Expert_Annotations_for_Accurate_Radiology_Report_Labeling_Using_BERT/chexpert_approximator/model.py'],\n",
       " 'Bridging_the_Domain_Gap__Self-Supervised_3D_Scene_Understanding_with_Foundation_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridging_the_Domain_Gap__Self-Supervised_3D_Scene_Understanding_with_Foundation_Models/Pretrain/clip/model.py'],\n",
       " 'Get_To_The_Point__Summarization_with_Pointer-Generator_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Get_To_The_Point__Summarization_with_Pointer-Generator_Networks/model.py'],\n",
       " 'StyleIPSB__Identity-Preserving_Semantic_Basis_of_StyleGAN_for_High_Fidelity_Face_Swapping': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StyleIPSB__Identity-Preserving_Semantic_Basis_of_StyleGAN_for_High_Fidelity_Face_Swapping/stylegan2-pytorch/model.py'],\n",
       " 'Modeling_Graphs_with_Vertex_Replacement_Grammars': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Modeling_Graphs_with_Vertex_Replacement_Grammars/src/vog/MDL/model.py'],\n",
       " 'Studying_the_Usage_of_Text-To-Text_Transfer_Transformer_to_Support_Code-Related_Tasks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Studying_the_Usage_of_Text-To-Text_Transfer_Transformer_to_Support_Code-Related_Tasks/NeuralCodeSum/main/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Studying_the_Usage_of_Text-To-Text_Transfer_Transformer_to_Support_Code-Related_Tasks/CodeBERT/code/model.py'],\n",
       " 'Discrete_Representations_Strengthen_Vision_Transformer_Robustness': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Discrete_Representations_Strengthen_Vision_Transformer_Robustness/benchmarks/imagenet-e/ImageNet-Editing/editing_diffusion/CLIP/clip/model.py'],\n",
       " 'PanoFormer__Panorama_Transformer_for_Indoor_360_Depth_Estimation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PanoFormer__Panorama_Transformer_for_Indoor_360_Depth_Estimation/PanoFormer/network/model.py'],\n",
       " 'Unifying_Multimodal_Transformer_for_Bi-directional_Image_and_Text_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unifying_Multimodal_Transformer_for_Bi-directional_Image_and_Text_Generation/it-generator/evaluation/inception_score/model.py'],\n",
       " 'A_Picture_is_Worth_a_Thousand_Words__A_Unified_System_for_Diverse_Captions_and_Rich_Images_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Picture_is_Worth_a_Thousand_Words__A_Unified_System_for_Diverse_Captions_and_Rich_Images_Generation/it-generator/evaluation/inception_score/model.py'],\n",
       " 'EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/applications/MULLM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/paddlemix/models/audioldm2/clap_module/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/paddlemix/models/audioldm2/hifigan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/paddlemix/models/diffsinger/modules/pe/rmvpe/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/adalora/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/ia3/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/loha/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/lokr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/lora/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/mixed/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/multitask_prompt_tuning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/oft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/p_tuning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/prefix_tuning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/ppdiffusers/peft/tuners/prompt_tuning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/PhotoMaker/photomaker/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/consistency_distillation/lcm_trainer/lcm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/controlnet/control/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/ip_adapter/ip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/stable_diffusion/sd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/t2i-adapter/adapter/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/text_to_image_laion400m/ldm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/text_to_image_mscoco_uvit/ldm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/AnimateAnyone/src/trainer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/Open-Sora/trainer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/autoencoder/vae/ldm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/visual_tokenizer/open-magvit2/taming/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVA__Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_Scale/ppdiffusers/examples/visual_tokenizer/open-magvit2/taming/modules/discriminator/model.py'],\n",
       " 'HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HEBO_Pushing_The_Limits_of_Sample-Efficient_Hyperparameter_Optimisation/RLLG/agents/common/model.py'],\n",
       " 'Dimensional_Emotion_Detection_from_Categorical_Emotion': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dimensional_Emotion_Detection_from_Categorical_Emotion/src/models/model.py'],\n",
       " 'Generalized_Clustering_and_Multi-Manifold_Learning_with_Geometric_Structure_Preservation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generalized_Clustering_and_Multi-Manifold_Learning_with_Geometric_Structure_Preservation/model.py'],\n",
       " 'TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TernaryBERT__Distillation-aware_Ultra-low_Bit_BERT/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Improving_Inductive_Link_Prediction_Using_Hyper-Relational_Facts': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Inductive_Link_Prediction_Using_Hyper-Relational_Facts/openke/module/model/Model.py'],\n",
       " 'Analysis_of_Training_Object_Detection_Models_with_Synthetic_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Analysis_of_Training_Object_Detection_Models_with_Synthetic_Data/mrcnn/model.py'],\n",
       " 'Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/Contents/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bridge_the_Gap_Between_Architecture_Spaces_via_A_Cross-Domain_Predictor/aecrnet/src/models/model.py'],\n",
       " 'Deep_Learning_Face_Representation_from_Predicting_10_000_Classes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_Face_Representation_from_Predicting_10_000_Classes/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Multifidelity_deep_neural_operators_for_efficient_learning_of_partial_differential_equations_with_application_to_fast_inverse_design_of_nanoscale_heat_transport': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multifidelity_deep_neural_operators_for_efficient_learning_of_partial_differential_equations_with_application_to_fast_inverse_design_of_nanoscale_heat_transport/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multifidelity_deep_neural_operators_for_efficient_learning_of_partial_differential_equations_with_application_to_fast_inverse_design_of_nanoscale_heat_transport/deepxde/zcs/model.py'],\n",
       " 'Enhancing_Unsupervised_Video_Representation_Learning_by_Decoupling_the_Scene_and_the_Motion': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Unsupervised_Video_Representation_Learning_by_Decoupling_the_Scene_and_the_Motion/src/model/model.py'],\n",
       " 'Spatial_Transformer_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial_Transformer_Networks/src/model/model.py'],\n",
       " 'WOOD__Wasserstein-based_Out-of-Distribution_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/WOOD__Wasserstein-based_Out-of-Distribution_Detection/Model.py'],\n",
       " 'Semi-supervised_teacher-student_deep_neural_network_for_materials_discovery': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_teacher-student_deep_neural_network_for_materials_discovery/pu_cgcnn/cgcnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semi-supervised_teacher-student_deep_neural_network_for_materials_discovery/tsdnn/model.py'],\n",
       " 'Meta_Pseudo_Labels': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Meta_Pseudo_Labels/pu_cgcnn/cgcnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Meta_Pseudo_Labels/tsdnn/model.py'],\n",
       " 'Permutation_Equivariant_Graph_Framelets_for_Heterophilous_Graph_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Permutation_Equivariant_Graph_Framelets_for_Heterophilous_Graph_Learning/model.py'],\n",
       " 'LipNet__End-to-End_Sentence-level_Lipreading': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LipNet__End-to-End_Sentence-level_Lipreading/lipnet/model.py'],\n",
       " 'Rethinking_Negative_Pairs_in_Code_Search': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Rethinking_Negative_Pairs_in_Code_Search/GraphCodeBERT/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Rethinking_Negative_Pairs_in_Code_Search/UniXCoder/model.py'],\n",
       " 'A_Framework_for_Interdomain_and_Multioutput_Gaussian_Processes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Framework_for_Interdomain_and_Multioutput_Gaussian_Processes/gpflow/models/model.py'],\n",
       " 'Detecting_Corrupted_Labels_Without_Training_a_Model_to_Predict': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_Corrupted_Labels_Without_Training_a_Model_to_Predict/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_Corrupted_Labels_Without_Training_a_Model_to_Predict/models/model.py'],\n",
       " 'Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Farewell_to_Mutual_Information__Variational_Distillation_for_Cross-Modal_Person_Re-Identification/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Acceleration_of_Federated_Learning_with_Alleviated_Forgetting_in_Local_Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Acceleration_of_Federated_Learning_with_Alleviated_Forgetting_in_Local_Training/FedUtils/models/transformer/model.py'],\n",
       " 'AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AntBO__Towards_Real-World_Automated_Antibody_Design_with_Combinatorial_Bayesian_Optimisation/RLLG/agents/common/model.py'],\n",
       " 'GPT_Understands__Too': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/data_augmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/feature_vectorization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/geep_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/image2text_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/information_extraction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/language_modeling/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/latent_diffusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/machine_reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/open_domain_dialogue/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/sequence_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/sequence_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/sequence_labeling/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/text2image_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/text2video_retrieval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/text_match/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/video2text_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/appzoo/wukong_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/easynlp/modelzoo/models/latent_diffusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/SASA/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/xtremeclip/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/agree/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/fashionklip/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/parasum/finetune_for_CNNDM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPT_Understands__Too/examples/parasum/paraphrase_pretraining/model.py'],\n",
       " 'HLT-NUS_SUBMISSION_FOR_2020_NIST_Conversational_Telephone_Speech_SRE': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HLT-NUS_SUBMISSION_FOR_2020_NIST_Conversational_Telephone_Speech_SRE/model.py'],\n",
       " 'Generate_Like_Experts__Multi-Stage_Font_Generation_by_Incorporating_Font_Transfer_Process_into_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generate_Like_Experts__Multi-Stage_Font_Generation_by_Incorporating_Font_Transfer_Process_into_Diffusion_Models/llama/llama/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generate_Like_Experts__Multi-Stage_Font_Generation_by_Incorporating_Font_Transfer_Process_into_Diffusion_Models/llama2/origin_llama/llama/model.py'],\n",
       " 'Automated_Concatenation_of_Embeddings_for_Structured_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Automated_Concatenation_of_Embeddings_for_Structured_Prediction/flair/parser/model.py'],\n",
       " 'Value-Decomposition_Networks_For_Cooperative_Multi-Agent_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Value-Decomposition_Networks_For_Cooperative_Multi-Agent_Learning/smac/examples/rllib/model.py'],\n",
       " 'Deep_Learning_for_the_Matrix_Element_Method': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Learning_for_the_Matrix_Element_Method/src/deepmem/model.py'],\n",
       " 'Temporal_Transductive_Inference_for_Few-Shot_Video_Object_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Transductive_Inference_for_Few-Shot_Video_Object_Segmentation/src/model/model.py'],\n",
       " 'Hierarchical_Matching_and_Reasoning_for_Multi-Query_Image_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hierarchical_Matching_and_Reasoning_for_Multi-Query_Image_Retrieval/model.py'],\n",
       " 'ESRGAN__Enhanced_Super-Resolution_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ESRGAN__Enhanced_Super-Resolution_Generative_Adversarial_Networks/model.py'],\n",
       " 'Measuring_Perceptual_Color_Differences_of_Smartphone_Photographs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Measuring_Perceptual_Color_Differences_of_Smartphone_Photographs/model.py'],\n",
       " 'Data_augmentation_and_multimodal_learning_for_predicting_drug_response_in_patient-derived_xenografts_from_gene_expressions_and_histology_images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Data_augmentation_and_multimodal_learning_for_predicting_drug_response_in_patient-derived_xenografts_from_gene_expressions_and_histology_images/slideflow/segment/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Data_augmentation_and_multimodal_learning_for_predicting_drug_response_in_patient-derived_xenografts_from_gene_expressions_and_histology_images/slideflow/studio/widgets/model.py'],\n",
       " 'GIT__A_Generative_Image-to-text_Transformer_for_Vision_and_Language': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GIT__A_Generative_Image-to-text_Transformer_for_Vision_and_Language/generativeimage2text/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GIT__A_Generative_Image-to-text_Transformer_for_Vision_and_Language/generativeimage2text/layers/CLIP/model.py'],\n",
       " 'Self-Supervised_Modality-Aware_Multiple_Granularity_Pre-Training_for_RGB-Infrared_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Self-Supervised_Modality-Aware_Multiple_Granularity_Pre-Training_for_RGB-Infrared_Person_Re-Identification/AGW/model.py'],\n",
       " 'Enhancing_Hyperspectral_Images_via_Diffusion_Model_and_Group-Autoencoder_Super-resolution_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Hyperspectral_Images_via_Diffusion_Model_and_Group-Autoencoder_Super-resolution_Network/model/model.py'],\n",
       " 'Learning_to_restore_images_degraded_by_atmospheric_turbulence_using_uncertainty': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_restore_images_degraded_by_atmospheric_turbulence_using_uncertainty/model.py'],\n",
       " 'Assessing_differentially_private_deep_learning_with_Membership_Inference': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Assessing_differentially_private_deep_learning_with_Membership_Inference/MIAttack/mia/core/model.py'],\n",
       " 'Show_Me_What_and_Tell_Me_How__Video_Synthesis_via_Multimodal_Conditioning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show_Me_What_and_Tell_Me_How__Video_Synthesis_via_Multimodal_Conditioning/taming/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show_Me_What_and_Tell_Me_How__Video_Synthesis_via_Multimodal_Conditioning/taming/modules/discriminator/model.py'],\n",
       " 'Generative_Sparse_Detection_Networks_for_3D_Single-shot_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Generative_Sparse_Detection_Networks_for_3D_Single-shot_Object_Detection/models/model.py'],\n",
       " 'Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance/code/tools/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance/code/tools/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance/code/tools/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Original_or_Translated__A_Causal_Analysis_of_the_Impact_of_Translationese_on_Machine_Translation_Performance/code/tools/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'MetaFormer_Is_Actually_What_You_Need_for_Vision': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MetaFormer_Is_Actually_What_You_Need_for_Vision/examples/llama_inference/model.py'],\n",
       " 'Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regularizing_End-to-End_Speech_Translation_with_Triangular_Decomposition_Agreement/fairseq/models/roberta/model.py'],\n",
       " 'Regression_as_Classification__Influence_of_Task_Formulation_on_Neural_Network_Features': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regression_as_Classification__Influence_of_Task_Formulation_on_Neural_Network_Features/src/model.py'],\n",
       " 'SE_3_-Transformers__3D_Roto-Translation_Equivariant_Attention_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SE_3_-Transformers__3D_Roto-Translation_Equivariant_Attention_Networks/DAN-msa/pyErrorPred/model.py'],\n",
       " 'Learning_Generalisable_Omni-Scale_Representations_for_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Generalisable_Omni-Scale_Representations_for_Person_Re-Identification/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Generalisable_Omni-Scale_Representations_for_Person_Re-Identification/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Generalisable_Omni-Scale_Representations_for_Person_Re-Identification/PatchCore/src/model.py'],\n",
       " 'MetaFormer_Baselines_for_Vision': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MetaFormer_Baselines_for_Vision/examples/llama_inference/model.py'],\n",
       " 'Rethinking_Attention_with_Performers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Rethinking_Attention_with_Performers/examples/llama_inference/model.py'],\n",
       " 'Compositional_Attention__Disentangling_Search_and_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Compositional_Attention__Disentangling_Search_and_Retrieval/examples/llama_inference/model.py'],\n",
       " 'Transformers_without_Tears__Improving_the_Normalization_of_Self-Attention': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformers_without_Tears__Improving_the_Normalization_of_Self-Attention/examples/llama_inference/model.py'],\n",
       " 'A_Dual-level_Detection_Method_for_Video_Copy_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_v106/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_v107/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_v115/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_v68/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Dual-level_Detection_Method_for_Video_Copy_Detection/VSC22-Descriptor-Track-1st/train/train_vid_score/video/model.py'],\n",
       " 'Inverting_Gradients_--_How_easy_is_it_to_break_privacy_in_federated_learning_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Inverting_Gradients_--_How_easy_is_it_to_break_privacy_in_federated_learning_/src/model.py'],\n",
       " 'Modularity-Aware_Graph_Autoencoders_for_Joint_Community_Detection_and_Link_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Modularity-Aware_Graph_Autoencoders_for_Joint_Community_Detection_and_Link_Prediction/modularity_aware_gae/model.py'],\n",
       " 'Hard_hat_wearing_detection_based_on_head_keypoint_localization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hard_hat_wearing_detection_based_on_head_keypoint_localization/src/model.py'],\n",
       " 'NestE__Modeling_Nested_Relational_Structures_for_Knowledge_Graph_Reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NestE__Modeling_Nested_Relational_Structures_for_Knowledge_Graph_Reasoning/openke/module/model/Model.py'],\n",
       " 'Out-of-Distribution_Generalization_via_Risk_Extrapolation__REx_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Out-of-Distribution_Generalization_via_Risk_Extrapolation__REx_/model/model.py'],\n",
       " 'Strong_Lensing_Source_Reconstruction_Using_Continuous_Neural_Fields': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Strong_Lensing_Source_Reconstruction_Using_Continuous_Neural_Fields/gigalens/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Strong_Lensing_Source_Reconstruction_Using_Continuous_Neural_Fields/gigalens/jax/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Strong_Lensing_Source_Reconstruction_Using_Continuous_Neural_Fields/gigalens/tf/model.py'],\n",
       " 'MusicBERT__Symbolic_Music_Understanding_with_Large-Scale_Pre-Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MusicBERT__Symbolic_Music_Understanding_with_Large-Scale_Pre-Training/musecoco/1-text2attribute_model/model.py'],\n",
       " 'A_General_Contextualized_Rewriting_Framework_for_Text_Summarization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_General_Contextualized_Rewriting_Framework_for_Text_Summarization/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_General_Contextualized_Rewriting_Framework_for_Text_Summarization/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_General_Contextualized_Rewriting_Framework_for_Text_Summarization/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_General_Contextualized_Rewriting_Framework_for_Text_Summarization/fairseq/models/roberta/model.py'],\n",
       " 'Towards_out_of_distribution_generalization_for_problems_in_mechanics': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_out_of_distribution_generalization_for_problems_in_mechanics/model/model.py'],\n",
       " 'Written_Justifications_are_Key_to_Aggregate_Crowdsourced_Forecasts': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Written_Justifications_are_Key_to_Aggregate_Crowdsourced_Forecasts/model.py'],\n",
       " 'Can_Spatiotemporal_3D_CNNs_Retrace_the_History_of_2D_CNNs_and_ImageNet_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Spatiotemporal_3D_CNNs_Retrace_the_History_of_2D_CNNs_and_ImageNet_/model.py'],\n",
       " 'Actionable_and_Interpretable_Fault_Localization_for_Recurring_Failures_in_Online_Service_Systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Actionable_and_Interpretable_Fault_Localization_for_Recurring_Failures_in_Online_Service_Systems/random_walk_failure_instance/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Actionable_and_Interpretable_Fault_Localization_for_Recurring_Failures_in_Online_Service_Systems/random_walk_single_metric/model.py'],\n",
       " 'Multiresolution_Tree_Networks_for_3D_Point_Cloud_Processing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multiresolution_Tree_Networks_for_3D_Point_Cloud_Processing/models/Model.py'],\n",
       " 'Benchmarking_Compositionality_with_Formal_Languages': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Benchmarking_Compositionality_with_Formal_Languages/src/model.py'],\n",
       " 'MDMLP__Image_Classification_from_Scratch_on_Small_Datasets_with_MLP': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MDMLP__Image_Classification_from_Scratch_on_Small_Datasets_with_MLP/timm/utils/model.py'],\n",
       " 'Test_Time_Embedding_Normalization_for_Popularity_Bias_Mitigation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Test_Time_Embedding_Normalization_for_Popularity_Bias_Mitigation/model.py'],\n",
       " 'CLIPA-v2__Scaling_CLIP_Training_with_81_1__Zero-shot_ImageNet_Accuracy_within_a___10_000_Budget__An_Extra___4_000_Unlocks_81_8__Accuracy': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLIPA-v2__Scaling_CLIP_Training_with_81_1__Zero-shot_ImageNet_Accuracy_within_a___10_000_Budget__An_Extra___4_000_Unlocks_81_8__Accuracy/clipa_torch/open_clip/model.py'],\n",
       " 'Embarassingly_Simple_Dataset_Distillation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Embarassingly_Simple_Dataset_Distillation/framework/model.py'],\n",
       " 'Improving_RNN_Transducer_Based_ASR_with_Auxiliary_Tasks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_RNN_Transducer_Based_ASR_with_Auxiliary_Tasks/transformer_transducer/model.py'],\n",
       " 'Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/3DViT/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/3DViT_0_layer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/3DViT_1_layer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/3DViT_LWF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_We_Solve_3D_Vision_Tasks_Starting_from_A_2D_Vision_Transformer_/models/Hengshuang/model.py'],\n",
       " 'More_than_Words__In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/More_than_Words__In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech/utils/model.py'],\n",
       " 'Optimal_Transport_Guided_Unsupervised_Learning_for_Enhancing_low-quality_Retinal_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Optimal_Transport_Guided_Unsupervised_Learning_for_Enhancing_low-quality_Retinal_Images/Cycle-GAN/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Optimal_Transport_Guided_Unsupervised_Learning_for_Enhancing_low-quality_Retinal_Images/OTE-GAN/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Optimal_Transport_Guided_Unsupervised_Learning_for_Enhancing_low-quality_Retinal_Images/OTTGAN/model/model.py'],\n",
       " 'Spikformer__When_Spiking_Neural_Network_Meets_Transformer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spikformer__When_Spiking_Neural_Network_Meets_Transformer/cifar10/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spikformer__When_Spiking_Neural_Network_Meets_Transformer/cifar10dvs/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spikformer__When_Spiking_Neural_Network_Meets_Transformer/imagenet/model.py'],\n",
       " 'SoccerNet-v2__A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_Soccer_Videos': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet-v2__A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_Soccer_Videos/Benchmarks/SoccerNetv2-ReplayGrounding-CALF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet-v2__A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_Soccer_Videos/Benchmarks/SoccerNetv2-ReplayGrounding-CALF_more_negative/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet-v2__A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_Soccer_Videos/Benchmarks/SoccerNetv2-ReplayGrounding-NetVLAD-More-Negative/model.py'],\n",
       " 'SoccerNet_2022_Challenges_Results': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet_2022_Challenges_Results/Benchmarks/SoccerNetv2-ReplayGrounding-CALF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet_2022_Challenges_Results/Benchmarks/SoccerNetv2-ReplayGrounding-CALF_more_negative/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SoccerNet_2022_Challenges_Results/Benchmarks/SoccerNetv2-ReplayGrounding-NetVLAD-More-Negative/model.py'],\n",
       " 'Learning_Video-independent_Eye_Contact_Segmentation_from_In-the-Wild_Videos': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Video-independent_Eye_Contact_Segmentation_from_In-the-Wild_Videos/models/MSTCN/model.py'],\n",
       " 'OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OctSqueeze__Octree-Structured_Entropy_Model_for_LiDAR_Compression/rcnn/src/model.py'],\n",
       " 'Improving_Multi-Task_Deep_Neural_Networks_via_Knowledge_Distillation_for_Natural_Language_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multi-Task_Deep_Neural_Networks_via_Knowledge_Distillation_for_Natural_Language_Understanding/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multi-Task_Deep_Neural_Networks_via_Knowledge_Distillation_for_Natural_Language_Understanding/mt_dnn/model.py'],\n",
       " 'On_the_Variance_of_the_Adaptive_Learning_Rate_and_Beyond': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Variance_of_the_Adaptive_Learning_Rate_and_Beyond/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Variance_of_the_Adaptive_Learning_Rate_and_Beyond/mt_dnn/model.py'],\n",
       " 'SMART__Robust_and_Efficient_Fine-Tuning_for_Pre-trained_Natural_Language_Models_through_Principled_Regularized_Optimization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SMART__Robust_and_Efficient_Fine-Tuning_for_Pre-trained_Natural_Language_Models_through_Principled_Regularized_Optimization/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SMART__Robust_and_Efficient_Fine-Tuning_for_Pre-trained_Natural_Language_Models_through_Principled_Regularized_Optimization/mt_dnn/model.py'],\n",
       " 'The_Microsoft_Toolkit_of_Multi-Task_Deep_Neural_Networks_for_Natural_Language_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Microsoft_Toolkit_of_Multi-Task_Deep_Neural_Networks_for_Natural_Language_Understanding/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Microsoft_Toolkit_of_Multi-Task_Deep_Neural_Networks_for_Natural_Language_Understanding/mt_dnn/model.py'],\n",
       " 'Adversarial_Training_for_Large_Neural_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Training_for_Large_Neural_Language_Models/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Training_for_Large_Neural_Language_Models/mt_dnn/model.py'],\n",
       " 'Posterior_Differential_Regularization_with_f-divergence_for_Improving_Model_Robustness': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Posterior_Differential_Regularization_with_f-divergence_for_Improving_Model_Robustness/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Posterior_Differential_Regularization_with_f-divergence_for_Improving_Model_Robustness/mt_dnn/model.py'],\n",
       " 'A_Hybrid_Neural_Network_Model_for_Commonsense_Reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Hybrid_Neural_Network_Model_for_Commonsense_Reasoning/alum/adv_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Hybrid_Neural_Network_Model_for_Commonsense_Reasoning/mt_dnn/model.py'],\n",
       " 'Incorporating_Bias-aware_Margins_into_Contrastive_Loss_for_Collaborative_Filtering': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Incorporating_Bias-aware_Margins_into_Contrastive_Loss_for_Collaborative_Filtering/model.py'],\n",
       " 'MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/tensorflow/contrib/boosted_trees/estimator_batch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/tensorflow/contrib/timeseries/python/timeseries/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/modelzoo/features/adamasync_optimizer/dien/script/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/modelzoo/features/dynamic_dimension_embedding_variable/dien/script/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/modelzoo/features/embedding_variable/dien/script/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaskNet__Introducing_Feature-Wise_Multiplication_to_CTR_Ranking_Models_by_Instance-Guided_Mask/modelzoo/features/multihash_variable/dien/script/model.py'],\n",
       " 'A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/hubert/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/u2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/u2_kaldi/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/u2_st/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/wav2vec2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/s2t/exps/wavlm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/t2s/models/starganv2_vc/AuxiliaryASR/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/t2s/models/starganv2_vc/JDCNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/paddlespeech/text/models/ernie_crf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A__3_T__Alignment-Aware_Acoustic_and_Text_Pretraining_for_Speech_Synthesis_and_Editing/demos/streaming_tts_serving_fastdeploy/streaming_tts_serving/1/model.py'],\n",
       " 'DilatedSegNet__A_Deep_Dilated_Segmentation_Network_for_Polyp_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DilatedSegNet__A_Deep_Dilated_Segmentation_Network_for_Polyp_Segmentation/model.py'],\n",
       " 'Synthetic_Data_Supervised_Salient_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Synthetic_Data_Supervised_Salient_Object_Detection/models/BigGAN/model.py'],\n",
       " 'Multi-Granularity_Cross-Modality_Representation_Learning_for_Named_Entity_Recognition_on_Social_Media': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-Granularity_Cross-Modality_Representation_Learning_for_Named_Entity_Recognition_on_Social_Media/object_detector/mrcnn/model.py'],\n",
       " 'An_Opponent-Aware_Reinforcement_Learning_Method_for_Team-to-Team_Multi-Vehicle_Pursuit_via_Maximizing_Mutual_Information_Indicator': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/An_Opponent-Aware_Reinforcement_Learning_Method_for_Team-to-Team_Multi-Vehicle_Pursuit_via_Maximizing_Mutual_Information_Indicator/Informer-MVP/models/model.py'],\n",
       " 'A_Learned_Representation_For_Artistic_Style': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/gansynth/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/image_stylization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/onsets_frames_transcription/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/piano_genie/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/shared/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Learned_Representation_For_Artistic_Style/magenta/models/sketch_rnn/model.py'],\n",
       " 'Explaining_heterogeneity_in_medial_entorhinal_cortex_with_task-driven_neural_networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Explaining_heterogeneity_in_medial_entorhinal_cortex_with_task-driven_neural_networks/mec/models/model.py'],\n",
       " 'ET-AL__Entropy-Targeted_Active_Learning_for_Bias_Mitigation_in_Materials_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ET-AL__Entropy-Targeted_Active_Learning_for_Bias_Mitigation_in_Materials_Data/utils/cgcnn/cgcnn/model.py'],\n",
       " 'Hyper-X__A_Unified_Hypernetwork_for_Multi-Task_Multilingual_Transfer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hyper-X__A_Unified_Hypernetwork_for_Multi-Task_Multilingual_Transfer/src/hyperx/model.py'],\n",
       " 'Real-time_Scene_Text_Detection_with_Differentiable_Binarization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Real-time_Scene_Text_Detection_with_Differentiable_Binarization/modules/model.py'],\n",
       " 'Learning_from_Very_Little_Data__On_the_Value_of_Landscape_Analysis_for_Predicting_Software_Project_Health': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_from_Very_Little_Data__On_the_Value_of_Landscape_Analysis_for_Predicting_Software_Project_Health/baselines/nue_framework/src/modeling/model.py'],\n",
       " 'StrongSORT__Make_DeepSORT_Great_Again': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StrongSORT__Make_DeepSORT_Great_Again/AFLink/model.py'],\n",
       " 'ELSR__Extreme_Low-Power_Super_Resolution_Network_For_Mobile_Devices': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELSR__Extreme_Low-Power_Super_Resolution_Network_For_Mobile_Devices/model.py'],\n",
       " 'SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SinGAN-Seg__Synthetic_training_data_generation_for_medical_image_segmentation/ssc_resnet50/src/network/model.py'],\n",
       " 'LU-Net__Invertible_Neural_Networks_Based_on_Matrix_Factorization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LU-Net__Invertible_Neural_Networks_Based_on_Matrix_Factorization/gaussian mixture/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LU-Net__Invertible_Neural_Networks_Based_on_Matrix_Factorization/mnist/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LU-Net__Invertible_Neural_Networks_Based_on_Matrix_Factorization/realnvp/model.py'],\n",
       " 'Real-time_Wireless_ECG-derived_Respiration_Rate_Estimation_Using_an_Autoencoder_with_a_DCT_Layer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Real-time_Wireless_ECG-derived_Respiration_Rate_Estimation_Using_an_Autoencoder_with_a_DCT_Layer/autoencoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Real-time_Wireless_ECG-derived_Respiration_Rate_Estimation_Using_an_Autoencoder_with_a_DCT_Layer/autoencoder_with_dct/model.py'],\n",
       " 'Discovering_Quantum_Circuit_Components_with_Program_Synthesis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Discovering_Quantum_Circuit_Components_with_Program_Synthesis/prototypical-networks/protonets/utils/model.py'],\n",
       " 'FreeNeRF__Improving_Few-shot_Neural_Rendering_with_Free_Frequency_Regularization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FreeNeRF__Improving_Few-shot_Neural_Rendering_with_Free_Frequency_Regularization/DietNeRF-pytorch/CLIP/clip/model.py'],\n",
       " 'BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/trainer/callbacks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/multimodal/llava/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/multimodal/multimodal_simple/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bert/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bert/classifier/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bert/extractive_summarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bert/token_classifier/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/bloom/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/btlm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/dpo/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/dpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/esm2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/falcon/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/gemma2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/gpt2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/gpt3/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/gptj/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/jais/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/llama/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/mistral/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/mixtral/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/santacoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/starcoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/t5/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/nlp/transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/vision/dit/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BTLM-3B-8K__7B_Parameter_Performance_in_a_3B_Parameter_Model/src/cerebras/modelzoo/models/vision/vision_transformer/model.py'],\n",
       " 'Fourier-DeepONet__Fourier-enhanced_deep_operator_networks_for_full_waveform_inversion_with_improved_accuracy__generalizability__and_robustness': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fourier-DeepONet__Fourier-enhanced_deep_operator_networks_for_full_waveform_inversion_with_improved_accuracy__generalizability__and_robustness/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fourier-DeepONet__Fourier-enhanced_deep_operator_networks_for_full_waveform_inversion_with_improved_accuracy__generalizability__and_robustness/deepxde/zcs/model.py'],\n",
       " 'DAM__Deliberation__Abandon_and_Memory_Networks_for_Generating_Detailed_and_Non-repetitive_Responses_in_Visual_Dialogue': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAM__Deliberation__Abandon_and_Memory_Networks_for_Generating_Detailed_and_Non-repetitive_Responses_in_Visual_Dialogue/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DAM__Deliberation__Abandon_and_Memory_Networks_for_Generating_Detailed_and_Non-repetitive_Responses_in_Visual_Dialogue/duconv/src/model.py'],\n",
       " 'Deep_Variational_Bayes_Filters__Unsupervised_Learning_of_State_Space_Models_from_Raw_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Variational_Bayes_Filters__Unsupervised_Learning_of_State_Space_Models_from_Raw_Data/model.py'],\n",
       " 'LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LSTM-based_Encoder-Decoder_for_Multi-sensor_Anomaly_Detection/jasper/src/model.py'],\n",
       " 'Shepherding_Slots_to_Objects__Towards_Stable_and_Robust_Object-Centric_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Shepherding_Slots_to_Objects__Towards_Stable_and_Robust_Object-Centric_Learning/model.py'],\n",
       " 'Knowledge_Rumination_for_Pre-trained_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Knowledge_Rumination_for_Pre-trained_Language_Models/commonsense/model.py'],\n",
       " 'QMIX__Monotonic_Value_Function_Factorisation_for_Deep_Multi-Agent_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QMIX__Monotonic_Value_Function_Factorisation_for_Deep_Multi-Agent_Reinforcement_Learning/smac/examples/rllib/model.py'],\n",
       " 'QPLEX__Duplex_Dueling_Multi-Agent_Q-Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QPLEX__Duplex_Dueling_Multi-Agent_Q-Learning/smac/examples/rllib/model.py'],\n",
       " 'MLPerf_Tiny_Benchmark': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MLPerf_Tiny_Benchmark/benchmark/experimental/training_torch/image_classification/utils/model.py'],\n",
       " 'Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement/clip/model.py'],\n",
       " 'Uncertainty_Quantification_on_Clinical_Trial_Outcome_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Uncertainty_Quantification_on_Clinical_Trial_Outcome_Prediction/HINT/model.py'],\n",
       " 'MaPLe__Multi-modal_Prompt_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaPLe__Multi-modal_Prompt_Learning/Dassl.ProGrad.pytorch/dassl/modeling/backbone/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MaPLe__Multi-modal_Prompt_Learning/KgCoOp/clip/model.py'],\n",
       " 'Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hearing_Lips_in_Noise__Universal_Viseme-Phoneme_Mapping_and_Transfer_for_Robust_Audio-Visual_Speech_Recognition/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Enhancing_Reinforcement_Learning_Agents_with_Local_Guides': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Reinforcement_Learning_Agents_with_Local_Guides/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Reinforcement_Learning_Agents_with_Local_Guides/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Reinforcement_Learning_Agents_with_Local_Guides/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enhancing_Reinforcement_Learning_Agents_with_Local_Guides/RLLG/agents/common/model.py'],\n",
       " 'PAMTRI__Pose-Aware_Multi-Task_Learning_for_Vehicle_Re-Identification_Using_Highly_Randomized_Synthetic_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PAMTRI__Pose-Aware_Multi-Task_Learning_for_Vehicle_Re-Identification_Using_Highly_Randomized_Synthetic_Data/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PAMTRI__Pose-Aware_Multi-Task_Learning_for_Vehicle_Re-Identification_Using_Highly_Randomized_Synthetic_Data/PaDiM/src/model.py'],\n",
       " 'Large_Language_Models_Are_Reasoning_Teachers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Large_Language_Models_Are_Reasoning_Teachers/src/custom/model.py'],\n",
       " 'Adaptive_Graph_Contrastive_Learning_for_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Graph_Contrastive_Learning_for_Recommendation/Model.py'],\n",
       " 'Align_your_Latents__High-Resolution_Video_Synthesis_with_Latent_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Align_your_Latents__High-Resolution_Video_Synthesis_with_Latent_Diffusion_Models/sgm/modules/autoencoding/lpips/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Align_your_Latents__High-Resolution_Video_Synthesis_with_Latent_Diffusion_Models/sgm/modules/diffusionmodules/model.py'],\n",
       " 'Multi-scale_Semantic_Correlation_Mining_for_Visible-Infrared_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-scale_Semantic_Correlation_Mining_for_Visible-Infrared_Person_Re-Identification/model.py'],\n",
       " 'ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/dpkd/transformers/examples/research_projects/fsner/src/fsner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/understand_icl/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/uprise/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ResLoRA__Identity_Residual_Mapping_in_Low-Rank_Adaption/structured_prompting/fairseq-version/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Towards_Robust_Multi-Modal_Reasoning_via_Model_Selection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Robust_Multi-Modal_Reasoning_via_Model_Selection/MS-GQA/code/models/metagl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Robust_Multi-Modal_Reasoning_via_Model_Selection/MS-OKVQA/code/models/metagl/model.py'],\n",
       " 'A_Goal-Driven_Approach_to_Systems_Neuroscience': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Goal-Driven_Approach_to_Systems_Neuroscience/mec/models/model.py'],\n",
       " 'DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiSAN__Directional_Self-Attention_Network_for_RNN_CNN-Free_Language_Understanding/cdp/model.py'],\n",
       " '3D_Indoor_Instance_Segmentation_in_an_Open-World': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/3D_Indoor_Instance_Segmentation_in_an_Open-World/models/model.py'],\n",
       " 'Localized_Symbolic_Knowledge_Distillation_for_Visual_Commonsense_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Localized_Symbolic_Knowledge_Distillation_for_Visual_Commonsense_Models/lavis/common/annotator/openpose/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Localized_Symbolic_Knowledge_Distillation_for_Visual_Commonsense_Models/lavis/models/clip_models/model.py'],\n",
       " 'A_Gaussian_process_based_approach_for_validation_of_multi-variable_measurement_systems__application_to_SAR_measurement_systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Gaussian_process_based_approach_for_validation_of_multi-variable_measurement_systems__application_to_SAR_measurement_systems/src/iec62209/model.py'],\n",
       " 'Texture_Synthesis_Using_Convolutional_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Texture_Synthesis_Using_Convolutional_Neural_Networks/po/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Texture_Synthesis_Using_Convolutional_Neural_Networks/beta/po/model.py'],\n",
       " 'DiffusionEdge__Diffusion_Probabilistic_Model_for_Crisp_Edge_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiffusionEdge__Diffusion_Probabilistic_Model_for_Crisp_Edge_Detection/taming/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiffusionEdge__Diffusion_Probabilistic_Model_for_Crisp_Edge_Detection/taming/modules/discriminator/model.py'],\n",
       " 'UniRec__A_Dual_Enhancement_of_Uniformity_and_Frequency_in_Sequential_Recommendations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UniRec__A_Dual_Enhancement_of_Uniformity_and_Frequency_in_Sequential_Recommendations/UniRec/unirec/models/model.py'],\n",
       " 'HyperFast__Instant_Classification_for_Tabular_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HyperFast__Instant_Classification_for_Tabular_Data/hyperfast/model.py'],\n",
       " 'EarthPT__a_time_series_foundation_model_for_Earth_Observation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EarthPT__a_time_series_foundation_model_for_Earth_Observation/src/model.py'],\n",
       " 'Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation/MovieLens/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation/Taobao/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation/Tianchi/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Context-Aware_Sequential_Model_for_Multi-Behaviour_Recommendation/Yelp/model.py'],\n",
       " 'VocaLiST__An_Audio-Visual_Synchronisation_Model_for_Lips_and_Voices': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VocaLiST__An_Audio-Visual_Synchronisation_Model_for_Lips_and_Voices/models/model.py'],\n",
       " 'QuEST__Low-bit_Diffusion_Model_Quantization_via_Efficient_Selective_Finetuning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuEST__Low-bit_Diffusion_Model_Quantization_via_Efficient_Selective_Finetuning/ldm/modules/diffusionmodules/model.py'],\n",
       " 'Radiative_transfer_with_POLARIS__I__Analysis_of_magnetic_fields_through_synthetic_dust_continuum_polarization_measurements': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Radiative_transfer_with_POLARIS__I__Analysis_of_magnetic_fields_through_synthetic_dust_continuum_polarization_measurements/tools/polaris_tools_custom/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Radiative_transfer_with_POLARIS__I__Analysis_of_magnetic_fields_through_synthetic_dust_continuum_polarization_measurements/tools/polaris_tools_modules/model.py'],\n",
       " 'GISTEmbed__Guided_In-sample_Selection_of_Training_Negatives_for_Text_Embedding_Fine-tuning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GISTEmbed__Guided_In-sample_Selection_of_Training_Negatives_for_Text_Embedding_Fine-tuning/gist_embed/trainer/arguments/model.py'],\n",
       " 'One_Embedder__Any_Task__Instruction-Finetuned_Text_Embeddings': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/One_Embedder__Any_Task__Instruction-Finetuned_Text_Embeddings/gist_embed/trainer/arguments/model.py'],\n",
       " 'NextLevelBERT__Masked_Language_Modeling_with_Higher-Level_Representations_for_Long_Documents': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NextLevelBERT__Masked_Language_Modeling_with_Higher-Level_Representations_for_Long_Documents/src/model.py'],\n",
       " 'A_Teacher-Free_Graph_Knowledge_Distillation_Framework_with_Dual_Self-Distillation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Teacher-Free_Graph_Knowledge_Distillation_Framework_with_Dual_Self-Distillation/code/model.py'],\n",
       " 'LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/GNNs/GCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/GNNs/MLP/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/GNNs/MixHop/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/GNNs/SAGE/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGIN__A_Large_Language_Model_Consulted_Graph_Neural_Network_Training_Framework/LMs/model.py'],\n",
       " 'First-Pass_Large_Vocabulary_Continuous_Speech_Recognition_using_Bi-Directional_Recurrent_DNNs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/First-Pass_Large_Vocabulary_Continuous_Speech_Recognition_using_Bi-Directional_Recurrent_DNNs/model.py'],\n",
       " 'Accelerating_Geo-distributed_Machine_Learning_with_Network-Aware_Adaptive_Tree_and_Auxiliary_Route': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Geo-distributed_Machine_Learning_with_Network-Aware_Adaptive_Tree_and_Auxiliary_Route/python/mxnet/model.py'],\n",
       " 'Application_of_Neural_Ordinary_Differential_Equations_for_Tokamak_Plasma_Dynamics_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Application_of_Neural_Ordinary_Differential_Equations_for_Tokamak_Plasma_Dynamics_Analysis/src/model.py'],\n",
       " 'Application_of_Neural_Ordinary_Differential_Equations_for_ITER_Burning_Plasma_Dynamics': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Application_of_Neural_Ordinary_Differential_Equations_for_ITER_Burning_Plasma_Dynamics/src/model.py'],\n",
       " 'Safe_Multi-Agent_Reinforcement_Learning_with_Bilevel_Optimization_in_Autonomous_Driving': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Safe_Multi-Agent_Reinforcement_Learning_with_Bilevel_Optimization_in_Autonomous_Driving/bilevel_maddpg/model.py'],\n",
       " 'Resource_Constrained_Semantic_Segmentation_for_Waste_Sorting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Resource_Constrained_Semantic_Segmentation_for_Waste_Sorting/project-WasteSemSeg/model.py'],\n",
       " 'Finetuning_Generative_Large_Language_Models_with_Discrimination_Instructions_for_Knowledge_Graph_Completion': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Finetuning_Generative_Large_Language_Models_with_Discrimination_Instructions_for_Knowledge_Graph_Completion/model.py'],\n",
       " 'QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression/core/CAE/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression/core/PVCAE/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression/core/QCAE/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/QuadConv__Quadrature-Based_Convolutions_with_Applications_to_Non-Uniform_PDE_Data_Compression/core/VCAE/model.py'],\n",
       " 'MobileNetV4_-_Universal_Models_for_the_Mobile_Ecosystem': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MobileNetV4_-_Universal_Models_for_the_Mobile_Ecosystem/timm/utils/model.py'],\n",
       " 'Transformer_neural_networks_and_quantum_simulators__a_hybrid_approach_for_simulating_strongly_correlated_systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_neural_networks_and_quantum_simulators__a_hybrid_approach_for_simulating_strongly_correlated_systems/src/model.py'],\n",
       " 'Deciphering_Oracle_Bone_Language_with_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deciphering_Oracle_Bone_Language_with_Diffusion_Models/OBS_Diffusion/FontDiffuser/src/model.py'],\n",
       " 'Plug-and-Play_Adaptation_for_Continuously-updated_QA': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Plug-and-Play_Adaptation_for_Continuously-updated_QA/model.py'],\n",
       " 'Understanding_Multi-Granularity_for_Open-Vocabulary_Part_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Understanding_Multi-Granularity_for_Open-Vocabulary_Part_Segmentation/baselines/modeling/transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Understanding_Multi-Granularity_for_Open-Vocabulary_Part_Segmentation/baselines/third_party/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Understanding_Multi-Granularity_for_Open-Vocabulary_Part_Segmentation/open_clip/src/open_clip/model.py'],\n",
       " 'Sign_Language_Sense_Disambiguation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sign_Language_Sense_Disambiguation/signjoey/model.py'],\n",
       " 'Improving_Diffusion_Inverse_Problem_Solving_with_Decoupled_Noise_Annealing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Diffusion_Inverse_Problem_Solving_with_Decoupled_Noise_Annealing/model/ldm/modules/diffusionmodules/model.py'],\n",
       " 'Learning_from_Emergence__A_Study_on_Proactively_Inhibiting_the_Monosemantic_Neurons_of_Artificial_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_from_Emergence__A_Study_on_Proactively_Inhibiting_the_Monosemantic_Neurons_of_Artificial_Neural_Networks/physics/now/models/model.py'],\n",
       " 'Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/dpkd/transformers/examples/research_projects/fsner/src/fsner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/understand_icl/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/uprise/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Instruction_Pre-Training__Language_Models_are_Supervised_Multitask_Learners/structured_prompting/fairseq-version/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Chain-of-Thought_Unfaithfulness_as_Disguised_Accuracy': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Chain-of-Thought_Unfaithfulness_as_Disguised_Accuracy/src/model.py'],\n",
       " 'Language_Models_are_Few-Shot_Learners': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Language_Models_are_Few-Shot_Learners/lm_eval/api/model.py'],\n",
       " 'Gender_Bias_Detection_in_Court_Decisions__A_Brazilian_Case_Study': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Gender_Bias_Detection_in_Court_Decisions__A_Brazilian_Case_Study/exp/model.py'],\n",
       " 'Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mockingjay__Unsupervised_Speech_Representation_Learning_with_Deep_Bidirectional_Transformer_Encoders/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Audio_ALBERT__A_Lite_BERT_for_Self-supervised_Learning_of_Audio_Representation/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_for_Black-box_Attacks_on_Anti-spoofing_Models_by_Self-Supervised_Learning/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/S2VC__A_Framework_for_Any-to-Any_Voice_Conversion_with_Self-Supervised_Pretrained_Representations/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'Utilizing_Self-supervised_Representations_for_MOS_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/a2a-vc-vctk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/a2o-vc-vcc2020/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/asr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/atis/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/audio_snips/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/diarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/emotion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/enhancement_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/enhancement_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/example/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/fluent_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/mos_prediction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/mosei/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/quesst14_embedding/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/separation_stft/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/separation_stft2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/speaker_linear_utter_libri/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/speech_commands/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/sv_voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/sws2013/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/timit_phone/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/timit_phone_1hidden/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/timit_phone_linear/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/timit_phone_linear_concat/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/voxceleb1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/voxceleb2_amsoftmax_segment_eval/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/downstream/voxceleb2_ge2e/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/upstream/cpc/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/upstream/distiller/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/upstream/mockingjay/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Utilizing_Self-supervised_Representations_for_MOS_Prediction/s3prl/upstream/mos_prediction/model.py'],\n",
       " 'Explaining_Spectrograms_in_Machine_Learning__A_Study_on_Neural_Networks_for_Speech_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Explaining_Spectrograms_in_Machine_Learning__A_Study_on_Neural_Networks_for_Speech_Classification/ResNet101/model.py'],\n",
       " 'Boosting_Vision-Language_Models_for_Histopathology_Classification__Predict_all_at_once': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Boosting_Vision-Language_Models_for_Histopathology_Classification__Predict_all_at_once/clip/model.py'],\n",
       " 'Modeling_Relational_Data_with_Graph_Convolutional_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Modeling_Relational_Data_with_Graph_Convolutional_Networks/gae/model.py'],\n",
       " 'Learning_to_Generate_Chairs__Tables_and_Cars_with_Convolutional_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_Generate_Chairs__Tables_and_Cars_with_Convolutional_Networks/faces/model.py'],\n",
       " 'ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games/atari/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games/rts/game_CF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games/rts/game_MC/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ELF__An_Extensive__Lightweight_and_Flexible_Research_Platform_for_Real-time_Strategy_Games/rts/game_TD/model.py'],\n",
       " 'Variational_Graph_Auto-Encoders': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Variational_Graph_Auto-Encoders/gae/model.py'],\n",
       " 'Multi-Level_Contextual_Network_for_Biomedical_Image_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-Level_Contextual_Network_for_Biomedical_Image_Segmentation/model.py'],\n",
       " 'Semantic_Instance_Segmentation_via_Deep_Metric_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Instance_Segmentation_via_Deep_Metric_Learning/model.py'],\n",
       " 'SqueezeNet__AlexNet-level_accuracy_with_50x_fewer_parameters_and__0_5MB_model_size': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SqueezeNet__AlexNet-level_accuracy_with_50x_fewer_parameters_and__0_5MB_model_size/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SqueezeNet__AlexNet-level_accuracy_with_50x_fewer_parameters_and__0_5MB_model_size/patch400/model.py'],\n",
       " 'Recurrent_Neural_Networks_for_Polyphonic_Sound_Event_Detection_in_Real_Life_Recordings': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Neural_Networks_for_Polyphonic_Sound_Event_Detection_in_Real_Life_Recordings/src/tweetynet/model.py'],\n",
       " 'End-to-end_Recovery_of_Human_Shape_and_Pose': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/End-to-end_Recovery_of_Human_Shape_and_Pose/src/model.py'],\n",
       " 'Metadata_Embeddings_for_User_and_Item_Cold-start_Recommendations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metadata_Embeddings_for_User_and_Item_Cold-start_Recommendations/experiments/movielens/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metadata_Embeddings_for_User_and_Item_Cold-start_Recommendations/experiments/stackexchange/model.py'],\n",
       " 'Road_Extraction_by_Deep_Residual_U-Net': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Road_Extraction_by_Deep_Residual_U-Net/patch400/model.py'],\n",
       " 'EmotionFlow__Capture_the_Dialogue_Level_Emotion_Transitions': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EmotionFlow__Capture_the_Dialogue_Level_Emotion_Transitions/model.py'],\n",
       " 'PyTorch-BigGraph__A_Large-scale_Graph_Embedding_System': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyTorch-BigGraph__A_Large-scale_Graph_Embedding_System/torchbiggraph/model.py'],\n",
       " 'Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/deeplab/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/object_detection/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/pcl_rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/vid2depth/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Pixel-Level_Domain_Adaptation_with_Generative_Adversarial_Networks/research/attention_ocr/python/model.py'],\n",
       " 'Defense_against_Adversarial_Attacks_Using_High-Level_Representation_Guided_Denoiser': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Defense_against_Adversarial_Attacks_Using_High-Level_Representation_Guided_Denoiser/Exps/sample/model.py'],\n",
       " 'A_Multilayer_Convolutional_Encoder-Decoder_Neural_Network_for_Grammatical_Error_Correction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multilayer_Convolutional_Encoder-Decoder_Neural_Network_for_Grammatical_Error_Correction/caption_model/model.py'],\n",
       " 'A_Note_on_the_Inception_Score': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Note_on_the_Inception_Score/mnist/model.py'],\n",
       " 'Multi-view_to_Novel_view__Synthesizing_Novel_Views_with_Self-Learned_Confidence': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-view_to_Novel_view__Synthesizing_Novel_Views_with_Self-Learned_Confidence/model.py'],\n",
       " 'Exploring_Social_Media_for_Early_Detection_of_Depression_in_COVID-19_Patients': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Exploring_Social_Media_for_Early_Detection_of_Depression_in_COVID-19_Patients/model/model.py'],\n",
       " 'Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/deeplab/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/object_detection/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/pcl_rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/vid2depth/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Depth_Prediction_Without_the_Sensors__Leveraging_Structure_for_Unsupervised_Learning_from_Monocular_Videos/research/attention_ocr/python/model.py'],\n",
       " 'Multiagent_Reinforcement_Learning_Based_on_Fusion-Multiactor-Attention-Critic_for_Multiple-Unmanned-Aerial-Vehicle_Navigation_Control': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multiagent_Reinforcement_Learning_Based_on_Fusion-Multiactor-Attention-Critic_for_Multiple-Unmanned-Aerial-Vehicle_Navigation_Control/MAAC/baselines-master/baselines/ppo2/model.py'],\n",
       " 'Weakly_Supervised_Domain_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly_Supervised_Domain_Detection/src/frame/model.py'],\n",
       " 'PYRO-NN__Python_Reconstruction_Operators_in_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PYRO-NN__Python_Reconstruction_Operators_in_Neural_Networks/examples/ct_reconstruction/example_learning_tensorflow/model/model.py'],\n",
       " 'XNAS__Neural_Architecture_Search_with_Expert_Advice': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/XNAS__Neural_Architecture_Search_with_Expert_Advice/model.py'],\n",
       " 'Learning_with_Opponent-Learning_Awareness': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_with_Opponent-Learning_Awareness/ConsensusOptimization/CoinGame/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_with_Opponent-Learning_Awareness/ConsensusOptimization/GAN/model.py'],\n",
       " 'Unite_the_People__Closing_the_Loop_Between_3D_and_2D_Human_Representations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unite_the_People__Closing_the_Loop_Between_3D_and_2D_Human_Representations/src/model.py'],\n",
       " 'UNI-EM__An_Environment_for_Deep_Neural_Network-Based_Automated_Segmentation_of_Neuronal_Electron_Microscopic_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNI-EM__An_Environment_for_Deep_Neural_Network-Based_Automated_Segmentation_of_Neuronal_Electron_Microscopic_Images/segment/_3D_FFN/ffn/ffn/training/model.py'],\n",
       " 'StarGAN__Unified_Generative_Adversarial_Networks_for_Multi-Domain_Image-to-Image_Translation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/StarGAN__Unified_Generative_Adversarial_Networks_for_Multi-Domain_Image-to-Image_Translation/model.py'],\n",
       " 'Tighter_Variational_Bounds_are_Not_Necessarily_Better__A_Research_Report_on_Implementation__Ablation_Study__and_Extensions': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tighter_Variational_Bounds_are_Not_Necessarily_Better__A_Research_Report_on_Implementation__Ablation_Study__and_Extensions/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tighter_Variational_Bounds_are_Not_Necessarily_Better__A_Research_Report_on_Implementation__Ablation_Study__and_Extensions/plotting_utils/1_reference_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tighter_Variational_Bounds_are_Not_Necessarily_Better__A_Research_Report_on_Implementation__Ablation_Study__and_Extensions/plotting_utils/2_bigger_model/model.py'],\n",
       " 'Extreme_Memorization_via_Scale_of_Initialization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/cnn_quantization/tf_cnn_benchmarks/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/imp/max/projects/imp/config/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/meta_reward_learning/textworld/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/stacked_capsule_autoencoders/capsules/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/table_rag/agent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/tf3d/instance_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/tf3d/object_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/tf3d/semantic_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/video_timeline_modeling/vtm/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/cache_replacement/policy_learning/cache_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/fairness_teaching/in_progress/rl_a2c/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Extreme_Memorization_via_Scale_of_Initialization/graph_embedding/huge/model.py'],\n",
       " 'The_effects_of_regularisation_on_RNN_models_for_time_series_forecasting__Covid-19_as_an_example': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_effects_of_regularisation_on_RNN_models_for_time_series_forecasting__Covid-19_as_an_example/COVID-19/model.py'],\n",
       " 'fPINNs__Fractional_Physics-Informed_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/fPINNs__Fractional_Physics-Informed_Neural_Networks/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/fPINNs__Fractional_Physics-Informed_Neural_Networks/deepxde/zcs/model.py'],\n",
       " 'HandAugment__A_Simple_Data_Augmentation_Method_for_Depth-Based_3D_Hand_Pose_Estimation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HandAugment__A_Simple_Data_Augmentation_Method_for_Depth-Based_3D_Hand_Pose_Estimation/model/efficientnet_pytorch/model.py'],\n",
       " 'Are_We_Falling_in_a_Middle-Intelligence_Trap__An_Analysis_and_Mitigation_of_the_Reversal_Curse': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Are_We_Falling_in_a_Middle-Intelligence_Trap__An_Analysis_and_Mitigation_of_the_Reversal_Curse/transformers/examples/research_projects/fsner/src/fsner/model.py'],\n",
       " 'EEG-GAN__Generative_adversarial_networks_for_electroencephalograhic__EEG__brain_signals': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EEG-GAN__Generative_adversarial_networks_for_electroencephalograhic__EEG__brain_signals/GAN/eeggan/examples/conv_lin/model.py'],\n",
       " 'Imprints_of_cosmological_tensions_in_reconstructed_gravity': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Imprints_of_cosmological_tensions_in_reconstructed_gravity/camb/camb/model.py'],\n",
       " 'Dual_Path_Multi-Scale_Fusion_Networks_with_Attention_for_Crowd_Counting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Multi-Scale_Fusion_Networks_with_Attention_for_Crowd_Counting/model.py'],\n",
       " 'A_Multigrid_Method_for_Efficiently_Training_Video_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multigrid_Method_for_Efficiently_Training_Video_Models/train/model.py'],\n",
       " 'Probabilistic_Logic_Neural_Networks_for_Reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Probabilistic_Logic_Neural_Networks_for_Reasoning/kge/model.py'],\n",
       " 'Iterative_Projection_and_Matching__Finding_Structure-preserving_Representatives_and_Its_Application_to_Computer_Vision': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Iterative_Projection_and_Matching__Finding_Structure-preserving_Representatives_and_Its_Application_to_Computer_Vision/model.py'],\n",
       " 'Deep_Speech__Scaling_up_end-to-end_speech_recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Speech__Scaling_up_end-to-end_speech_recognition/src/deepspeech/models/model.py'],\n",
       " 'Adversarial_Color_Enhancement__Generating_Unrestricted_Adversarial_Images_by_Optimizing_a_Color_Filter': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Color_Enhancement__Generating_Unrestricted_Adversarial_Images_by_Optimizing_a_Color_Filter/Journal_version/AdvTrain_ACE/src/model/model.py'],\n",
       " 'Attribute-based_Regularization_of_Latent_Spaces_for_Variational_Auto-Encoders': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Attribute-based_Regularization_of_Latent_Spaces_for_Variational_Auto-Encoders/utils/model.py'],\n",
       " 'Detecting_Oriented_Text_in_Natural_Images_by_Linking_Segments': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_Oriented_Text_in_Natural_Images_by_Linking_Segments/seglink/model.py'],\n",
       " 'Enabling_more_efficient_and_cost-effective_AI_ML_systems_with_Collective_Mind__virtualized_MLOps__MLPerf__Collective_Knowledge_Playground_and_reproducible_optimization_tournaments': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enabling_more_efficient_and_cost-effective_AI_ML_systems_with_Collective_Mind__virtualized_MLOps__MLPerf__Collective_Knowledge_Playground_and_reproducible_optimization_tournaments/cm-mlops/script/app-loadgen-generic-python/src/loadgen/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Enabling_more_efficient_and_cost-effective_AI_ML_systems_with_Collective_Mind__virtualized_MLOps__MLPerf__Collective_Knowledge_Playground_and_reproducible_optimization_tournaments/cmx4mlops/cmx4mlops/repo/script/app-loadgen-generic-python/src/loadgen/model.py'],\n",
       " 'DiffBlender__Scalable_and_Composable_Multimodal_Text-to-Image_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiffBlender__Scalable_and_Composable_Multimodal_Text-to-Image_Diffusion_Models/ldm/modules/diffusionmodules/model.py'],\n",
       " 'CAT-Seg__Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CAT-Seg__Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation/cat_seg/modeling/transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CAT-Seg__Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation/cat_seg/third_party/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CAT-Seg__Cost_Aggregation_for_Open-Vocabulary_Semantic_Segmentation/open_clip/src/open_clip/model.py'],\n",
       " 'Crowd-Powered_Photo_Enhancement_Featuring_an_Active_Learning_Based_Local_Filter': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Crowd-Powered_Photo_Enhancement_Featuring_an_Active_Learning_Based_Local_Filter/NBNet/model.py'],\n",
       " 'DiffTalk__Crafting_Diffusion_Models_for_Generalized_Audio-Driven_Portraits_Animation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiffTalk__Crafting_Diffusion_Models_for_Generalized_Audio-Driven_Portraits_Animation/ldm/modules/diffusionmodules/model.py'],\n",
       " 'Hiera__A_Hierarchical_Vision_Transformer_without_the_Bells-and-Whistles': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hiera__A_Hierarchical_Vision_Transformer_without_the_Bells-and-Whistles/timm/utils/model.py'],\n",
       " 'Class-Adaptive_Self-Training_for_Relation_Extraction_with_Incompletely_Annotated_Training_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Class-Adaptive_Self-Training_for_Relation_Extraction_with_Incompletely_Annotated_Training_Data/model.py'],\n",
       " 'Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Saute_RL__Almost_Surely_Safe_Reinforcement_Learning_Using_State_Augmentation/RLLG/agents/common/model.py'],\n",
       " 'Effects_of_Safety_State_Augmentation_on_Safe_Exploration': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Effects_of_Safety_State_Augmentation_on_Safe_Exploration/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Effects_of_Safety_State_Augmentation_on_Safe_Exploration/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Effects_of_Safety_State_Augmentation_on_Safe_Exploration/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Effects_of_Safety_State_Augmentation_on_Safe_Exploration/RLLG/agents/common/model.py'],\n",
       " 'Maximum_diffusion_reinforcement_learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Maximum_diffusion_reinforcement_learning/mpc_lib/model.py'],\n",
       " 'Recurrent_Back-Projection_Network_for_Video_Super-Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Back-Projection_Network_for_Video_Super-Resolution/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Back-Projection_Network_for_Video_Super-Resolution/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Back-Projection_Network_for_Video_Super-Resolution/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Back-Projection_Network_for_Video_Super-Resolution/ras/src/model.py'],\n",
       " 'Boosting_Feedback_Efficiency_of_Interactive_Reinforcement_Learning_by_Adaptive_Learning_from_Scores': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Boosting_Feedback_Efficiency_of_Interactive_Reinforcement_Learning_by_Adaptive_Learning_from_Scores/model.py'],\n",
       " 'Scene-centric_vs__Object-centric_Image-Text_Cross-modal_Retrieval__A_Reproducibility_Study': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Scene-centric_vs__Object-centric_Image-Text_Cross-modal_Retrieval__A_Reproducibility_Study/CLIP/src/model.py'],\n",
       " 'Interleaving_GANs_with_knowledge_graphs_to_support_design_creativity_for_book_covers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Interleaving_GANs_with_knowledge_graphs_to_support_design_creativity_for_book_covers/model.py'],\n",
       " 'GOES_GLM__Biased_Bolides__and_Debiased_Distributions': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GOES_GLM__Biased_Bolides__and_Debiased_Distributions/model.py'],\n",
       " 'GPL__Generative_Pseudo_Labeling_for_Unsupervised_Domain_Adaptation_of_Dense_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPL__Generative_Pseudo_Labeling_for_Unsupervised_Domain_Adaptation_of_Dense_Retrieval/income/bpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GPL__Generative_Pseudo_Labeling_for_Unsupervised_Domain_Adaptation_of_Dense_Retrieval/income/bpr/gpl/model.py'],\n",
       " 'Unsupervised_Dense_Information_Retrieval_with_Contrastive_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Dense_Information_Retrieval_with_Contrastive_Learning/income/bpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Dense_Information_Retrieval_with_Contrastive_Learning/income/bpr/gpl/model.py'],\n",
       " 'Efficiently_Teaching_an_Effective_Dense_Retriever_with_Balanced_Topic_Aware_Sampling': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Efficiently_Teaching_an_Effective_Dense_Retriever_with_Balanced_Topic_Aware_Sampling/income/bpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Efficiently_Teaching_an_Effective_Dense_Retriever_with_Balanced_Topic_Aware_Sampling/income/bpr/gpl/model.py'],\n",
       " 'Injecting_Domain_Adaptation_with_Learning-to-hash_for_Effective_and_Efficient_Zero-shot_Dense_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Injecting_Domain_Adaptation_with_Learning-to-hash_for_Effective_and_Efficient_Zero-shot_Dense_Retrieval/income/bpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Injecting_Domain_Adaptation_with_Learning-to-hash_for_Effective_and_Efficient_Zero-shot_Dense_Retrieval/income/bpr/gpl/model.py'],\n",
       " 'CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages/classla/models/depparse/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages/classla/models/ner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages/classla/models/pos/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CLASSLA-Stanza__The_Next_Step_for_Linguistic_Processing_of_South_Slavic_Languages/classla/models/srl/model.py'],\n",
       " 'MatchXML__An_Efficient_Text-label_Matching_Framework_for_Extreme_Multi-label_Text_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MatchXML__An_Efficient_Text-label_Matching_Framework_for_Extreme_Multi-label_Text_Classification/model.py'],\n",
       " 'Adversarial_Erasing_with_Pruned_Elements__Towards_Better_Graph_Lottery_Ticket': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Erasing_with_Pruned_Elements__Towards_Better_Graph_Lottery_Ticket/large_scale/ogbn_arxiv/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adversarial_Erasing_with_Pruned_Elements__Towards_Better_Graph_Lottery_Ticket/large_scale/ogbn_proteins/model.py'],\n",
       " 'CenterNet___for_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CenterNet___for_Object_Detection/cdp/model.py'],\n",
       " 'FLEE-GNN__A_Federated_Learning_System_for_Edge-Enhanced_Graph_Neural_Network_in_Analyzing_Geospatial_Resilience_of_Multicommodity_Food_Flows': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FLEE-GNN__A_Federated_Learning_System_for_Edge-Enhanced_Graph_Neural_Network_in_Analyzing_Geospatial_Resilience_of_Multicommodity_Food_Flows/scripts/model.py'],\n",
       " 'XVir__A_Transformer-Based_Architecture_for_Identifying_Viral_Reads_from_Cancer_Samples': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/XVir__A_Transformer-Based_Architecture_for_Identifying_Viral_Reads_from_Cancer_Samples/model.py'],\n",
       " 'Style-Based_Global_Appearance_Flow_for_Virtual_Try-On': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Style-Based_Global_Appearance_Flow_for_Virtual_Try-On/exp/runtime/ViTPose/models/model.py'],\n",
       " 'Parser-Free_Virtual_Try-on_via_Distilling_Appearance_Flows': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Parser-Free_Virtual_Try-on_via_Distilling_Appearance_Flows/exp/runtime/ViTPose/models/model.py'],\n",
       " 'Adaptive_Path-Memory_Network_for_Temporal_Knowledge_Graph_Reasoning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Path-Memory_Network_for_Temporal_Knowledge_Graph_Reasoning/src/model.py'],\n",
       " 'Fast_Texture_Synthesis_via_Pseudo_Optimizer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fast_Texture_Synthesis_via_Pseudo_Optimizer/po/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fast_Texture_Synthesis_via_Pseudo_Optimizer/beta/po/model.py'],\n",
       " 'Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_Few-Shot_Model_Adaption': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_Few-Shot_Model_Adaption/clip/model.py'],\n",
       " 'Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/EigenTrajectory/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/agentformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/gpgraphsgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/gpgraphstgcnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/graphtern/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/implicit/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/lbebm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/pecnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/sgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Pedestrian_Group_Representations_for_Multi-modal_Trajectory_Prediction/baseline/stgcnn/model.py'],\n",
       " 'HetuMoE__An_Efficient_Trillion-scale_Mixture-of-Expert_Distributed_Training_System': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HetuMoE__An_Efficient_Trillion-scale_Mixture-of-Expert_Distributed_Training_System/python/hetu/peft/lora/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/HetuMoE__An_Efficient_Trillion-scale_Mixture-of-Expert_Distributed_Training_System/hetu/v1/examples/gnn/gnn_model/model.py'],\n",
       " 'Learning_Transferable_Architectures_for_Scalable_Image_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Transferable_Architectures_for_Scalable_Image_Recognition/cdp/model.py'],\n",
       " 'POV-Surgery__A_Dataset_for_Egocentric_Hand_and_Tool_Pose_Estimation_During_Surgical_Activities': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/POV-Surgery__A_Dataset_for_Egocentric_Hand_and_Tool_Pose_Estimation_During_Surgical_Activities/MANO/mano/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/POV-Surgery__A_Dataset_for_Egocentric_Hand_and_Tool_Pose_Estimation_During_Surgical_Activities/HandOccNet_ft/main/model.py'],\n",
       " 'PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PVANet__Lightweight_Deep_Neural_Networks_for_Real-time_Object_Detection/rcnn/src/model.py'],\n",
       " 'Dior-CVAE__Pre-trained_Language_Models_and_Diffusion_Priors_for_Variational_Dialog_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dior-CVAE__Pre-trained_Language_Models_and_Diffusion_Priors_for_Variational_Dialog_Generation/model.py'],\n",
       " 'ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ISyNet__Convolutional_Neural_Networks_design_for_AI_accelerator/lerf/lerf_sr/model.py'],\n",
       " 'Ask_the_Right_Questions__Active_Question_Reformulation_with_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Ask_the_Right_Questions__Active_Question_Reformulation_with_Reinforcement_Learning/active-qa/px/nmt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Ask_the_Right_Questions__Active_Question_Reformulation_with_Reinforcement_Learning/active-qa/third_party/bi_att_flow/basic/model.py'],\n",
       " 'EVNet__An_Explainable_Deep_Network_for_Dimension_Reduction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EVNet__An_Explainable_Deep_Network_for_Dimension_Reduction/model/model.py'],\n",
       " 'PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis/pyabsa/tasks/ABSAInstruction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis/pyabsa/tasks/AspectSentimentTripletExtraction/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis/pyabsa/tasks/UniversalSentimentAnalysis/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PyABSA__A_Modularized_Framework_for_Reproducible_Aspect-based_Sentiment_Analysis/pyabsa/tasks/__SubtaskTemplate__/models/model.py'],\n",
       " 'Robust_Natural_Language_Understanding_with_Residual_Attention_Debiasing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robust_Natural_Language_Understanding_with_Residual_Attention_Debiasing/model.py'],\n",
       " 'Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/cnn_quantization/tf_cnn_benchmarks/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/imp/max/projects/imp/config/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/meta_reward_learning/textworld/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/stacked_capsule_autoencoders/capsules/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/table_rag/agent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/tf3d/instance_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/tf3d/object_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/tf3d/semantic_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/video_timeline_modeling/vtm/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/cache_replacement/policy_learning/cache_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/fairness_teaching/in_progress/rl_a2c/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Temporal_Fusion_Transformers_for_Interpretable_Multi-horizon_Time_Series_Forecasting/graph_embedding/huge/model.py'],\n",
       " 'Interpretable_Time-series_Classification_on_Few-shot_Samples': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Interpretable_Time-series_Classification_on_Few-shot_Samples/SFA_Python-master/src/LibLinear/Model.py'],\n",
       " 'Specifying_Object_Attributes_and_Relations_in_Interactive_Scene_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Specifying_Object_Attributes_and_Relations_in_Interactive_Scene_Generation/scene_generation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Specifying_Object_Attributes_and_Relations_in_Interactive_Scene_Generation/scripts/gui/model.py'],\n",
       " 'Recursive_Visual_Attention_in_Visual_Dialog': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recursive_Visual_Attention_in_Visual_Dialog/visdialch/model.py'],\n",
       " 'Self-Attention_Generative_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Self-Attention_Generative_Adversarial_Networks/model.py'],\n",
       " 'When_Relation_Networks_meet_GANs__Relation_GANs_with_Triplet_Loss': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/When_Relation_Networks_meet_GANs__Relation_GANs_with_Triplet_Loss/super_resolution/model.py'],\n",
       " 'Heterogeneous_Graph_Neural_Networks_for_Malicious_Account_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Heterogeneous_Graph_Neural_Networks_for_Malicious_Account_Detection/algorithms/HACUD/model.py'],\n",
       " 'ContCap__A_scalable_framework_for_continual_image_captioning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ContCap__A_scalable_framework_for_continual_image_captioning/model.py'],\n",
       " 'Mean_teachers_are_better_role_models__Weight-averaged_consistency_targets_improve_semi-supervised_deep_learning_results': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mean_teachers_are_better_role_models__Weight-averaged_consistency_targets_improve_semi-supervised_deep_learning_results/pixelssl/task_template/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mean_teachers_are_better_role_models__Weight-averaged_consistency_targets_improve_semi-supervised_deep_learning_results/task/sseg/model.py'],\n",
       " 'CheXpert____Approximating_the_CheXpert_labeler_for_Speed_Differentiability__and_Probabilistic_Output': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CheXpert____Approximating_the_CheXpert_labeler_for_Speed_Differentiability__and_Probabilistic_Output/chexpert_approximator/model.py'],\n",
       " 'Diversifying_Task-oriented_Dialogue_Response_Generation_with_Prototype_Guided_Paraphrasing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Diversifying_Task-oriented_Dialogue_Response_Generation_with_Prototype_Guided_Paraphrasing/code/unsupervised_models/model.py'],\n",
       " 'Alpha-Refine__Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Alpha-Refine__Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation/external/RT_MDNet/modules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Alpha-Refine__Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation/ltr/models/backbone/efficientnet/model.py'],\n",
       " 'Parallel-Data-Free_Voice_Conversion_Using_Cycle-Consistent_Adversarial_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Parallel-Data-Free_Voice_Conversion_Using_Cycle-Consistent_Adversarial_Networks/model.py'],\n",
       " 'Light_bending_and_X-ray_echoes_from_behind_a_supermassive_black_hole': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Light_bending_and_X-ray_echoes_from_behind_a_supermassive_black_hole/pylag/model.py'],\n",
       " 'Action_sequencing_using_visual_permutations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Action_sequencing_using_visual_permutations/scrabble/model.py'],\n",
       " 'Spatial_As_Deep__Spatial_CNN_for_Traffic_Scene_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial_As_Deep__Spatial_CNN_for_Traffic_Scene_Understanding/model.py'],\n",
       " 'Hamilton-Jacobi_Deep_Q-Learning_for_Deterministic_Continuous-Time_Systems_with_Lipschitz_Continuous_Controls': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Hamilton-Jacobi_Deep_Q-Learning_for_Deterministic_Continuous-Time_Systems_with_Lipschitz_Continuous_Controls/algorithms/model.py'],\n",
       " 'FANG__Leveraging_Social_Context_for_Fake_News_Detection_Using_Graph_Representation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FANG__Leveraging_Social_Context_for_Fake_News_Detection_Using_Graph_Representation/graph/ngcn/model.py'],\n",
       " 'Automatic_Grading_of_Individual_Knee_Osteoarthritis_Features_in_Plain_Radiographs_using_Deep_Convolutional_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Automatic_Grading_of_Individual_Knee_Osteoarthritis_Features_in_Plain_Radiographs_using_Deep_Convolutional_Neural_Networks/oarsigrading/training/model.py'],\n",
       " 'Light_Multi-segment_Activation_for_Model_Compression': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Light_Multi-segment_Activation_for_Model_Compression/translation_models/model.py'],\n",
       " 'Deep_Anomaly_Detection_with_Outlier_Exposure': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Anomaly_Detection_with_Outlier_Exposure/NLP_language_modeling/model.py'],\n",
       " 'Robustness_of_Conditional_GANs_to_Noisy_Labels': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robustness_of_Conditional_GANs_to_Noisy_Labels/mnist/model.py'],\n",
       " 'Open-World_Semi-Supervised_Learning_for_Node_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Open-World_Semi-Supervised_Learning_for_Node_Classification/networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Open-World_Semi-Supervised_Learning_for_Node_Classification/networks_large/model.py'],\n",
       " 'Population_Based_Augmentation__Efficient_Learning_of_Augmentation_Policy_Schedules': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Population_Based_Augmentation__Efficient_Learning_of_Augmentation_Policy_Schedules/pba/model.py'],\n",
       " 'Variational_Autoencoder_with_Arbitrary_Conditioning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Variational_Autoencoder_with_Arbitrary_Conditioning/celeba_model/model.py'],\n",
       " 'DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/DialogueGCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/DialogueRNN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/ICON-end-to-end/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/ICON/IEMOCAP/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/bc-LSTM-pytorch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/COSMIC/erc-training/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueRNN__An_Attentive_RNN_for_Emotion_Detection_in_Conversations/emotion-cause-extraction/RoBERTa Baseline/simpletransformers/model.py'],\n",
       " 'Smoothed_Dilated_Convolutions_for_Improved_Dense_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Smoothed_Dilated_Convolutions_for_Improved_Dense_Prediction/model.py'],\n",
       " 'Distribution-induced_Bidirectional_Generative_Adversarial_Network_for_Graph_Representation_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Distribution-induced_Bidirectional_Generative_Adversarial_Network_for_Graph_Representation_Learning/DBGAN_cluster/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Distribution-induced_Bidirectional_Generative_Adversarial_Network_for_Graph_Representation_Learning/DBGAN_link/model.py'],\n",
       " 'Deep_Reinforcement_Learning_for_List-wise_Recommendations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Reinforcement_Learning_for_List-wise_Recommendations/src/model.py'],\n",
       " 'Proposal_for_a_Leaky-Integrate-Fire_Spiking_Neuron_based_on_Magneto-Electric_Switching_of_Ferro-magnets': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Proposal_for_a_Leaky-Integrate-Fire_Spiking_Neuron_based_on_Magneto-Electric_Switching_of_Ferro-magnets/model.py'],\n",
       " 'DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/CURL/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/DeepLPF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/SteReFo/blur_CV_refinement/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/SteReFo/blur_baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/SteReFo/blur_refinement/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/SteReFo/stereonet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/NLP/EntityCS/wsd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/NLP/UniMS/unims/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/noahnmt/multiuat/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/noahnmt/multiuat/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/noahnmt/multiuat/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseShift__Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization/noahnmt/multiuat/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Learning_to_Ask__Neural_Question_Generation_for_Reading_Comprehension': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_Ask__Neural_Question_Generation_for_Reading_Comprehension/model.py'],\n",
       " 'SQuAD__100_000__Questions_for_Machine_Comprehension_of_Text': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SQuAD__100_000__Questions_for_Machine_Comprehension_of_Text/model.py'],\n",
       " 'Machine_Comprehension_by_Text-to-Text_Neural_Question_Generation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Machine_Comprehension_by_Text-to-Text_Neural_Question_Generation/model.py'],\n",
       " 'Discriminative_Deep_Dyna-Q__Robust_Planning_for_Dialogue_Policy_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Discriminative_Deep_Dyna-Q__Robust_Planning_for_Dialogue_Policy_Learning/D3Q/src/deep_dialog/usersims/model.py'],\n",
       " 'Show__Attend_and_Tell__Neural_Image_Caption_Generation_with_Visual_Attention': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show__Attend_and_Tell__Neural_Image_Caption_Generation_with_Visual_Attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show__Attend_and_Tell__Neural_Image_Caption_Generation_with_Visual_Attention/Image_Captioning/model.py'],\n",
       " 'VQA__Visual_Question_Answering': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VQA__Visual_Question_Answering/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VQA__Visual_Question_Answering/Image_Captioning/model.py'],\n",
       " 'Automatic_Temporally_Coherent_Video_Colorization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Automatic_Temporally_Coherent_Video_Colorization/keras_noise2noise/model.py'],\n",
       " 'Applying_Deep_Learning_to_the_Newsvendor_Problem': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Applying_Deep_Learning_to_the_Newsvendor_Problem/model.py'],\n",
       " 'On_the_Effectiveness_of_Weight-Encoded_Neural_Implicit_3D_Shapes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Effectiveness_of_Weight-Encoded_Neural_Implicit_3D_Shapes/neuralImplicitTools/src/model.py'],\n",
       " 'Probing_Linguistic_Information_For_Logical_Inference_In_Pre-trained_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Probing_Linguistic_Information_For_Logical_Inference_In_Pre-trained_Language_Models/inform_prob/model.py'],\n",
       " 'DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/DialogueGCN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/DialogueRNN/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/ICON-end-to-end/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/ICON/IEMOCAP/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/bc-LSTM-pytorch/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/COSMIC/erc-training/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DialogueGCN__A_Graph_Convolutional_Neural_Network_for_Emotion_Recognition_in_Conversation/emotion-cause-extraction/RoBERTa Baseline/simpletransformers/model.py'],\n",
       " 'DeepFaceLab__Integrated__flexible_and_extensible_face-swapping_framework': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DeepFaceLab__Integrated__flexible_and_extensible_face-swapping_framework/model.py'],\n",
       " 'Show_and_Tell__A_Neural_Image_Caption_Generator': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Show_and_Tell__A_Neural_Image_Caption_Generator/model.py'],\n",
       " 'Unsupervised_Extractive_Summarization_by_Pre-training_Hierarchical_Transformers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Extractive_Summarization_by_Pre-training_Hierarchical_Transformers/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unsupervised_Extractive_Summarization_by_Pre-training_Hierarchical_Transformers/fairseq/models/roberta/model.py'],\n",
       " 'High-Performance_Large-Scale_Image_Recognition_Without_Normalization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High-Performance_Large-Scale_Image_Recognition_Without_Normalization/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High-Performance_Large-Scale_Image_Recognition_Without_Normalization/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High-Performance_Large-Scale_Image_Recognition_Without_Normalization/PatchCore/src/model.py'],\n",
       " 'MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/MIDAS__Microcluster-Based_Detector_of_Anomalies_in_Edge_Streams/lerf/lerf_sr/model.py'],\n",
       " 'Multi-Facet_Recommender_Networks_with_Spherical_Optimization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-Facet_Recommender_Networks_with_Spherical_Optimization/models/model.py'],\n",
       " 'Direct_Speech-to-image_Translation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Direct_Speech-to-image_Translation/StackGAN_v2/model.py'],\n",
       " 'Mitigating_Memorization_of_Noisy_Labels_via_Regularization_between_Representations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Mitigating_Memorization_of_Noisy_Labels_via_Regularization_between_Representations/model.py'],\n",
       " 'BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BCS-Net__Boundary__Context_and_Semantic_for_Automatic_COVID-19_Lung_Infection_Segmentation_from_CT_Images/jasper/src/model.py'],\n",
       " 'Single-Stage_6D_Object_Pose_Estimation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Single-Stage_6D_Object_Pose_Estimation/model.py'],\n",
       " 'How_baryons_can_significantly_bias_cluster_count_cosmology': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/How_baryons_can_significantly_bias_cluster_count_cosmology/lensing_haloes/halo/model.py'],\n",
       " 'Dual_Path_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dual_Path_Networks/erfnet/src/model.py'],\n",
       " 'Projecting_Your_View_Attentively__Monocular_Road_Scene_Layout_Estimation_via_Cross-View_Transformation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Projecting_Your_View_Attentively__Monocular_Road_Scene_Layout_Estimation_via_Cross-View_Transformation/crossView/model.py'],\n",
       " 'UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning/CV/Effective Transformer-based Solution for RSNA Intracranial Hemorrhage Detection/easymia/model/brain_intracranial_hemorrhage_clas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning/CV/PWCNet/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning/KG/DuKEVU_Baseline/paddle-video-classify-tag/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNIMO__Towards_Unified-Modal_Understanding_and_Generation_via_Cross-Modal_Contrastive_Learning/NLP/ACL2019-JEMT/model.py'],\n",
       " '3DSNet__Unsupervised_Shape-to-Shape_3D_Style_Transfer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/3DSNet__Unsupervised_Shape-to-Shape_3D_Style_Transfer/model/model.py'],\n",
       " 'Single_Image_Reflection_Removal_With_Absorption_Effect': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Single_Image_Reflection_Removal_With_Absorption_Effect/model.py'],\n",
       " 'Conditional_Image_Synthesis_With_Auxiliary_Classifier_GANs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Conditional_Image_Synthesis_With_Auxiliary_Classifier_GANs/model.py'],\n",
       " 'Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/cnn_quantization/tf_cnn_benchmarks/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/imp/max/projects/imp/config/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/meta_reward_learning/textworld/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/stacked_capsule_autoencoders/capsules/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/table_rag/agent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/tf3d/instance_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/tf3d/object_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/tf3d/semantic_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/video_timeline_modeling/vtm/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/cache_replacement/policy_learning/cache_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/fairness_teaching/in_progress/rl_a2c/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Accelerating_Large-Scale_Inference_with_Anisotropic_Vector_Quantization/graph_embedding/huge/model.py'],\n",
       " 'Code_to_Comment_Translation__A_Comparative_Study_on_Model_Effectiveness___Errors': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Code_to_Comment_Translation__A_Comparative_Study_on_Model_Effectiveness___Errors/NeuralCodeSum/main/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Code_to_Comment_Translation__A_Comparative_Study_on_Model_Effectiveness___Errors/CodeBERT/code/model.py'],\n",
       " 'Joint_entity_recognition_and_relation_extraction_as_a_multi-head_selection_problem': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Joint_entity_recognition_and_relation_extraction_as_a_multi-head_selection_problem/model.py'],\n",
       " 'VALUE__A_Multi-Task_Benchmark_for_Video-and-Language_Understanding_Evaluation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/VALUE__A_Multi-Task_Benchmark_for_Video-and-Language_Understanding_Evaluation/model/model.py'],\n",
       " 'DoubleEnsemble__A_New_Ensemble_Method_Based_on_Sample_Reweighting_and_Feature_Selection_for_Financial_Data_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DoubleEnsemble__A_New_Ensemble_Method_Based_on_Sample_Reweighting_and_Feature_Selection_for_Financial_Data_Analysis/examples/benchmarks/TRA/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DoubleEnsemble__A_New_Ensemble_Method_Based_on_Sample_Reweighting_and_Feature_Selection_for_Financial_Data_Analysis/qlib/contrib/meta/data_selection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DoubleEnsemble__A_New_Ensemble_Method_Based_on_Sample_Reweighting_and_Feature_Selection_for_Financial_Data_Analysis/qlib/model/meta/model.py'],\n",
       " 'Designing_Network_Design_Spaces': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/mm/opt/src/fastspeech2_ms/utils/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/mm/wukong-huahua/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/FastSpeech/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/FastSpeech/src/deepspeech2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/FastSpeech/src/waveglow/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/ctcmodel/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/audio/jasper/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/DeepID/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/DnCNN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/E-NET/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/EfficientDet_d0/src/efficientdet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/EfficientDet_d0/src/efficientnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/PaDiM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/PatchCore/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/RDN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/REDNet30/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/StarGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/cdp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/erfnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ras/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/rcnn/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/simple_pose/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/ssc_resnet50/src/network/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/wdsr/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/cv/lerf/lerf_sr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/atae_lstm/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/luke/src/luke/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/luke/src/reading_comprehension/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/nlp/luke/src/relation_classification/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/recommend/IntTower/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/research/recommend/JEPOO/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/community/cv/wgan_gp/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/official/audio/MELGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Designing_Network_Design_Spaces/official/cv/DBNet/src/modules/model.py'],\n",
       " 'Normed_Spaces_for_Graph_Embedding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Normed_Spaces_for_Graph_Embedding/recosys/sympa/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Normed_Spaces_for_Graph_Embedding/sympa/model.py'],\n",
       " 'FastSpeech__Fast__Robust_and_Controllable_Text_to_Speech': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FastSpeech__Fast__Robust_and_Controllable_Text_to_Speech/src/lib/model.py'],\n",
       " 'Semantically_Self-Aligned_Network_for_Text-to-Image_Part-aware_Person_Re-identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantically_Self-Aligned_Network_for_Text-to-Image_Part-aware_Person_Re-identification/src/model/model.py'],\n",
       " 'DenseFuse__A_Fusion_Approach_to_Infrared_and_Visible_Images': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DenseFuse__A_Fusion_Approach_to_Infrared_and_Visible_Images/FusionGAN/model.py'],\n",
       " 'LLVIP__A_Visible-infrared_Paired_Dataset_for_Low-light_Vision': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LLVIP__A_Visible-infrared_Paired_Dataset_for_Low-light_Vision/FusionGAN/model.py'],\n",
       " 'NeuroCartography__Scalable_Automatic_Visual_Summarization_of_Concepts_in_Deep_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/NeuroCartography__Scalable_Automatic_Visual_Summarization_of_Concepts_in_Deep_Neural_Networks/src/python/utils/model.py'],\n",
       " 'Bi-Bimodal_Modality_Fusion_for_Correlation-Controlled_Multimodal_Sentiment_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bi-Bimodal_Modality_Fusion_for_Correlation-Controlled_Multimodal_Sentiment_Analysis/Low-rank-Multimodal-Fusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bi-Bimodal_Modality_Fusion_for_Correlation-Controlled_Multimodal_Sentiment_Analysis/TensorFusionNetworks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bi-Bimodal_Modality_Fusion_for_Correlation-Controlled_Multimodal_Sentiment_Analysis/contextual-attention-based-LSTM/model.py'],\n",
       " 'Improving_Multimodal_Fusion_with_Hierarchical_Mutual_Information_Maximization_for_Multimodal_Sentiment_Analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multimodal_Fusion_with_Hierarchical_Mutual_Information_Maximization_for_Multimodal_Sentiment_Analysis/Low-rank-Multimodal-Fusion/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multimodal_Fusion_with_Hierarchical_Mutual_Information_Maximization_for_Multimodal_Sentiment_Analysis/TensorFusionNetworks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improving_Multimodal_Fusion_with_Hierarchical_Mutual_Information_Maximization_for_Multimodal_Sentiment_Analysis/contextual-attention-based-LSTM/model.py'],\n",
       " 'A_composite_neural_network_that_learns_from_multi-fidelity_data__Application_to_function_approximation_and_inverse_PDE_problems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_composite_neural_network_that_learns_from_multi-fidelity_data__Application_to_function_approximation_and_inverse_PDE_problems/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_composite_neural_network_that_learns_from_multi-fidelity_data__Application_to_function_approximation_and_inverse_PDE_problems/deepxde/zcs/model.py'],\n",
       " 'Micro_Expression_Generation_with_Thin-plate_Spline_Motion_Model_and_Face_Parsing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Micro_Expression_Generation_with_Thin-plate_Spline_Motion_Model_and_Face_Parsing/modules/model.py'],\n",
       " 'GoalNet__Inferring_Conjunctive_Goal_Predicates_from_Human_Plan_Demonstrations_for_Robot_Instruction_Following': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/GoalNet__Inferring_Conjunctive_Goal_Predicates_from_Human_Plan_Demonstrations_for_Robot_Instruction_Following/src/model.py'],\n",
       " 'Low_frequency_X-ray_timing_with_Gaussian_processes_and_reverberation_in_the_radio-loud_AGN_3C_120': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Low_frequency_X-ray_timing_with_Gaussian_processes_and_reverberation_in_the_radio-loud_AGN_3C_120/pylag/model.py'],\n",
       " 'Neighbor2Seq__Deep_Learning_on_Massive_Graphs_by_Transforming_Neighbors_to_Sequences': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Neighbor2Seq__Deep_Learning_on_Massive_Graphs_by_Transforming_Neighbors_to_Sequences/Neighbor2Seq/model.py'],\n",
       " 'A_comprehensive_study_of_non-adaptive_and_residual-based_adaptive_sampling_for_physics-informed_neural_networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_comprehensive_study_of_non-adaptive_and_residual-based_adaptive_sampling_for_physics-informed_neural_networks/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_comprehensive_study_of_non-adaptive_and_residual-based_adaptive_sampling_for_physics-informed_neural_networks/deepxde/zcs/model.py'],\n",
       " 'Learning_Sparse_Analytic_Filters_for_Piano_Transcription': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Sparse_Analytic_Filters_for_Piano_Transcription/scripts/model.py'],\n",
       " 'Object-Centric_Learning_with_Slot_Attention': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Object-Centric_Learning_with_Slot_Attention/model.py'],\n",
       " 'Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/coref/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/depparse/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/langid/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/ner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/pos/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Biomedical_and_Clinical_English_Model_Packages_in_the_Stanza_Python_NLP_Library/stanza/models/tokenization/model.py'],\n",
       " 'Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/coref/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/depparse/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/langid/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/ner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/pos/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Stanza__A_Python_Natural_Language_Processing_Toolkit_for_Many_Human_Languages/stanza/models/tokenization/model.py'],\n",
       " 'UNITER__UNiversal_Image-TExt_Representation_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UNITER__UNiversal_Image-TExt_Representation_Learning/src/model/model.py'],\n",
       " 'CFSum__A_Coarse-to-Fine_Contribution_Network_for_Multimodal_Summarization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/CFSum__A_Coarse-to-Fine_Contribution_Network_for_Multimodal_Summarization/src/model/model.py'],\n",
       " 'Interaction-Aware_Planning_With_Deep_Inverse_Reinforcement_Learning_for_Human-Like_Autonomous_Driving_in_Merge_Scenarios': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Interaction-Aware_Planning_With_Deep_Inverse_Reinforcement_Learning_for_Human-Like_Autonomous_Driving_in_Merge_Scenarios/model.py'],\n",
       " 'Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief/BOiLS/DRiLLS/drills/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief/RDUCB/hdbo/febo/algorithms/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief/RDUCB/hdbo/febo/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Model-Based_Offline_Reinforcement_Learning_with_Pessimism-Modulated_Dynamics_Belief/RLLG/agents/common/model.py'],\n",
       " 'New_Frontiers_in_Graph_Autoencoders__Joint_Community_Detection_and_Link_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/New_Frontiers_in_Graph_Autoencoders__Joint_Community_Detection_and_Link_Prediction/modularity_aware_gae/model.py'],\n",
       " 'SageMix__Saliency-Guided_Mixup_for_Point_Clouds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SageMix__Saliency-Guided_Mixup_for_Point_Clouds/pointcloud/model.py'],\n",
       " 'Thinking_Two_Moves_Ahead__Anticipating_Other_Users_Improves_Backdoor_Attacks_in_Federated_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Thinking_Two_Moves_Ahead__Anticipating_Other_Users_Improves_Backdoor_Attacks_in_Federated_Learning/models/model.py'],\n",
       " 'AutoVideo__An_Automated_Video_Action_Recognition_System': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoVideo__An_Automated_Video_Action_Recognition_System/autovideo/recognition/R2p1D/model.py'],\n",
       " 'Pseudo-Inverted_Bottleneck_Convolution_for_DARTS_Search_Space': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Pseudo-Inverted_Bottleneck_Convolution_for_DARTS_Search_Space/cnn/model.py'],\n",
       " 'OmDet__Large-scale_vision-language_multi-dataset_pre-training_with_multimodal_detection_network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OmDet__Large-scale_vision-language_multi-dataset_pre-training_with_multimodal_detection_network/omdet/modeling/language_backbone/clip/models/model.py'],\n",
       " 'From_Sky_to_the_Ground__A_Large-scale_Benchmark_and_Simple_Baseline_Towards_Real_Rain_Removal': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/From_Sky_to_the_Ground__A_Large-scale_Benchmark_and_Simple_Baseline_Towards_Real_Rain_Removal/SCD-Former/model.py'],\n",
       " 'New_MGCAMB_tests_of_gravity_with_CosmoMC_and_Cobaya': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/New_MGCAMB_tests_of_gravity_with_CosmoMC_and_Cobaya/camb/camb/model.py'],\n",
       " 'Masked_Autoencoders_Are_Scalable_Vision_Learners': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Masked_Autoencoders_Are_Scalable_Vision_Learners/visionts/model.py'],\n",
       " 'Recurrent_Environment_Simulators': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Recurrent_Environment_Simulators/forward_models/model.py'],\n",
       " 'SepLUT__Separable_Image-adaptive_Lookup_Tables_for_Real-time_Image_Enhancement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SepLUT__Separable_Image-adaptive_Lookup_Tables_for_Real-time_Image_Enhancement/seplut/model.py'],\n",
       " 'Joint_Admission_Control_and_Resource_Allocation_of_Virtual_Network_Embedding_via_Hierarchical_Deep_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Joint_Admission_Control_and_Resource_Allocation_of_Virtual_Network_Embedding_via_Hierarchical_Deep_Reinforcement_Learning/solver/learning/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Joint_Admission_Control_and_Resource_Allocation_of_Virtual_Network_Embedding_via_Hierarchical_Deep_Reinforcement_Learning/solver/learning/gae_vne/model.py'],\n",
       " 'Towards_a_Holistic_Understanding_of_Mathematical_Questions_with_Contrastive_Pre-training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_a_Holistic_Understanding_of_Mathematical_Questions_with_Contrastive_Pre-training/src/model.py'],\n",
       " 'Learning_from_Unlabeled_3D_Environments_for_Vision-and-Language_Navigation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_from_Unlabeled_3D_Environments_for_Vision-and-Language_Navigation/map_nav_src/models/model.py'],\n",
       " 'Gated-ViGAT__Efficient_Bottom-Up_Event_Recognition_and_Explanation_Using_a_New_Frame_Selection_Policy_and_Gating_Mechanism': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Gated-ViGAT__Efficient_Bottom-Up_Event_Recognition_and_Explanation_Using_a_New_Frame_Selection_Policy_and_Gating_Mechanism/model.py'],\n",
       " 'L2CS-Net__Fine-Grained_Gaze_Estimation_in_Unconstrained_Environments': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/L2CS-Net__Fine-Grained_Gaze_Estimation_in_Unconstrained_Environments/l2cs/model.py'],\n",
       " 'Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/dpkd/transformers/examples/research_projects/fsner/src/fsner/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/understand_icl/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/uprise/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adapting_Large_Language_Models_to_Domains_via_Reading_Comprehension/structured_prompting/fairseq-version/fairseq/fairseq/models/roberta/model.py'],\n",
       " 'Fully_transformer-based_biomarker_prediction_from_colorectal_cancer_histology__a_large-scale_multicentric_study': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fully_transformer-based_biomarker_prediction_from_colorectal_cancer_histology__a_large-scale_multicentric_study/marugoto/mil/model.py'],\n",
       " 'RAFaRe__Learning_Robust_and_Accurate_Non-parametric_3D_Face_Reconstruction_from_Pseudo_2D_3D_Pairs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RAFaRe__Learning_Robust_and_Accurate_Non-parametric_3D_Face_Reconstruction_from_Pseudo_2D_3D_Pairs/engineer/face_parse/model.py'],\n",
       " 'Do_graph_neural_networks_learn_traditional_jet_substructure_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Do_graph_neural_networks_learn_traditional_jet_substructure_/xai4hep/mlpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Do_graph_neural_networks_learn_traditional_jet_substructure_/xai4hep/particlenet/model.py'],\n",
       " 'A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction/pyabsa/tasks/ABSAInstruction/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction/pyabsa/tasks/AspectSentimentTripletExtraction/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction/pyabsa/tasks/UniversalSentimentAnalysis/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-task_Learning_Model_for_Chinese-oriented_Aspect_Polarity_Classification_and_Aspect_Term_Extraction/pyabsa/tasks/__SubtaskTemplate__/models/model.py'],\n",
       " 'Deep_Quantigraphic_Image_Enhancement_via_Comparametric_Equations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Quantigraphic_Image_Enhancement_via_Comparametric_Equations/model.py'],\n",
       " 'Caption_Anything__Interactive_Image_Description_with_Diverse_Multimodal_Controls': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Caption_Anything__Interactive_Image_Description_with_Diverse_Multimodal_Controls/caption_anything/model.py'],\n",
       " 'RoSteALS__Robust_Steganography_using_Autoencoder_Latent_Space': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RoSteALS__Robust_Steganography_using_Autoencoder_Latent_Space/annotator/openpose/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RoSteALS__Robust_Steganography_using_Autoencoder_Latent_Space/cldm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RoSteALS__Robust_Steganography_using_Autoencoder_Latent_Space/ldm/modules/diffusionmodules/model.py'],\n",
       " 'AU-aware_graph_convolutional_network_for_Macro-_and_Micro-expression_spotting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AU-aware_graph_convolutional_network_for_Macro-_and_Micro-expression_spotting/model.py'],\n",
       " 'RiDDLE__Reversible_and_Diversified_De-identification_with_Latent_Encryptor': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RiDDLE__Reversible_and_Diversified_De-identification_with_Latent_Encryptor/models/stylegan2/model.py'],\n",
       " 'On_the_number_of_subproblem_iterations_per_coupling_step_in_partitioned_fluid-structure_interaction_simulations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_number_of_subproblem_iterations_per_coupling_step_in_partitioned_fluid-structure_interaction_simulations/data_structure/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_number_of_subproblem_iterations_per_coupling_step_in_partitioned_fluid-structure_interaction_simulations/tests/coupled_solvers/models/model.py'],\n",
       " 'Initiative_Defense_against_Facial_Manipulation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Initiative_Defense_against_Facial_Manipulation/model.py'],\n",
       " 'Weakly_Supervised_Clustering_by_Exploiting_Unique_Class_Count': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly_Supervised_Clustering_by_Exploiting_Unique_Class_Count/ucc/model.py'],\n",
       " 'Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/trainer/callbacks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/multimodal/llava/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/multimodal/multimodal_simple/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bert/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bert/classifier/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bert/extractive_summarization/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bert/token_classifier/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/bloom/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/btlm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/dpo/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/dpr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/esm2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/falcon/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/gemma2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/gpt2/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/gpt3/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/gptj/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/jais/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/llama/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/mistral/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/mixtral/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/santacoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/starcoder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/t5/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/nlp/transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/vision/dit/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cerebras-GPT__Open_Compute-Optimal_Language_Models_Trained_on_the_Cerebras_Wafer-Scale_Cluster/src/cerebras/modelzoo/models/vision/vision_transformer/model.py'],\n",
       " 'Regression-based_Deep-Learning_predicts_molecular_biomarkers_from_pathology_slides': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Regression-based_Deep-Learning_predicts_molecular_biomarkers_from_pathology_slides/marugoto/mil/model.py'],\n",
       " 'Learning_to_Fly_in_Seconds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_to_Fly_in_Seconds/tests/src/nn/layers/gru/pytorch/model.py'],\n",
       " 'Reliable_extrapolation_of_deep_neural_operators_informed_by_physics_or_sparse_observations': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Reliable_extrapolation_of_deep_neural_operators_informed_by_physics_or_sparse_observations/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Reliable_extrapolation_of_deep_neural_operators_informed_by_physics_or_sparse_observations/deepxde/zcs/model.py'],\n",
       " 'Fourier-MIONet__Fourier-enhanced_multiple-input_neural_operators_for_multiphase_modeling_of_geological_carbon_sequestration': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fourier-MIONet__Fourier-enhanced_multiple-input_neural_operators_for_multiphase_modeling_of_geological_carbon_sequestration/deepxde/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fourier-MIONet__Fourier-enhanced_multiple-input_neural_operators_for_multiphase_modeling_of_geological_carbon_sequestration/deepxde/zcs/model.py'],\n",
       " 'Unicom__Universal_and_Compact_Representation_Learning_for_Image_Retrieval': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unicom__Universal_and_Compact_Representation_Learning_for_Image_Retrieval/llava/model/multimodal_encoder/dev_eva_clip/eva_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unicom__Universal_and_Compact_Representation_Learning_for_Image_Retrieval/unicom/unicom/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Unicom__Universal_and_Compact_Representation_Learning_for_Image_Retrieval/downstream/llava/model/multimodal_encoder/dev_eva_clip/eva_clip/model.py'],\n",
       " 'Omni-Scale_Feature_Learning_for_Person_Re-Identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Omni-Scale_Feature_Learning_for_Person_Re-Identification/PDarts/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Omni-Scale_Feature_Learning_for_Person_Re-Identification/PaDiM/src/model.py'],\n",
       " 'FedFA__Federated_Learning_with_Feature_Anchors_to_Align_Features_and_Classifiers_for_Heterogeneous_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FedFA__Federated_Learning_with_Feature_Anchors_to_Align_Features_and_Classifiers_for_Heterogeneous_Data/model.py'],\n",
       " 'One-shot_Joint_Extraction__Registration_and_Segmentation_of_Neuroimaging_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/One-shot_Joint_Extraction__Registration_and_Segmentation_of_Neuroimaging_Data/model.py'],\n",
       " 'The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/3/AECRNet/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/4/ACGNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/4/Fourier-Features-Let-Networks-Learn-High-Frequency/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/LECF/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/LIE-IQA/networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/UColor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/Cybertron/cybertron/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_IDEFICS_community-oriented_intervention_programme__a_new_model_for_childhood_obesity_prevention_in_Europe_/6/informer/model/model.py'],\n",
       " 'Evolution_Strategies_as_a_Scalable_Alternative_to_Reinforcement_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Evolution_Strategies_as_a_Scalable_Alternative_to_Reinforcement_Learning/model.py'],\n",
       " 'Can_Bad_Teaching_Induce_Forgetting__Unlearning_in_Deep_Networks_using_an_Incompetent_Teacher': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Bad_Teaching_Induce_Forgetting__Unlearning_in_Deep_Networks_using_an_Incompetent_Teacher/model.py'],\n",
       " 'A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_v106/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_v107/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_v115/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_v68/video/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Similarity_Alignment_Model_for_Video_Copy_Segment_Matching/VSC22-Descriptor-Track-1st/train/train_vid_score/video/model.py'],\n",
       " 'Feature_Fusion_from_Head_to_Tail_for_Long-Tailed_Visual_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Feature_Fusion_from_Head_to_Tail_for_Long-Tailed_Visual_Recognition/models/ride_model/model.py'],\n",
       " 'The_Tensor_Brain__A_Unified_Theory_of_Perception__Memory_and_Semantic_Decoding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/The_Tensor_Brain__A_Unified_Theory_of_Perception__Memory_and_Semantic_Decoding/tensorbrain/model.py'],\n",
       " 'AI-accelerated_Discovery_of_Altermagnetic_Materials': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AI-accelerated_Discovery_of_Altermagnetic_Materials/model.py'],\n",
       " 'Constructing_Boundary-identical_Microstructures_by_Guided_Diffusion_for_Fast_Multiscale_Designs': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Constructing_Boundary-identical_Microstructures_by_Guided_Diffusion_for_Fast_Multiscale_Designs/network/model.py'],\n",
       " 'Deep_Reinforcement_Learning_with_Task-Adaptive_Retrieval_via_Hypernetwork': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Reinforcement_Learning_with_Task-Adaptive_Retrieval_via_Hypernetwork/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Reinforcement_Learning_with_Task-Adaptive_Retrieval_via_Hypernetwork/torch_ac/model.py'],\n",
       " 'EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/EigenTrajectory/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/agentformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/gpgraphsgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/gpgraphstgcnn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/graphtern/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/implicit/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/lbebm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/pecnet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/sgcn/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/EigenTrajectory__Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting/baseline/stgcnn/model.py'],\n",
       " 'Your_Negative_May_not_Be_True_Negative__Boosting_Image-Text_Matching_with_False_Negative_Elimination': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Your_Negative_May_not_Be_True_Negative__Boosting_Image-Text_Matching_with_False_Negative_Elimination/model.py'],\n",
       " 'OTRE__Where_Optimal_Transport_Guided_Unpaired_Image-to-Image_Translation_Meets_Regularization_by_Enhancing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OTRE__Where_Optimal_Transport_Guided_Unpaired_Image-to-Image_Translation_Meets_Regularization_by_Enhancing/Cycle-GAN/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OTRE__Where_Optimal_Transport_Guided_Unpaired_Image-to-Image_Translation_Meets_Regularization_by_Enhancing/OTE-GAN/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/OTRE__Where_Optimal_Transport_Guided_Unpaired_Image-to-Image_Translation_Meets_Regularization_by_Enhancing/OTTGAN/model/model.py'],\n",
       " 'Differentiable_Modelling_of_Percussive_Audio_with_Transient_and_Spectral_Synthesis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Differentiable_Modelling_of_Percussive_Audio_with_Transient_and_Spectral_Synthesis/drumblender/utils/model.py'],\n",
       " 'High-Resolution_Spatial_Transcriptomics_from_Histology_Images_using_HisToSGE': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/High-Resolution_Spatial_Transcriptomics_from_Histology_Images_using_HisToSGE/model.py'],\n",
       " 'DM-VTON__Distilled_Mobile_Real-time_Virtual_Try-On': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DM-VTON__Distilled_Mobile_Real-time_Virtual_Try-On/exp/runtime/ViTPose/models/model.py'],\n",
       " 'Seq2seq_Dependency_Parsing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Seq2seq_Dependency_Parsing/cdp/model.py'],\n",
       " 'Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Towards_Compact_Single_Image_Super-Resolution_via_Contrastive_Self-distillation/cdp/model.py'],\n",
       " 'Self-optimizing_Feature_Generation_via_Categorical_Hashing_Representation_and_Hierarchical_Reinforcement_Crossing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Self-optimizing_Feature_Generation_via_Categorical_Hashing_Representation_and_Hierarchical_Reinforcement_Crossing/model.py'],\n",
       " 'BlazeNeo__Blazing_fast_polyp_segmentation_and_neoplasm_detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BlazeNeo__Blazing_fast_polyp_segmentation_and_neoplasm_detection/models/blazeneo/model.py'],\n",
       " 'Progressive_Attention_Guidance_for_Whole_Slide_Vulvovaginal_Candidiasis_Screening': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Progressive_Attention_Guidance_for_Whole_Slide_Vulvovaginal_Candidiasis_Screening/codes/image_level/retinanet/model.py'],\n",
       " 'BeatNet__CRNN_and_Particle_Filtering_for_Online_Joint_Beat_Downbeat_and_Meter_Tracking': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BeatNet__CRNN_and_Particle_Filtering_for_Online_Joint_Beat_Downbeat_and_Meter_Tracking/DBNet/src/modules/model.py'],\n",
       " 'Fast__Expressive_SE__n___Equivariant_Networks_through_Weight-Sharing_in_Position-Orientation_Space': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fast__Expressive_SE__n___Equivariant_Networks_through_Weight-Sharing_in_Position-Orientation_Space/n_body_system/model.py'],\n",
       " 'AutoAugment__Learning_Augmentation_Policies_from_Data': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/ArbitraryStyleTransfer/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/Auto-DeepLab/src/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/CBAM/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/CGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/advanced_east/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/aecrnet/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoAugment__Learning_Augmentation_Policies_from_Data/cdp/model.py'],\n",
       " 'Neural_Structure_Fields_with_Application_to_Crystal_Structure_Autoencoders': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Neural_Structure_Fields_with_Application_to_Crystal_Structure_Autoencoders/src/model.py'],\n",
       " 'A_Diffusion_Weighted_Graph_Framework_for_New_Intent_Discovery': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Diffusion_Weighted_Graph_Framework_for_New_Intent_Discovery/model.py'],\n",
       " 'SATO__Stable_Text-to-Motion_Framework': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SATO__Stable_Text-to-Motion_Framework/CLIP/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SATO__Stable_Text-to-Motion_Framework/visualization/CLIP/clip/model.py'],\n",
       " 'DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib/base/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib/unet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib_extended/base/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib_extended/base_with_class_head/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib_extended/unet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DiPS__Discriminative_Pseudo-Label_Sampling_with_Self-Supervised_Transformers_for_Weakly_Supervised_Object_Localization/dlib_extended/unet_with_class_head/model.py'],\n",
       " 'Whispering_LLaMA__A_Cross-Modal_Generative_Error_Correction_Framework_for_Speech_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Whispering_LLaMA__A_Cross-Modal_Generative_Error_Correction_Framework_for_Speech_Recognition/lit_llama/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Whispering_LLaMA__A_Cross-Modal_Generative_Error_Correction_Framework_for_Speech_Recognition/whisper_openAI/whisper/model.py'],\n",
       " 'Language_Agent_Tree_Search_Unifies_Reasoning_Acting_and_Planning_in_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Language_Agent_Tree_Search_Unifies_Reasoning_Acting_and_Planning_in_Language_Models/programming/generators/model.py'],\n",
       " 'DDM__2___Self-Supervised_Diffusion_MRI_Denoising_with_Generative_Diffusion_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDM__2___Self-Supervised_Diffusion_MRI_Denoising_with_Generative_Diffusion_Models/3D_DenseNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DDM__2___Self-Supervised_Diffusion_MRI_Denoising_with_Generative_Diffusion_Models/DeepID/src/model.py'],\n",
       " 'Large-Scale_and_Multi-Perspective_Opinion_Summarization_with_Diverse_Review_Subsets': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Large-Scale_and_Multi-Perspective_Opinion_Summarization_with_Diverse_Review_Subsets/shared_lib/utils/helpers/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Large-Scale_and_Multi-Perspective_Opinion_Summarization_with_Diverse_Review_Subsets/subsumm/utils/constants/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Large-Scale_and_Multi-Perspective_Opinion_Summarization_with_Diverse_Review_Subsets/subsumm/utils/helpers/model.py'],\n",
       " 'DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics/codebases/stable-diffusion/ldm/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics/codebases/stable-diffusion/src/clip/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics/codebases/stable-diffusion/src/taming-transformers/taming/modules/diffusionmodules/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DPM-Solver-v3__Improved_Diffusion_ODE_Solver_with_Empirical_Model_Statistics/codebases/stable-diffusion/src/taming-transformers/taming/modules/discriminator/model.py'],\n",
       " 'Concept-free_Causal_Disentanglement_with_Variational_Graph_Auto-Encoder': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Concept-free_Causal_Disentanglement_with_Variational_Graph_Auto-Encoder/model.py'],\n",
       " 'Domain-Specific_Code_Language_Models__Unraveling_the_Potential_for_HPC_Codes_and_Tasks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Domain-Specific_Code_Language_Models__Unraveling_the_Potential_for_HPC_Codes_and_Tasks/CompAI/OMPify/model.py'],\n",
       " 'Contrastive_variational_information_bottleneck_for_aspect-based_sentiment_analysis': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Contrastive_variational_information_bottleneck_for_aspect-based_sentiment_analysis/model.py'],\n",
       " 'FishNet__A_Versatile_Backbone_for_Image__Region__and_Pixel_Level_Prediction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FishNet__A_Versatile_Backbone_for_Image__Region__and_Pixel_Level_Prediction/erfnet/modelarts/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/FishNet__A_Versatile_Backbone_for_Image__Region__and_Pixel_Level_Prediction/erfnet/src/model.py'],\n",
       " 'Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Why_Can_GPT_Learn_In-Context__Language_Models_Implicitly_Perform_Gradient_Descent_as_Meta-Optimizers/uprise/src/models/model.py'],\n",
       " 'Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/adaptllm/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/minillm/minillm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/se2/src/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/understand_icl/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/understand_icl/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Tuna__Instruction_Tuning_using_Feedback_from_Large_Language_Models/uprise/src/models/model.py'],\n",
       " 'Machine-Generated_Text_Localization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Machine-Generated_Text_Localization/gradio_utils/fastdetectgpt_scripts/model.py'],\n",
       " 'Multimodal_Transformer_Distillation_for_Audio-Visual_Synchronization': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multimodal_Transformer_Distillation_for_Audio-Visual_Synchronization/models/conformer/model.py'],\n",
       " 'INSANet__INtra-INter_Spectral_Attention_Network_for_Effective_Feature_Fusion_of_Multispectral_Pedestrian_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/INSANet__INtra-INter_Spectral_Attention_Network_for_Effective_Feature_Fusion_of_Multispectral_Pedestrian_Detection/src/model.py'],\n",
       " 'PETA__Evaluating_the_Impact_of_Protein_Transfer_Learning_with_Sub-word_Tokenization_on_Downstream_Applications': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PETA__Evaluating_the_Impact_of_Protein_Transfer_Learning_with_Sub-word_Tokenization_on_Downstream_Applications/peta/model.py'],\n",
       " 'LOGO__A_Long-Form_Video_Dataset_for_Group_Action_Quality_Assessment': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LOGO__A_Long-Form_Video_Dataset_for_Group_Action_Quality_Assessment/StreamE-main/model/Model.py'],\n",
       " 'On_the_Continuity_of_Rotation_Representations_in_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Continuity_of_Rotation_Representations_in_Neural_Networks/Inverse_Kinematics/code/Model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_the_Continuity_of_Rotation_Representations_in_Neural_Networks/sanity_test/code/model.py'],\n",
       " 'Personalizing_Session-based_Recommendations_with_Hierarchical_Recurrent_Neural_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Personalizing_Session-based_Recommendations_with_Hierarchical_Recurrent_Neural_Networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Personalizing_Session-based_Recommendations_with_Hierarchical_Recurrent_Neural_Networks/model/legacy/model.py'],\n",
       " 'Deep_Probabilistic_Modeling_of_Glioma_Growth': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Probabilistic_Modeling_of_Glioma_Growth/probunet/model.py'],\n",
       " 'Deep_Speech_2__End-to-End_Speech_Recognition_in_English_and_Mandarin': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Speech_2__End-to-End_Speech_Recognition_in_English_and_Mandarin/model.py'],\n",
       " 'Locally_Differentially_Private__Contextual__Bandits_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Locally_Differentially_Private__Contextual__Bandits_Learning/duconv/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Locally_Differentially_Private__Contextual__Bandits_Learning/lite-hrnet/src/model.py'],\n",
       " 'Detecting_Text_in_Natural_Image_with_Connectionist_Text_Proposal_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Detecting_Text_in_Natural_Image_with_Connectionist_Text_Proposal_Network/densenet/model.py'],\n",
       " 'Metrics_and_continuity_in_reinforcement_learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Metrics_and_continuity_in_reinforcement_learning/graph_embedding/huge/model.py'],\n",
       " 'Bootstrap_your_own_latent__A_new_approach_to_self-supervised_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bootstrap_your_own_latent__A_new_approach_to_self-supervised_Learning/self_driving_car/ML Agent/model.py'],\n",
       " 'On_Adaptive_Attacks_to_Adversarial_Example_Defenses': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/On_Adaptive_Attacks_to_Adversarial_Example_Defenses/07_ensemble_diversity/model.py'],\n",
       " 'LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/beit2/vqkd_teacher/clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/examples/MMPT/scripts/video_feature_extractor/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/fairseq/model_parallel/models/pipeline_parallel_transformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/fairseq/model_parallel/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/edgelm/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/kosmos-2/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/kosmos-2/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/kosmos-2/open_clip/src/open_clip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/decoding/GAD/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/decoding/GAD/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/infoxlm/fairseq/fairseq/models/bart/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/infoxlm/fairseq/fairseq/models/roberta/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/xdoc/fine_tuning/funsd/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LayoutXLM__Multimodal_Pre-training_for_Multilingual_Visually-rich_Document_Understanding/xdoc/fine_tuning/websrc/model.py'],\n",
       " 'RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/rtmdet/projects/easydeploy/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/rtmdet/tests/test_deploy/data/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/engine/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/fastsam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/nas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/rtdetr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/sam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8l/ultralytics/models/yolo/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/engine/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/fastsam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/nas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/rtdetr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/sam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8m/ultralytics/models/yolo/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/engine/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/fastsam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/nas/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/rtdetr/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/sam/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RSUD20K__A_Dataset_for_Road_Scene_Understanding_In_Autonomous_Driving/object_detectors/yolov8s/ultralytics/models/yolo/model.py'],\n",
       " 'Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement/src/model.py'],\n",
       " 'Gaze360__Physically_Unconstrained_Gaze_Estimation_in_the_Wild': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Gaze360__Physically_Unconstrained_Gaze_Estimation_in_the_Wild/code/model.py'],\n",
       " 'AutoML_Segmentation_for_3D_Medical_Image_Data__Contribution_to_the_MSD_Challenge_2018': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AutoML_Segmentation_for_3D_Medical_Image_Data__Contribution_to_the_MSD_Challenge_2018/model.py'],\n",
       " 'AV_Taris__Online_Audio-Visual_Speech_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/AV_Taris__Online_Audio-Visual_Speech_Recognition/avsr/transformer/model.py'],\n",
       " 'Can_Autonomous_Vehicles_Identify__Recover_From__and_Adapt_to_Distribution_Shifts_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Autonomous_Vehicles_Identify__Recover_From__and_Adapt_to_Distribution_Shifts_/oatomobile/baselines/torch/cil/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Can_Autonomous_Vehicles_Identify__Recover_From__and_Adapt_to_Distribution_Shifts_/oatomobile/baselines/torch/dim/model.py'],\n",
       " 'Permutation-equivariant_and_Proximity-aware_Graph_Neural_Networks_with_Stochastic_Message_Passing': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Permutation-equivariant_and_Proximity-aware_Graph_Neural_Networks_with_Stochastic_Message_Passing/models/model.py'],\n",
       " 'Reviving_Iterative_Training_with_Mask_Guidance_for_Interactive_Segmentation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Reviving_Iterative_Training_with_Mask_Guidance_for_Interactive_Segmentation/deploy/fastdeploy/semantic_segmentation/serving/fastdeploy_serving/models/postprocess/1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Reviving_Iterative_Training_with_Mask_Guidance_for_Interactive_Segmentation/deploy/fastdeploy/semantic_segmentation/serving/fastdeploy_serving/models/preprocess/1/model.py'],\n",
       " 'SiftingGAN__Generating_and_Sifting_Labeled_Samples_to_Improve_the_Remote_Sensing_Image_Scene_Classification_Baseline_in_vitro': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/SiftingGAN__Generating_and_Sifting_Labeled_Samples_to_Improve_the_Remote_Sensing_Image_Scene_Classification_Baseline_in_vitro/model.py'],\n",
       " 'Multi-Pointer_Co-Attention_Networks_for_Recommendation': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multi-Pointer_Co-Attention_Networks_for_Recommendation/MPCN/tf_models/model.py'],\n",
       " 'PDNet__Prior-model_Guided_Depth-enhanced_Network_for_Salient_Object_Detection': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PDNet__Prior-model_Guided_Depth-enhanced_Network_for_Salient_Object_Detection/model.py'],\n",
       " 'Robust_Deep_Reinforcement_Learning_through_Adversarial_Loss': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robust_Deep_Reinforcement_Learning_through_Adversarial_Loss/A3C/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Robust_Deep_Reinforcement_Learning_through_Adversarial_Loss/DQN/model.py'],\n",
       " 'Investigating_Saturation_Effects_in_Integrated_Gradients': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Investigating_Saturation_Effects_in_Integrated_Gradients/captum/_utils/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Investigating_Saturation_Effects_in_Integrated_Gradients/captum/_utils/models/linear_model/model.py'],\n",
       " 'Perceptual_Extreme_Super_Resolution_Network_with_Receptive_Field_Block': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Perceptual_Extreme_Super_Resolution_Network_with_Receptive_Field_Block/model.py'],\n",
       " 'ParSeNet__A_Parametric_Surface_Fitting_Network_for_3D_Point_Clouds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ParSeNet__A_Parametric_Surface_Fitting_Network_for_3D_Point_Clouds/src/model.py'],\n",
       " 'Learning_explanations_that_are_hard_to_vary': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_explanations_that_are_hard_to_vary/examples/super_resolution/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_explanations_that_are_hard_to_vary/examples/transformers/model.py'],\n",
       " 'Neural_Twins_Talk': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Neural_Twins_Talk/misc/model.py'],\n",
       " 'A_Brief_Survey_and_Comparative_Study_of_Recent_Development_of_Pronoun_Coreference_Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Brief_Survey_and_Comparative_Study_of_Recent_Development_of_Pronoun_Coreference_Resolution/hard_PCR (WSC)/gpt2/src/model.py'],\n",
       " 'Cosine_meets_Softmax__A_tough-to-beat_baseline_for_visual_grounding': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Cosine_meets_Softmax__A_tough-to-beat_baseline_for_visual_grounding/efficientnet_pytorch/model.py'],\n",
       " 'Networks_with_pixels_embedding__a_method_to_improve_noise_resistance_in_images_classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Networks_with_pixels_embedding__a_method_to_improve_noise_resistance_in_images_classification/Apackage_image_classify_minist_test_noise/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Networks_with_pixels_embedding__a_method_to_improve_noise_resistance_in_images_classification/image_classify_minist_embedding_test_noise/model.py'],\n",
       " 'How_Useful_are_Reviews_for_Recommendation__A_Critical_Review_and_Potential_Improvements': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/How_Useful_are_Reviews_for_Recommendation__A_Critical_Review_and_Potential_Improvements/MPCN/tf_models/model.py'],\n",
       " 'Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/HMR/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/ISyNet/ISyNet/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/IndexNet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/JDE/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/LEO/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/MaskedFaceRecognition/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/hed/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/ivpf/ivpf/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/lite-hrnet/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/m2det/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_triplet_loss__a_deep_quadruplet_network_for_person_re-identification/lerf/lerf_sr/model.py'],\n",
       " 'Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/abstract_nas/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/adaptive_low_rank/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/capsule_em/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/cnn_quantization/tf_cnn_benchmarks/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/cold_posterior_bnn/core/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/comisr/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/contrack/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/covid_epidemiology/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/depth_from_video_in_the_wild/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/diffusion_distillation/diffusion_distillation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/direction_net/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/dreg_estimators/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/ieg/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/imp/max/projects/imp/config/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/l2tl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/meta_reward_learning/textworld/lib/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/multi_resolution_rec/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/polysketchformer/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/protoattend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/resolve_ref_exp_elements_ml/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/robust_optim/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/sign_language_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/slot_attention/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/spreadsheet_coder/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/stacked_capsule_autoencoders/capsules/models/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/sudoku_gpt/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/summae/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/table_rag/agent/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/tf3d/instance_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/tf3d/object_detection/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/tf3d/semantic_segmentation/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/video_timeline_modeling/vtm/model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/cache_replacement/policy_learning/cache_model/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/d3pm/images/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/fairness_teaching/baseline/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/fairness_teaching/gan/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/fairness_teaching/rl/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/fairness_teaching/in_progress/rl_a2c/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/graph_embedding/ddgk/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Beyond_512_Tokens__Siamese_Multi-depth_Transformer-based_Hierarchical_Encoder_for_Long-Form_Document_Matching/graph_embedding/huge/model.py'],\n",
       " 'Character-level_White-Box_Adversarial_Attacks_against_Transformers_via_Attachable_Subwords_Substitution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Character-level_White-Box_Adversarial_Attacks_against_Transformers_via_Attachable_Subwords_Substitution/token_level_attack/pretrainkit/model.py'],\n",
       " 'UPB_at_SemEval-2020_Task_6__Pretrained_Language_Models_for_Definition_Extraction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/UPB_at_SemEval-2020_Task_6__Pretrained_Language_Models_for_Definition_Extraction/model.py'],\n",
       " 'Learning_Energy-Based_Models_by_Diffusion_Recovery_Likelihood': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Learning_Energy-Based_Models_by_Diffusion_Recovery_Likelihood/model.py'],\n",
       " 'Bayesian_Diffusion_Models_for_3D_Shape_Reconstruction': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Bayesian_Diffusion_Models_for_3D_Shape_Reconstruction/experiments/model/model.py'],\n",
       " 'Sentence-Incremental_Neural_Coreference_Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Sentence-Incremental_Neural_Coreference_Resolution/model.py'],\n",
       " 'Value_Iteration_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Value_Iteration_Networks/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Value_Iteration_Networks/a2c_ppo_acktr/model.py'],\n",
       " 'BraggNN__Fast_X-ray_Bragg_Peak_Analysis_Using_Deep_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/BraggNN__Fast_X-ray_Bragg_Peak_Analysis_Using_Deep_Learning/model.py'],\n",
       " 'Adaptive_Personalized_Federated_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Personalized_Federated_Learning/fedtorch/components/model.py'],\n",
       " 'Federated_Learning_with_Compression__Unified_Analysis_and_Sharp_Guarantees': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Federated_Learning_with_Compression__Unified_Analysis_and_Sharp_Guarantees/fedtorch/components/model.py'],\n",
       " 'Agnostic_Federated_Learning': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Agnostic_Federated_Learning/fedtorch/components/model.py'],\n",
       " 'Federated_Optimization_in_Heterogeneous_Networks': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Federated_Optimization_in_Heterogeneous_Networks/fedtorch/components/model.py'],\n",
       " 'PU-GAN__a_Point_Cloud_Upsampling_Adversarial_Network': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/PU-GAN__a_Point_Cloud_Upsampling_Adversarial_Network/Upsampling/model.py'],\n",
       " 'Transformer_in_Transformer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_in_Transformer/TCN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_in_Transformer/WGAN_GP/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Transformer_in_Transformer/wdsr/src/model.py'],\n",
       " 'TabAug__Data_Driven_Augmentation_for_Enhanced_Table_Structure_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/TabAug__Data_Driven_Augmentation_for_Enhanced_Table_Structure_Recognition/libs/model.py'],\n",
       " 'Semantic_Photo_Manipulation_with_a_Generative_Image_Prior': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Photo_Manipulation_with_a_Generative_Image_Prior/editing/styleclip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Semantic_Photo_Manipulation_with_a_Generative_Image_Prior/models/stylegan2/model.py'],\n",
       " 'Improved_StyleGAN_Embedding__Where_are_the_Good_Latents_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improved_StyleGAN_Embedding__Where_are_the_Good_Latents_/editing/styleclip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Improved_StyleGAN_Embedding__Where_are_the_Good_Latents_/models/stylegan2/model.py'],\n",
       " 'Image2StyleGAN__How_to_Embed_Images_Into_the_StyleGAN_Latent_Space_': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Image2StyleGAN__How_to_Embed_Images_Into_the_StyleGAN_Latent_Space_/editing/styleclip/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Image2StyleGAN__How_to_Embed_Images_Into_the_StyleGAN_Latent_Space_/models/stylegan2/model.py'],\n",
       " 'Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Assessment_LM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Description_LM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Detection_LM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Location_LLM/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Multitask-based_Evaluation_of_Open-Source_LLM_on_Software_Vulnerability/Location_LM/model.py'],\n",
       " 'A_Multi-View_Deep_Learning_Approach_for_Cross_Domain_User_Modeling_in_Recommendation_Systems': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-View_Deep_Learning_Approach_for_Cross_Domain_User_Modeling_in_Recommendation_Systems/models/treebased/tdm/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-View_Deep_Learning_Approach_for_Cross_Domain_User_Modeling_in_Recommendation_Systems/uapi_rec/base/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/A_Multi-View_Deep_Learning_Approach_for_Cross_Domain_User_Modeling_in_Recommendation_Systems/uapi_rec/rank/model.py'],\n",
       " 'Fast_Nearest_Convolution_for_Real-Time_Efficient_Image_Super-Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Fast_Nearest_Convolution_for_Real-Time_Efficient_Image_Super-Resolution/src/model.py'],\n",
       " 'Segment_Anything': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Segment_Anything/deploy/fastdeploy/semantic_segmentation/serving/fastdeploy_serving/models/postprocess/1/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Segment_Anything/deploy/fastdeploy/semantic_segmentation/serving/fastdeploy_serving/models/preprocess/1/model.py'],\n",
       " 'Dynamical_Mechanism_of_Sampling-based_Stochastic_Inference_under_Probabilistic_Population_Codes': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Dynamical_Mechanism_of_Sampling-based_Stochastic_Inference_under_Probabilistic_Population_Codes/probabilistic_inference/model.py'],\n",
       " 'LMOT__Efficient_Light-Weight_Detection_and_Tracking_in_Crowds': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/LMOT__Efficient_Light-Weight_Detection_and_Tracking_in_Crowds/src/lib/model/model.py'],\n",
       " 'Adaptive_Ranking-based_Sample_Selection_for_Weakly_Supervised_Class-imbalanced_Text_Classification': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Adaptive_Ranking-based_Sample_Selection_for_Weakly_Supervised_Class-imbalanced_Text_Classification/wrench/seq_labelmodel/chmm_src/CHMM/Model.py'],\n",
       " 'ShuffleNet__An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/ShuffleNet__An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices/model.py'],\n",
       " 'Drafting_and_Revision__Laplacian_Pyramid_Network_for_Fast_High-Quality_Artistic_Style_Transfer': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Drafting_and_Revision__Laplacian_Pyramid_Network_for_Fast_High-Quality_Artistic_Style_Transfer/WebDemo/PaddleGAN/ppgan/faceutils/mask/model.py'],\n",
       " 'Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition/SinGAN/src/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition/simple_pose/src/model.py'],\n",
       " 'Simple_Hardware-Efficient_Long_Convolutions_for_Sequence_Modeling': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Simple_Hardware-Efficient_Long_Convolutions_for_Sequence_Modeling/src/models/sequence/model.py'],\n",
       " 'RAF__Holistic_Compilation_for_Deep_Learning_Model_Training': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RAF__Holistic_Compilation_for_Deep_Learning_Model_Training/python/raf/frontend/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/RAF__Holistic_Compilation_for_Deep_Learning_Model_Training/python/raf/model/model.py'],\n",
       " 'Spatial-temporal_Hierarchical_Reinforcement_Learning_for_Interpretable_Pathology_Image_Super-Resolution': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial-temporal_Hierarchical_Reinforcement_Learning_for_Interpretable_Pathology_Image_Super-Resolution/PW/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Spatial-temporal_Hierarchical_Reinforcement_Learning_for_Interpretable_Pathology_Image_Super-Resolution/spM_tpW/model.py'],\n",
       " 'Weakly-Supervised_Video_Anomaly_Detection_with_Snippet_Anomalous_Attention': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly-Supervised_Video_Anomaly_Detection_with_Snippet_Anomalous_Attention/FBPrompt-main/eval_scripts/pykp/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly-Supervised_Video_Anomaly_Detection_with_Snippet_Anomalous_Attention/SPCTNet-main/model.py',\n",
       "  '/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/Weakly-Supervised_Video_Anomaly_Detection_with_Snippet_Anomalous_Attention/WS-VAD-mindspore-main/model.py'],\n",
       " 'DivClust__Controlling_Diversity_in_Deep_Clustering': ['/media/ll16598/One Touch/INNOVATE/pwc_python_files_from_git/DivClust__Controlling_Diversity_in_Deep_Clustering/engine/model.py']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
